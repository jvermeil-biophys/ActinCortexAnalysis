{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from copy import copy\n",
    "matplotlib.rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainDir = \"C://Users//JosephVermeil//Desktop//ActinCortexAnalysis\"\n",
    "experimentalDataDir = os.path.join(mainDir, \"ExperimentalData\")\n",
    "dataDir = os.path.join(mainDir, \"DataAnalysis\")\n",
    "timeSeriesDataDir = os.path.join(dataDir, \"TimeSeriesData\")\n",
    "allTimeSeriesDataFiles = [f for f in os.listdir(timeSeriesDataDir) if (os.path.isfile(os.path.join(timeSeriesDataDir, f)) and f.endswith(\".txt\"))]\n",
    "allTimeSeriesDataFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility subfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCellTimeSeriesData(cellID):\n",
    "    allTimeSeriesDataFiles = [f for f in os.listdir(timeSeriesDataDir) if (os.path.isfile(os.path.join(timeSeriesDataDir, f)) and f.endswith(\".txt\"))]\n",
    "    fileFound = False\n",
    "    nFile = len(allTimeSeriesDataFiles)\n",
    "    iFile = 0\n",
    "    while (not fileFound) and (iFile < nFile):\n",
    "        f = allTimeSeriesDataFiles[iFile]\n",
    "        if f.startswith(cellID):\n",
    "            timeSeriesDataFilePath = os.path.join(timeSeriesDataDir, f)\n",
    "            timeSeriesDataFrame = pd.read_csv(timeSeriesDataFilePath, ',')\n",
    "            fileFound = True\n",
    "        iFile += 1\n",
    "    if not fileFound:\n",
    "        timeSeriesDataFrame = pd.DataFrame([])\n",
    "    return(timeSeriesDataFrame)\n",
    "\n",
    "def plotCellTimeSeriesData(cellID):\n",
    "    X = 'T'\n",
    "    Y = np.array(['B', 'F', 'dx', 'dy', 'dz', 'D2', 'D3'])\n",
    "    units = np.array([' (mT)', ' (pN)', ' (µm)', ' (µm)', ' (µm)', ' (µm)', ' (µm)'])\n",
    "    timeSeriesDataFrame = getCellTimeSeriesData(cellID)\n",
    "    if not timeSeriesDataFrame.size == 0:\n",
    "#         plt.tight_layout()\n",
    "#         fig.show() # figsize=(20,20)\n",
    "        axes = timeSeriesDataFrame.plot(x=X, y=Y, kind='line', ax=None, subplots=True, sharex=True, sharey=False, layout=None, \\\n",
    "                       figsize=(8,10), use_index=True, title = cellID + '- Time dependant data', grid=None, legend=False, style=None, logx=False, logy=False, \\\n",
    "                       loglog=False, xticks=None, yticks=None, xlim=None, ylim=None, rot=None, fontsize=None, colormap=None, \\\n",
    "                       table=False, yerr=None, xerr=None, secondary_y=False, sort_columns=False)\n",
    "        plt.gcf().tight_layout()\n",
    "        for i in range(len(Y)):\n",
    "            axes[i].set_ylabel(Y[i] + units[i])\n",
    "        \n",
    "    else:\n",
    "        print('cell not found')\n",
    "        \n",
    "def addExcludedCell(cellID, motive):\n",
    "    f = open(os.path.join(experimentalDataDir, 'ExcludedCells.txt'), 'r')\n",
    "    lines = f.readlines()\n",
    "    nLines = len(lines)\n",
    "    excludedCellsList = []\n",
    "    for iLine in range(nLines):\n",
    "        line = lines[iLine]\n",
    "        splitLine = line[:-1].split(',')\n",
    "        excludedCellsList.append(splitLine[0])\n",
    "    if cellID in excludedCellsList:\n",
    "        newlines = copy(lines)\n",
    "        iLineOfInterest = excludedCellsList.index(cellID)\n",
    "        if motive not in newlines[iLineOfInterest][:-1].split(','):\n",
    "            newlines[iLineOfInterest] = newlines[iLineOfInterest][:-1] + ',' + motive + '\\n'            \n",
    "    else:\n",
    "        newlines = copy(lines)\n",
    "        newlines.append('' + cellID + ',' + motive + '\\n')\n",
    "    f.close()\n",
    "    f = open(os.path.join(experimentalDataDir, 'ExcludedCells.txt'), 'w')\n",
    "    f.writelines(newlines)\n",
    "    \n",
    "def getExcludedCells():\n",
    "    f = open(os.path.join(experimentalDataDir, 'ExcludedCells.txt'), 'r')\n",
    "    lines = f.readlines()\n",
    "    nLines = len(lines)\n",
    "    excludedCellsDict = {}\n",
    "    for iLine in range(nLines):\n",
    "        line = lines[iLine]\n",
    "        splitLine = line[:-1].split(',')\n",
    "        excludedCellsDict[splitLine[0]] = splitLine[1:]\n",
    "    return(excludedCellsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getCellTimeSeriesData('20-08-05_M1_P1_C6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotCellTimeSeriesData('21-01-21_M1_P1_C2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecaDataFile = 'Global_MecaData.txt'\n",
    "mecaDataFilePath = os.path.join(dataDir, mecaDataFile)\n",
    "mecaDF = pd.read_csv(mecaDataFilePath, ',')\n",
    "print('Extracted a table with ' + str(mecaDF.shape[0]) + ' lines and ' + str(mecaDF.shape[1]) + ' columns.')\n",
    "\n",
    "mecaDF = mecaDF.rename(columns={\"CellID\": \"CellName\", \"CellName\": \"CellID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mecaDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentalDataFile = 'ExperimentalConditions.csv'\n",
    "experimentalDataFilePath = os.path.join(experimentalDataDir, experimentalDataFile)\n",
    "expConditionsDF = pd.read_csv(experimentalDataFilePath, ',',header=1)\n",
    "print('Extracted a table with ' + str(expConditionsDF.shape[0]) + ' lines and ' + str(expConditionsDF.shape[1]) + ' columns.')\n",
    "\n",
    "# Cleaning the table\n",
    "try:\n",
    "    expConditionsDF = expConditionsDF.convert_dtypes()\n",
    "\n",
    "    listTextColumns = []\n",
    "    for col in expConditionsDF.columns:\n",
    "        if expConditionsDF[col].dtype == 'string':\n",
    "            listTextColumns.append(col)\n",
    "\n",
    "    expConditionsDF[listTextColumns] = expConditionsDF[listTextColumns].apply(lambda x: x.str.replace(',','.'))\n",
    "\n",
    "    expConditionsDF['scale pixel per um'] = expConditionsDF['scale pixel per um'].astype(float)\n",
    "    expConditionsDF['optical index correction'] = \\\n",
    "              expConditionsDF['optical index correction'].apply(lambda x: x.split('/')[0]).astype(float) \\\n",
    "            / expConditionsDF['optical index correction'].apply(lambda x: x.split('/')[1]).astype(float)\n",
    "    expConditionsDF['magnetic field correction'] = expConditionsDF['magnetic field correction'].astype(float)\n",
    "    expConditionsDF['with fluo images'] = expConditionsDF['with fluo images'].astype(bool)\n",
    "\n",
    "    expConditionsDF['ramp field'] = \\\n",
    "    expConditionsDF['ramp field'].apply(lambda x: [x.split(';')[0], x.split(';')[1]] if not pd.isnull(x) else [])\n",
    "\n",
    "except:\n",
    "    print('Unexpected bug with the cleaning step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# expConditionsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused for now\n",
    "cellDescriptionDataFile = 'CellDescription.csv'\n",
    "cellDescriptionDataFilePath = os.path.join(experimentalDataDir, cellDescriptionDataFile)\n",
    "cellDescriptionDF = pd.read_csv(cellDescriptionDataFilePath, ',')\n",
    "print('Extracted a table with ' + str(cellDescriptionDF.shape[0]) + ' lines and ' + str(cellDescriptionDF.shape[1]) + ' columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecaDF['ManipID'] = mecaDF['ExpDay'] + '_' + mecaDF['CellName'].apply(lambda x: x.split('_')[0])\n",
    "expConditionsDF['ManipID'] = expConditionsDF['date'] + '_' + expConditionsDF['manip']\n",
    "\n",
    "mainMecaDF = pd.merge(\n",
    "    expConditionsDF,\n",
    "    mecaDF,\n",
    "    how=\"inner\",\n",
    "    on='ManipID',\n",
    "#     left_on=None,\n",
    "#     right_on=None,\n",
    "#     left_index=False,\n",
    "#     right_index=False,\n",
    "#     sort=True,\n",
    "#     suffixes=(\"_x\", \"_y\"),\n",
    "#     copy=True,\n",
    "#     indicator=False,\n",
    "#     validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# mainMecaDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('max_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# mainMecaDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.reset_option('max_columns')\n",
    "# mainMecaDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainMecaDF_f = mainMecaDF.loc[(mainMecaDF[\"Validated\"] == 1)]\n",
    "# mainMecaDF_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "listCells = mainMecaDF_f['CellID'].drop_duplicates().astype('string').values\n",
    "timeSeriesDict = {}\n",
    "for cell in listCells:\n",
    "    currentCell_TimeSeriesData = getCellTimeSeriesData(cell)\n",
    "    timeSeriesDict[cell] = currentCell_TimeSeriesData\n",
    "start, stop = 80, 100\n",
    "fig, axes = plt.subplots((stop-start),1, figsize = (7,4*(stop-start)))\n",
    "fig.tight_layout()\n",
    "for k in range(start, stop):\n",
    "    if k < len(listCells):\n",
    "        currentCell_TimeSeriesData = timeSeriesDict[listCells[k]]\n",
    "        T = currentCell_TimeSeriesData['T'].values\n",
    "        idxCompression = currentCell_TimeSeriesData['idxCompression'].values\n",
    "        D3 = currentCell_TimeSeriesData['D3'].values\n",
    "        maskConstant = (idxCompression == 0)\n",
    "        maskCompression = (idxCompression > 0)\n",
    "        axes[k - start].plot(T, D3*1000-4503, 'k-', linewidth = 0.5)\n",
    "        axes[k - start].plot(T[maskCompression], D3[maskCompression]*1000-4503, 'ro', markersize=2)\n",
    "        axes[k - start].plot(T[maskConstant], D3[maskConstant]*1000-4503, 'co', markersize=2)\n",
    "        axes[k - start].set_title(listCells[k])\n",
    "        axes[k - start].set_xlabel('T (s)')\n",
    "        axes[k - start].set_ylabel('D3 (µm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addExcludedCell('21-01-18_M1_P1_C2', 'passive')\n",
    "addExcludedCell('21-01-18_M1_P1_C3', 'passive')\n",
    "addExcludedCell('21-01-18_M1_P1_C4', 'passive')\n",
    "addExcludedCell('21-01-21_M3_P1_C4', 'passive')\n",
    "addExcludedCell('21-01-21_M3_P1_C5', 'passive')\n",
    "addExcludedCell('20-08-07_M1_P1_C6', 'too thick')\n",
    "addExcludedCell('20-08-07_M1_P1_C62', 'too thick')\n",
    "\n",
    "excludedCellsDict = getExcludedCells()\n",
    "# excludedMask = (mainMecaDF_f[\"CellID\"].values not in excludedCellsDict.keys())\n",
    "# mainMecaDF_f = mainMecaDF_f.loc[(mainMecaDF_f[\"CellID\"].values not in excludedCellsDict.keys())]\n",
    "for i in range(len(excludedCellsDict)):\n",
    "    print('a')\n",
    "mainMecaDF_f[\"CellID\"].drop_duplicates().astype('string').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentCell_TimeSeriesData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainMecaDF_GroupedPerCell = mainMecaDF_f.groupby('CellID')\n",
    "mainMecaDF_DataPerCell = mainMecaDF_GroupedPerCell.agg({\"EChadwick\": np.median, \"SurroundingThickness\": np.median, \"H0Chadwick\" : np.median})\n",
    "# mainMecaDF_GroupedPerCell.agg({\"EChadwick\": np.median, \"D\": lambda x: np.std(x, ddof=1)})\n",
    "cols = ['date', 'manip', 'experimentType', 'drug', 'substrate',\n",
    "       'objective magnification', 'scale pixel per um', 'objective immersion',\n",
    "       'optical index correction', 'magnetic field correction', 'cell type',\n",
    "       'cell subtype', 'bead type', 'bead diameter', 'normal field',\n",
    "       'ramp field', 'compression duration', 'with fluo images', 'comments',\n",
    "       'ManipID', 'ExpType', 'CellName', 'CellID']\n",
    "mainMecaDF_DataPerCell.dropna(inplace = True)\n",
    "mainMecaDF_DataPerCell = pd.merge(mainMecaDF_DataPerCell,\n",
    "                                  mainMecaDF_f[cols].drop_duplicates(subset=['CellID']),\n",
    "                                  how=\"inner\",\n",
    "                                  on='CellID',\n",
    "                                  #     left_on='CellID',\n",
    "                                  #     right_on='CellID',\n",
    "                                  #     left_index=False,\n",
    "                                  #     right_index=False,\n",
    "                                  #     sort=True,\n",
    "                                  #     suffixes=(\"_x\", \"_y\"),\n",
    "                                  #     copy=True,\n",
    "                                  #     indicator=False,\n",
    "                                  #     validate=None,\n",
    "                                  )\n",
    "# mainMecaDF_DataPerCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainMecaDF_DataPerCell_Count = mainMecaDF_DataPerCell.groupby(['cell type', 'cell subtype', 'bead type', 'drug', 'substrate']).count()\n",
    "mainMecaDF_DataPerCell_Count.loc[:, ['CellID']].rename(columns={'CellID' : 'Count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
