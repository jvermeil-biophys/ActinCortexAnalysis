{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24191cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pyautogui\n",
    "import matplotlib\n",
    "\n",
    "# import skimage\n",
    "from skimage import io, filters, exposure, measure, transform\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# 2. Pandas settings\n",
    "pd.set_option('mode.chained_assignment',None)\n",
    "\n",
    "# 3. Plot settings\n",
    "# Here we use this mode because displaying images \n",
    "# in new windows is more convenient for this code.\n",
    "%matplotlib qt \n",
    "# To switch back to inline display, use : \n",
    "# %matplotlib widget or %matplotlib inline\n",
    "matplotlib.rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "SMALLER_SIZE = 8\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 20\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALLER_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# 4. Other settings\n",
    "# These regex are used to correct the stupid date conversions done by Excel\n",
    "dateFormatExcel = re.compile('\\d{2}/\\d{2}/\\d{4}')\n",
    "dateFormatOk = re.compile('\\d{2}-\\d{2}-\\d{2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad62656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_100X = 15.8 # pix/µm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4326a59f",
   "metadata": {},
   "source": [
    "## Classes & functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a586e",
   "metadata": {},
   "source": [
    "### Import experiemental data table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4f217",
   "metadata": {},
   "source": [
    "Here the Experimental Data Table is imported. This table, filled after each experiment, contains all the relevant infos about experimental conditions, and can be both read by the users (to keep a history of the experiments done) and the computer (to access relevant parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccf2534a",
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted a table with 53 lines and 23 columns.\n",
      "optical index correction already in Float64 type.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>manip</th>\n",
       "      <th>experimentType</th>\n",
       "      <th>drug</th>\n",
       "      <th>substrate</th>\n",
       "      <th>objective magnification</th>\n",
       "      <th>scale pixel per um</th>\n",
       "      <th>objective immersion</th>\n",
       "      <th>optical index correction</th>\n",
       "      <th>magnetic field correction</th>\n",
       "      <th>...</th>\n",
       "      <th>bead diameter</th>\n",
       "      <th>beads bright spot delta</th>\n",
       "      <th>normal field</th>\n",
       "      <th>ramp field</th>\n",
       "      <th>compression duration</th>\n",
       "      <th>with fluo images</th>\n",
       "      <th>normal field multi images</th>\n",
       "      <th>loop structure</th>\n",
       "      <th>comments</th>\n",
       "      <th>manipID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEFAULT</td>\n",
       "      <td>DEFAULT</td>\n",
       "      <td>DEFAULT</td>\n",
       "      <td>DEFAULT</td>\n",
       "      <td>DEFAULT</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>DEFAULT</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>143_95</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>DEFAULT_DEFAULT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20-08-04</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions and constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>BSA coated glass</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>143_95</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20-08-04_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20-08-04</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions and constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>BSA coated glass</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>143_95</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20-08-04_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20-08-05</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions and constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>BSA coated glass</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>143_95</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20-08-05_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20-08-05</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions and constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>BSA coated glass</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>143_95</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20-08-05_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20-08-07</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions and constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>BSA coated glass</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>143_95</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20-08-07_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20-08-07</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions and constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>BSA coated glass</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>143_95</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20-08-07_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21-01-18</td>\n",
       "      <td>M1-1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.230</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-01-18_M1-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21-01-18</td>\n",
       "      <td>M1-2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.230</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-01-18_M1-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21-01-18</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.230</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-01-18_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21-01-18</td>\n",
       "      <td>M3</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.230</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-01-18_M3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21-01-21</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.230</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-01-21_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21-01-21</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.230</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-01-21_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21-01-21</td>\n",
       "      <td>M3</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.230</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-01-21_M3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21-02-10</td>\n",
       "      <td>M1</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.200</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>298_0_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-02-10_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21-02-10</td>\n",
       "      <td>M2</td>\n",
       "      <td>constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.200</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>298_0_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-02-10_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21-02-15</td>\n",
       "      <td>M1</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>diverse fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Anumita data</td>\n",
       "      <td>21-02-15_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21-02-15</td>\n",
       "      <td>M2</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>diverse fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Anumita data</td>\n",
       "      <td>21-02-15_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21-02-15</td>\n",
       "      <td>M3</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>diverse fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Anumita data</td>\n",
       "      <td>21-02-15_M3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20-12-16</td>\n",
       "      <td>M1</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.260</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20-12-16_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20-12-16</td>\n",
       "      <td>M2</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.260</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>20-12-16_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21-03-25</td>\n",
       "      <td>M1</td>\n",
       "      <td>constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.120</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>298_0_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-03-25_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21-03-25</td>\n",
       "      <td>M2</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.120</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>298_0_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-03-25_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21-04-21</td>\n",
       "      <td>M1</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>298_0_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-04-21_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21-04-21</td>\n",
       "      <td>M2</td>\n",
       "      <td>constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>298_0_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-04-21_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>21-04-23</td>\n",
       "      <td>M1</td>\n",
       "      <td>constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>298_0_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-04-23_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21-04-23</td>\n",
       "      <td>M2</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>298_0_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-04-23_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21-04-27</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-04-27_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>21-04-27</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-04-27_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>21-04-28</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-04-28_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>21-04-28</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-04-28_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21-06-16</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-06-16_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>21-06-16</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-06-16_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>21-06-17</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-06-17_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>21-06-17</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-06-17_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>21-05-21</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>4503_2691</td>\n",
       "      <td>400</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-05-21_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>21-07-08</td>\n",
       "      <td>M1-1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>2691_4503</td>\n",
       "      <td>400</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-07-08_M1-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>21-07-08</td>\n",
       "      <td>M1-2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>2691_2691</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-07-08_M1-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>21-07-08</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>2691_2691</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-07-08_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>21-07-08</td>\n",
       "      <td>M3</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>4503_2691</td>\n",
       "      <td>400</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-07-08_M3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>21-07-08</td>\n",
       "      <td>M4</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.100</td>\n",
       "      <td>...</td>\n",
       "      <td>4503_4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-07-08_M4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>21-09-01</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>dmso</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.095</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-09-01_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>21-09-01</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>smifh2</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.110</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-09-01_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>21-09-02</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>smifh2</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.110</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-09-02_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>21-09-02</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>dmso</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.110</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>169_133</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-09-02_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>21-09-02</td>\n",
       "      <td>M3</td>\n",
       "      <td>compressions</td>\n",
       "      <td>smifh2. doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.110</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-09-02_M3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>21-09-02</td>\n",
       "      <td>M4</td>\n",
       "      <td>compressions</td>\n",
       "      <td>dmso. doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.110</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-09-02_M4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>21-09-08</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.102</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-09-08_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>21-09-08</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.140</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-09-08_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>21-09-08</td>\n",
       "      <td>M3</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.112</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-09-08_M3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>21-09-08</td>\n",
       "      <td>M4</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.112</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-09-08_M4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>21-09-09</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.150</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-09-09_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>21-09-09</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.154</td>\n",
       "      <td>...</td>\n",
       "      <td>4503</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3_40</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>170_133_1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-09-09_M2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    manip                   experimentType                drug  \\\n",
       "0    DEFAULT  DEFAULT                          DEFAULT             DEFAULT   \n",
       "1   20-08-04       M1  compressions and constant field                none   \n",
       "2   20-08-04       M2  compressions and constant field          doxycyclin   \n",
       "3   20-08-05       M1  compressions and constant field          doxycyclin   \n",
       "4   20-08-05       M2  compressions and constant field                none   \n",
       "5   20-08-07       M1  compressions and constant field          doxycyclin   \n",
       "6   20-08-07       M2  compressions and constant field                none   \n",
       "7   21-01-18     M1-1                     compressions          doxycyclin   \n",
       "8   21-01-18     M1-2                     compressions          doxycyclin   \n",
       "9   21-01-18       M2                     compressions                none   \n",
       "10  21-01-18       M3                     compressions          doxycyclin   \n",
       "11  21-01-21       M1                     compressions                none   \n",
       "12  21-01-21       M2                     compressions          doxycyclin   \n",
       "13  21-01-21       M3                     compressions                none   \n",
       "14  21-02-10       M1                   constant field                none   \n",
       "15  21-02-10       M2                   constant field          doxycyclin   \n",
       "16  21-02-15       M1                   constant field                none   \n",
       "17  21-02-15       M2                   constant field                none   \n",
       "18  21-02-15       M3                   constant field                none   \n",
       "19  20-12-16       M1                   constant field                none   \n",
       "20  20-12-16       M2                   constant field                none   \n",
       "21  21-03-25       M1                   constant field          doxycyclin   \n",
       "22  21-03-25       M2                   constant field                none   \n",
       "23  21-04-21       M1                   constant field                none   \n",
       "24  21-04-21       M2                   constant field          doxycyclin   \n",
       "25  21-04-23       M1                   constant field          doxycyclin   \n",
       "26  21-04-23       M2                   constant field                none   \n",
       "27  21-04-27       M1                     compressions                none   \n",
       "28  21-04-27       M2                     compressions          doxycyclin   \n",
       "29  21-04-28       M1                     compressions          doxycyclin   \n",
       "30  21-04-28       M2                     compressions                none   \n",
       "31  21-06-16       M1                     compressions                none   \n",
       "32  21-06-16       M2                     compressions          doxycyclin   \n",
       "33  21-06-17       M1                     compressions          doxycyclin   \n",
       "34  21-06-17       M2                     compressions                none   \n",
       "35  21-05-21       M1                     compressions                none   \n",
       "36  21-07-08     M1-1                     compressions                none   \n",
       "37  21-07-08     M1-2                     compressions                none   \n",
       "38  21-07-08       M2                     compressions                none   \n",
       "39  21-07-08       M3                     compressions                none   \n",
       "40  21-07-08       M4                     compressions                none   \n",
       "41  21-09-01       M1                     compressions                dmso   \n",
       "42  21-09-01       M2                     compressions              smifh2   \n",
       "43  21-09-02       M1                     compressions              smifh2   \n",
       "44  21-09-02       M2                     compressions                dmso   \n",
       "45  21-09-02       M3                     compressions  smifh2. doxycyclin   \n",
       "46  21-09-02       M4                     compressions    dmso. doxycyclin   \n",
       "47  21-09-08       M1                     compressions          doxycyclin   \n",
       "48  21-09-08       M2                     compressions                none   \n",
       "49  21-09-08       M3                     compressions                none   \n",
       "50  21-09-08       M4                     compressions          doxycyclin   \n",
       "51  21-09-09       M1                     compressions          doxycyclin   \n",
       "52  21-09-09       M2                     compressions                none   \n",
       "\n",
       "                    substrate objective magnification  scale pixel per um  \\\n",
       "0                     DEFAULT                    100X                15.8   \n",
       "1            BSA coated glass                    100X                15.8   \n",
       "2            BSA coated glass                    100X                15.8   \n",
       "3            BSA coated glass                    100X                15.8   \n",
       "4            BSA coated glass                    100X                15.8   \n",
       "5            BSA coated glass                    100X                15.8   \n",
       "6            BSA coated glass                    100X                15.8   \n",
       "7      20um fibronectin discs                    100X                15.8   \n",
       "8      20um fibronectin discs                    100X                15.8   \n",
       "9      20um fibronectin discs                    100X                15.8   \n",
       "10     20um fibronectin discs                    100X                15.8   \n",
       "11     20um fibronectin discs                    100X                15.8   \n",
       "12     20um fibronectin discs                    100X                15.8   \n",
       "13     20um fibronectin discs                    100X                15.8   \n",
       "14     20um fibronectin discs                    100X                15.8   \n",
       "15     20um fibronectin discs                    100X                15.8   \n",
       "16  diverse fibronectin discs                    100X                15.8   \n",
       "17  diverse fibronectin discs                    100X                15.8   \n",
       "18  diverse fibronectin discs                    100X                15.8   \n",
       "19     20um fibronectin discs                    100X                15.8   \n",
       "20     20um fibronectin discs                    100X                15.8   \n",
       "21     20um fibronectin discs                    100X                15.8   \n",
       "22     20um fibronectin discs                    100X                15.8   \n",
       "23     20um fibronectin discs                    100X                15.8   \n",
       "24     20um fibronectin discs                    100X                15.8   \n",
       "25     20um fibronectin discs                    100X                15.8   \n",
       "26     20um fibronectin discs                    100X                15.8   \n",
       "27     20um fibronectin discs                    100X                15.8   \n",
       "28     20um fibronectin discs                    100X                15.8   \n",
       "29     20um fibronectin discs                    100X                15.8   \n",
       "30     20um fibronectin discs                    100X                15.8   \n",
       "31     20um fibronectin discs                    100X                15.8   \n",
       "32     20um fibronectin discs                    100X                15.8   \n",
       "33     20um fibronectin discs                    100X                15.8   \n",
       "34     20um fibronectin discs                    100X                15.8   \n",
       "35     20um fibronectin discs                    100X                15.8   \n",
       "36     20um fibronectin discs                    100X                15.8   \n",
       "37     20um fibronectin discs                    100X                15.8   \n",
       "38     20um fibronectin discs                    100X                15.8   \n",
       "39     20um fibronectin discs                    100X                15.8   \n",
       "40     20um fibronectin discs                    100X                15.8   \n",
       "41     20um fibronectin discs                    100X                15.8   \n",
       "42     20um fibronectin discs                    100X                15.8   \n",
       "43     20um fibronectin discs                    100X                15.8   \n",
       "44     20um fibronectin discs                    100X                15.8   \n",
       "45     20um fibronectin discs                    100X                15.8   \n",
       "46     20um fibronectin discs                    100X                15.8   \n",
       "47     20um fibronectin discs                    100X                15.8   \n",
       "48     20um fibronectin discs                    100X                15.8   \n",
       "49     20um fibronectin discs                    100X                15.8   \n",
       "50     20um fibronectin discs                    100X                15.8   \n",
       "51     20um fibronectin discs                    100X                15.8   \n",
       "52     20um fibronectin discs                    100X                15.8   \n",
       "\n",
       "   objective immersion  optical index correction  magnetic field correction  \\\n",
       "0                  oil                     0.875                      1.150   \n",
       "1                  oil                     0.875                      1.150   \n",
       "2                  oil                     0.875                      1.150   \n",
       "3                  oil                     0.875                      1.150   \n",
       "4                  oil                     0.875                      1.150   \n",
       "5                  oil                     0.875                      1.150   \n",
       "6                  oil                     0.875                      1.150   \n",
       "7                  oil                     0.875                      1.230   \n",
       "8                  oil                     0.875                      1.230   \n",
       "9                  oil                     0.875                      1.230   \n",
       "10                 oil                     0.875                      1.230   \n",
       "11                 oil                     0.875                      1.230   \n",
       "12                 oil                     0.875                      1.230   \n",
       "13                 oil                     0.875                      1.230   \n",
       "14                 oil                     0.875                      1.200   \n",
       "15                 oil                     0.875                      1.200   \n",
       "16                 oil                     0.875                      1.100   \n",
       "17                 oil                     0.875                      1.100   \n",
       "18                 oil                     0.875                      1.100   \n",
       "19                 oil                     0.875                      1.260   \n",
       "20                 oil                     0.875                      1.260   \n",
       "21                 oil                     0.875                      1.120   \n",
       "22                 oil                     0.875                      1.120   \n",
       "23                 oil                     0.875                      1.150   \n",
       "24                 oil                     0.875                      1.150   \n",
       "25                 oil                     0.875                      1.150   \n",
       "26                 oil                     0.875                      1.150   \n",
       "27                 oil                     0.875                      1.150   \n",
       "28                 oil                     0.875                      1.150   \n",
       "29                 oil                     0.875                      1.150   \n",
       "30                 oil                     0.875                      1.150   \n",
       "31                 oil                     0.875                      1.100   \n",
       "32                 oil                     0.875                      1.100   \n",
       "33                 oil                     0.875                      1.100   \n",
       "34                 oil                     0.875                      1.100   \n",
       "35                 oil                     0.875                      1.100   \n",
       "36                 oil                     0.875                      1.100   \n",
       "37                 oil                     0.875                      1.100   \n",
       "38                 oil                     0.875                      1.100   \n",
       "39                 oil                     0.875                      1.100   \n",
       "40                 oil                     0.875                      1.100   \n",
       "41                 oil                     0.875                      1.095   \n",
       "42                 oil                     0.875                      1.110   \n",
       "43                 oil                     0.875                      1.110   \n",
       "44                 oil                     0.875                      1.110   \n",
       "45                 oil                     0.875                      1.110   \n",
       "46                 oil                     0.875                      1.110   \n",
       "47                 oil                     0.875                      1.102   \n",
       "48                 oil                     0.875                      1.140   \n",
       "49                 oil                     0.875                      1.112   \n",
       "50                 oil                     0.875                      1.112   \n",
       "51                 oil                     0.875                      1.150   \n",
       "52                 oil                     0.875                      1.154   \n",
       "\n",
       "    ... bead diameter beads bright spot delta normal field ramp field  \\\n",
       "0   ...       DEFAULT                       0            5       3_40   \n",
       "1   ...          4503                       0           10       3_40   \n",
       "2   ...          4503                       0           10       3_40   \n",
       "3   ...          4503                       0           10       3_40   \n",
       "4   ...          4503                       0           10       3_40   \n",
       "5   ...          4503                       0           10       3_40   \n",
       "6   ...          4503                       0           10       3_40   \n",
       "7   ...          4503                       0            5       3_40   \n",
       "8   ...          4503                       0            5       3_40   \n",
       "9   ...          4503                       0            5       3_40   \n",
       "10  ...          4503                       0            5       3_40   \n",
       "11  ...          4503                       0            5       3_40   \n",
       "12  ...          4503                       0            5       3_40   \n",
       "13  ...          4503                       0            5       3_40   \n",
       "14  ...          4503                       0            5       <NA>   \n",
       "15  ...          4503                       0            5       <NA>   \n",
       "16  ...          4503                       0            5       <NA>   \n",
       "17  ...          4503                       0            5       <NA>   \n",
       "18  ...          4503                       0            5       <NA>   \n",
       "19  ...          4503                       0            5       <NA>   \n",
       "20  ...          4503                       0            5       <NA>   \n",
       "21  ...          4503                       0            5       <NA>   \n",
       "22  ...          4503                       0            5       <NA>   \n",
       "23  ...          4503                       0            5       <NA>   \n",
       "24  ...          4503                       0            5       <NA>   \n",
       "25  ...          4503                       0            5       <NA>   \n",
       "26  ...          4503                       0            5       <NA>   \n",
       "27  ...          4503                       0            5       3_40   \n",
       "28  ...          4503                       0            5       3_40   \n",
       "29  ...          4503                       0            5       3_40   \n",
       "30  ...          4503                       0            5       3_40   \n",
       "31  ...          4503                       0            5       3_40   \n",
       "32  ...          4503                       0            5       3_40   \n",
       "33  ...          4503                       0            5       3_40   \n",
       "34  ...          4503                       0            5       3_40   \n",
       "35  ...     4503_2691                     400            5       3_40   \n",
       "36  ...     2691_4503                     400            5       3_40   \n",
       "37  ...     2691_2691                       0            5       3_40   \n",
       "38  ...     2691_2691                       0            5       3_40   \n",
       "39  ...     4503_2691                     400            5       3_40   \n",
       "40  ...     4503_4503                       0            5       3_40   \n",
       "41  ...          4503                       0            5       3_40   \n",
       "42  ...          4503                       0            5       3_40   \n",
       "43  ...          4503                       0            5       3_40   \n",
       "44  ...          4503                       0            5       3_40   \n",
       "45  ...          4503                       0            5       3_40   \n",
       "46  ...          4503                       0            5       3_40   \n",
       "47  ...          4503                       0            5       3_40   \n",
       "48  ...          4503                       0            5       3_40   \n",
       "49  ...          4503                       0            5       3_40   \n",
       "50  ...          4503                       0            5       3_40   \n",
       "51  ...          4503                       0            5       3_40   \n",
       "52  ...          4503                       0            5       3_40   \n",
       "\n",
       "    compression duration  with fluo images normal field multi images  \\\n",
       "0                     1s             False                         3   \n",
       "1                     1s             False                         3   \n",
       "2                     1s             False                         3   \n",
       "3                     1s             False                         3   \n",
       "4                     1s             False                         3   \n",
       "5                     1s             False                         3   \n",
       "6                     1s             False                         3   \n",
       "7                     1s             False                         3   \n",
       "8                     1s              True                         3   \n",
       "9                     1s              True                         3   \n",
       "10                    1s              True                         3   \n",
       "11                    1s              True                         3   \n",
       "12                    1s              True                         3   \n",
       "13                    1s              True                         3   \n",
       "14                  <NA>              True                         3   \n",
       "15                  <NA>              True                         3   \n",
       "16                  <NA>             False                         3   \n",
       "17                  <NA>             False                         3   \n",
       "18                  <NA>             False                         3   \n",
       "19                  <NA>             False                         3   \n",
       "20                  <NA>             False                         3   \n",
       "21                  <NA>              True                         3   \n",
       "22                  <NA>              True                         3   \n",
       "23                  <NA>              True                         3   \n",
       "24                  <NA>              True                         3   \n",
       "25                  <NA>              True                         3   \n",
       "26                  <NA>              True                         3   \n",
       "27                    1s              True                         3   \n",
       "28                    1s              True                         3   \n",
       "29                    1s              True                         3   \n",
       "30                    1s             False                         3   \n",
       "31                    1s              True                         3   \n",
       "32                    1s              True                         3   \n",
       "33                    1s              True                         3   \n",
       "34                    1s              True                         3   \n",
       "35                    1s              True                         3   \n",
       "36                    1s             False                         3   \n",
       "37                    1s             False                         3   \n",
       "38                    1s             False                         3   \n",
       "39                    1s             False                         3   \n",
       "40                    1s             False                         3   \n",
       "41                    1s             False                         3   \n",
       "42                    1s             False                         3   \n",
       "43                    1s             False                         3   \n",
       "44                    1s             False                         3   \n",
       "45                    1s              True                         3   \n",
       "46                    1s              True                         3   \n",
       "47                    1s             False                         3   \n",
       "48                    1s             False                         3   \n",
       "49                    1s              True                         3   \n",
       "50                    1s              True                         3   \n",
       "51                    1s              True                         3   \n",
       "52                    1s              True                         3   \n",
       "\n",
       "   loop structure      comments          manipID  \n",
       "0          143_95          <NA>  DEFAULT_DEFAULT  \n",
       "1          143_95          <NA>      20-08-04_M1  \n",
       "2          143_95          <NA>      20-08-04_M2  \n",
       "3          143_95          <NA>      20-08-05_M1  \n",
       "4          143_95          <NA>      20-08-05_M2  \n",
       "5          143_95          <NA>      20-08-07_M1  \n",
       "6          143_95          <NA>      20-08-07_M2  \n",
       "7         169_133          <NA>    21-01-18_M1-1  \n",
       "8       170_133_1          <NA>    21-01-18_M1-2  \n",
       "9       170_133_1          <NA>      21-01-18_M2  \n",
       "10      170_133_1          <NA>      21-01-18_M3  \n",
       "11      170_133_1          <NA>      21-01-21_M1  \n",
       "12      170_133_1          <NA>      21-01-21_M2  \n",
       "13      170_133_1          <NA>      21-01-21_M3  \n",
       "14        298_0_1          <NA>      21-02-10_M1  \n",
       "15        298_0_1          <NA>      21-02-10_M2  \n",
       "16           <NA>  Anumita data      21-02-15_M1  \n",
       "17           <NA>  Anumita data      21-02-15_M2  \n",
       "18           <NA>  Anumita data      21-02-15_M3  \n",
       "19             36          <NA>      20-12-16_M1  \n",
       "20             36          <NA>      20-12-16_M2  \n",
       "21        298_0_1          <NA>      21-03-25_M1  \n",
       "22        298_0_1          <NA>      21-03-25_M2  \n",
       "23        298_0_1          <NA>      21-04-21_M1  \n",
       "24        298_0_1          <NA>      21-04-21_M2  \n",
       "25        298_0_1          <NA>      21-04-23_M1  \n",
       "26        298_0_1          <NA>      21-04-23_M2  \n",
       "27      170_133_1          <NA>      21-04-27_M1  \n",
       "28      170_133_1          <NA>      21-04-27_M2  \n",
       "29        169_133          <NA>      21-04-28_M1  \n",
       "30        169_133          <NA>      21-04-28_M2  \n",
       "31        169_133          <NA>      21-06-16_M1  \n",
       "32        169_133          <NA>      21-06-16_M2  \n",
       "33        169_133          <NA>      21-06-17_M1  \n",
       "34        169_133          <NA>      21-06-17_M2  \n",
       "35        169_133          <NA>      21-05-21_M1  \n",
       "36        169_133          <NA>    21-07-08_M1-1  \n",
       "37        169_133          <NA>    21-07-08_M1-2  \n",
       "38        169_133          <NA>      21-07-08_M2  \n",
       "39        169_133          <NA>      21-07-08_M3  \n",
       "40        169_133          <NA>      21-07-08_M4  \n",
       "41        169_133          <NA>      21-09-01_M1  \n",
       "42        169_133          <NA>      21-09-01_M2  \n",
       "43        169_133          <NA>      21-09-02_M1  \n",
       "44        169_133          <NA>      21-09-02_M2  \n",
       "45      170_133_1          <NA>      21-09-02_M3  \n",
       "46      170_133_1          <NA>      21-09-02_M4  \n",
       "47      170_133_1          <NA>      21-09-08_M1  \n",
       "48      170_133_1          <NA>      21-09-08_M2  \n",
       "49      170_133_1          <NA>      21-09-08_M3  \n",
       "50      170_133_1          <NA>      21-09-08_M4  \n",
       "51      170_133_1          <NA>      21-09-09_M1  \n",
       "52      170_133_1          <NA>      21-09-09_M2  \n",
       "\n",
       "[53 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experimentalDataDir = \"C://Users//josep//Desktop//ActinCortexAnalysis//ExperimentalData\"\n",
    "experimentalDataDir = \"C://Users//JosephVermeil//Desktop//ActinCortexAnalysis//ExperimentalData\"\n",
    "\n",
    "def getExperimentalConditions(save = False):\n",
    "    # Getting the table\n",
    "    experimentalDataFile = 'ExperimentalConditions.csv'\n",
    "    experimentalDataFilePath = os.path.join(experimentalDataDir, experimentalDataFile)\n",
    "    expConditionsDF = pd.read_csv(experimentalDataFilePath, sep=';',header=0)\n",
    "    print('Extracted a table with ' + str(expConditionsDF.shape[0]) + ' lines and ' + str(expConditionsDF.shape[1]) + ' columns.')\n",
    "    \n",
    "    # Cleaning the table\n",
    "    try:\n",
    "        for c in expConditionsDF.columns:\n",
    "            if 'Unnamed' in c:\n",
    "                expConditionsDF = expConditionsDF.drop([c], axis=1)\n",
    "            if '.1' in c:\n",
    "                expConditionsDF = expConditionsDF.drop([c], axis=1)\n",
    "        expConditionsDF = expConditionsDF.convert_dtypes()\n",
    "\n",
    "        listTextColumns = []\n",
    "        for col in expConditionsDF.columns:\n",
    "            try:\n",
    "                if expConditionsDF[col].dtype == 'string':\n",
    "                    listTextColumns.append(col)\n",
    "            except:\n",
    "                aaaa=0\n",
    "                #Ok\n",
    "\n",
    "        expConditionsDF[listTextColumns] = expConditionsDF[listTextColumns].apply(lambda x: x.str.replace(',','.'))\n",
    "\n",
    "        expConditionsDF['scale pixel per um'] = expConditionsDF['scale pixel per um'].astype(float)\n",
    "        try:\n",
    "            expConditionsDF['optical index correction'] = \\\n",
    "                      expConditionsDF['optical index correction'].apply(lambda x: x.split('/')[0]).astype(float) \\\n",
    "                    / expConditionsDF['optical index correction'].apply(lambda x: x.split('/')[1]).astype(float)\n",
    "        except:\n",
    "            print('optical index correction already in ' + str(expConditionsDF['optical index correction'].dtype) + ' type.')\n",
    "\n",
    "        expConditionsDF['magnetic field correction'] = expConditionsDF['magnetic field correction'].astype(float)\n",
    "        expConditionsDF['with fluo images'] = expConditionsDF['with fluo images'].astype(bool)\n",
    "\n",
    "        try:\n",
    "            expConditionsDF['ramp field'] = \\\n",
    "            expConditionsDF['ramp field'].apply(lambda x: [x.split(';')[0], x.split(';')[1]] if not pd.isnull(x) else [])\n",
    "        except:\n",
    "            aaaa=0\n",
    "            #Ok\n",
    "\n",
    "        dateExemple = expConditionsDF.loc[expConditionsDF.index[1],'date']\n",
    "\n",
    "        if re.match(dateFormatExcel, dateExemple):\n",
    "            print('dates corrected')\n",
    "            expConditionsDF.loc[1:,'date'] = expConditionsDF.loc[1:,'date'].apply(lambda x: x.split('/')[0] + '-' + x.split('/')[1] + '-' + x.split('/')[2][2:])        \n",
    "        \n",
    "    except:\n",
    "        print('Unexpected bug with the cleaning step')\n",
    "\n",
    "    if save:\n",
    "        saveName = 'ExperimentalConditions.csv'\n",
    "        savePath = os.path.join(experimentalDataDir, saveName)\n",
    "        expConditionsDF.to_csv(savePath, sep=';')\n",
    "\n",
    "    expConditionsDF['manipID'] = expConditionsDF['date'] + '_' + expConditionsDF['manip']\n",
    "#     reorgaList = np.array([i for i in range(len(expConditionsDF.columns))])\n",
    "#     reorgaList[2] = reorgaList[-1]\n",
    "#     reorgaList[3:] = reorgaList[3:] - np.ones(len(reorgaList)-3)\n",
    "#     expConditionsDF = expConditionsDF[expConditionsDF.columns[reorgaList]]\n",
    "    \n",
    "    return(expConditionsDF)\n",
    "\n",
    "expDf = getExperimentalConditions()\n",
    "\n",
    "expDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c4ddf",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7ad1ee5",
   "metadata": {
    "code_folding": [
     0,
     38,
     85,
     99,
     109
    ]
   },
   "outputs": [],
   "source": [
    "def findInfosInFileName(f, infoType):\n",
    "    \"\"\"\n",
    "    Return a given type of info from a file name.\n",
    "    Inputs : f (str), the file name.\n",
    "             infoType (str), the type of info wanted.\n",
    "             infoType can be equal to : \n",
    "             * 'M', 'P', 'C' -> will return the number of manip (M), well (P), or cell (C) in a cellID.\n",
    "             ex : if f = '21-01-18_M2_P1_C8.tif' and infoType = 'C', the function will return 8.\n",
    "             * 'manipID'     -> will return the full manip ID.\n",
    "             ex : if f = '21-01-18_M2_P1_C8.tif' and infoType = 'manipID', the function will return '21-01-18_M2'.\n",
    "             * 'cellID'     -> will return the full cell ID.\n",
    "             ex : if f = '21-01-18_M2_P1_C8.tif' and infoType = 'cellID', the function will return '21-01-18_M2_P1_C8'.\n",
    "    \"\"\"\n",
    "    if infoType in ['M', 'P', 'C']:\n",
    "        acceptedChar = [str(i) for i in range(10)] + ['.', '-']\n",
    "        string = '_' + infoType\n",
    "        iStart = re.search(string, f).end()\n",
    "        i = iStart\n",
    "        infoString = '' + f[i]\n",
    "        while f[i+1] in acceptedChar and i < len(f)-1:\n",
    "            i += 1\n",
    "            infoString += f[i]\n",
    "    \n",
    "    elif infoType == 'manipID':\n",
    "        datePos = re.search(r\"[\\d]{1,2}-[\\d]{1,2}-[\\d]{2}\", f)\n",
    "        date = f[datePos.start():datePos.end()]\n",
    "        manip = 'M' + findInfosInFileName(f, 'M')\n",
    "        infoString = date + '_' + manip\n",
    "        \n",
    "    elif infoType == 'cellID':\n",
    "        datePos = re.search(r\"[\\d]{1,2}-[\\d]{1,2}-[\\d]{2}\", f)\n",
    "        date = f[datePos.start():datePos.end()]\n",
    "        infoString = date + '_' + 'M' + findInfosInFileName(f, 'M') + \\\n",
    "                            '_' + 'P' + findInfosInFileName(f, 'P') + \\\n",
    "                            '_' + 'C' + findInfosInFileName(f, 'C')\n",
    "    \n",
    "    return(infoString)\n",
    "\n",
    "def isFileOfInterest(f, manips, wells, cells):\n",
    "    \"\"\"\n",
    "    Determine if a file f correspond to the given criteria.\n",
    "    More precisely, return a boolean saying if the manip, well and cell number are in the given range.\n",
    "    f is a file name. Each of the fields 'manips', 'wells', 'cells' can be either a number, a list of numbers, or 'all'.\n",
    "    Example : if f = '21-01-18_M2_P1_C8.tif'\n",
    "    * manips = 'all', wells = 'all', cells = 'all' -> the function return True.\n",
    "    * manips = 1, wells = 'all', cells = 'all' -> the function return False.\n",
    "    * manips = [1, 2], wells = 'all', cells = 'all' -> the function return True.\n",
    "    * manips = [1, 2], wells = 2, cells = 'all' -> the function return False.\n",
    "    * manips = [1, 2], wells = 1, cells = [5, 6, 7, 8] -> the function return True.\n",
    "    Note : if manips = 'all', the code will consider that wells = 'all', cells = 'all'.\n",
    "           if wells = 'all', the code will consider that cells = 'all'.\n",
    "           This means you can add filters only in this order : manips > wells > cells.\n",
    "    \"\"\"\n",
    "    test = False\n",
    "    if f.endswith(\".tif\"):\n",
    "        if manips == 'all':\n",
    "            test = True\n",
    "        else:\n",
    "            try:\n",
    "                manips_str = [str(i) for i in manips]\n",
    "            except:\n",
    "                manips_str = [str(manips)]\n",
    "            infoM = findInfosInFileName(f, 'M')\n",
    "            if infoM in manips_str:\n",
    "                if wells == 'all':\n",
    "                    test = True\n",
    "                else:\n",
    "                    try:\n",
    "                        wells_str = [str(i) for i in wells]\n",
    "                    except:\n",
    "                        wells_str = [str(wells)]\n",
    "                    infoP = findInfosInFileName(f, 'P')\n",
    "                    if infoP in wells_str:\n",
    "                        if cells == 'all':\n",
    "                            test = True\n",
    "                        else:\n",
    "                            try:\n",
    "                                cells_str = [str(i) for i in cells]\n",
    "                            except:\n",
    "                                cells_str = [str(cells)]\n",
    "                            infoC = findInfosInFileName(f, 'C')\n",
    "                            if infoC in cells_str:\n",
    "                                test = True\n",
    "    return(test)\n",
    "\n",
    "def compute_cost_matrix(XY1,XY2):\n",
    "    \"\"\"\n",
    "    Compute a custom cost matrix between two arrays of XY positions.\n",
    "    Here the costs are simply the squared distance between each XY positions.\n",
    "    Example : M[2,1] is the sqaured distance between XY1[2] and XY2[1], \n",
    "    which is ((XY2[1,1]-XY1[2,1])**2 + (XY2[1,0]-XY1[2,0])**2)\n",
    "    \"\"\"\n",
    "    N1, N2 = XY1.shape[0],XY2.shape[0]\n",
    "    M = np.zeros((N1, N2))\n",
    "    for i in range(N1):\n",
    "        for j in range(N2):\n",
    "            M[i,j] = (np.sum((XY2[j,:] - XY1[i,:]) ** 2))\n",
    "    return(M)\n",
    "\n",
    "def ui2array(uixy):\n",
    "    \"\"\"\n",
    "    Translate the output of the function plt.ginput() (which are lists of tuples), in a XY array.\n",
    "    \"\"\"\n",
    "    n = len(uixy)\n",
    "    XY = np.zeros((n, 2))\n",
    "    for i in range(n):\n",
    "        XY[i,0], XY[i,1] = uixy[i][0], uixy[i][1]\n",
    "    return(XY)\n",
    "\n",
    "def getROI(roiSize, x0, y0, nx, ny):\n",
    "    \"\"\"\n",
    "    Return coordinates of top left (x1, y1) and bottom right (x2, y2) corner of a ROI, \n",
    "    and a boolean validROI that says if the ROI exceed the limit of the image.\n",
    "    Inputs : \n",
    "    - roiSize, the width of the (square) ROI.\n",
    "    - x0, y0, the position of the central pixel.\n",
    "    - nx, ny, the size of the image.\n",
    "    Note : the ROI is done so that the final width (= height) of the ROI will always be an odd number.\n",
    "    \"\"\"\n",
    "    roiSize += roiSize%2\n",
    "    x1 = int(np.floor(x0) - roiSize*0.5) - 1\n",
    "    x2 = int(np.floor(x0) + roiSize*0.5)\n",
    "    y1 = int(np.floor(y0) - roiSize*0.5) - 1\n",
    "    y2 = int(np.floor(y0) + roiSize*0.5)\n",
    "    if min([x1,nx-x2,y1,ny-y2]) < 0:\n",
    "        validROI = False\n",
    "    else:\n",
    "        validROI = True\n",
    "    return(x1, y1, x2, y2, validROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caf4a4d4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Test utility functions\n",
    "\n",
    "# a = 'aa12-32-12AZF34_M2'\n",
    "# datePos = re.search(r\"[\\d]{1,2}-[\\d]{1,2}-[\\d]{2}\", a)\n",
    "# a[datePos.start():datePos.end()]\n",
    "# findInfosInFileName(a, 'manipID')\n",
    "# a = 'aaa_bbb'\n",
    "# a.split('_')\n",
    "# s = '21-04-27_M1_P1_C4_R40_disc20um_wFluo'\n",
    "# findInfosInFileName(s, 'cellID')\n",
    "# [(331.26256664936864, 258.949997248057), (403.98986101188945, 258.9821671859072)]\n",
    "\n",
    "# XY1 = np.array([[1,2],[4,2],[7,2]])\n",
    "# XY2 = np.array([[4.2,1.9],[7.3,2.4],[10.5,2.9]])\n",
    "# M = compute_cost_matrix(XY1,XY2)\n",
    "# row_ind, col_ind = linear_sum_assignment(M)\n",
    "# for i in range(len(row_ind)):\n",
    "#     e1 = XY1[row_ind[i]]\n",
    "#     e2 = XY2[col_ind[i]]\n",
    "#     print(str(e1) + ' match with ' + str(e2))\n",
    "    \n",
    "# XY1 = np.array([[1,2]])\n",
    "# XY2 = np.array([[4.2,1.9],[7.3,2.4],[10.5,2.9]])\n",
    "# M = compute_cost_matrix(XY1,XY2)\n",
    "# row_ind, col_ind = linear_sum_assignment(M)\n",
    "# for i in range(len(row_ind)):\n",
    "#     e1 = XY1[row_ind[i]]\n",
    "#     e2 = XY2[col_ind[i]]\n",
    "#     print(str(e1) + ' match with ' + str(e2))\n",
    "# print(M[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378e505a",
   "metadata": {},
   "source": [
    "### Tracker Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f919c7f",
   "metadata": {
    "code_folding": [
     213,
     283
    ]
   },
   "outputs": [],
   "source": [
    "class PincherTimeLapse:\n",
    "    \"\"\"\n",
    "    This class is initialised for each new .tif file analysed.\n",
    "    \n",
    "    It requires the following inputs :\n",
    "    > I : the timelapse analysed.\n",
    "    > cellID : the id of the cell currently analysed.\n",
    "    > manipDict : the line of the experimental data table that concerns the current experiment.\n",
    "    > NB : the number of beads of interest that will be tracked.\n",
    "    \n",
    "    It contains:\n",
    "    * data about the 3D image I (dimensions = time, height, width),\n",
    "    * a list of Frame objects listFrames, 1 per frame in the timelapse,\n",
    "    * a list of Trajectory objects listTrajectories, 1 per bead of interest (Boi) in the timelapse,\n",
    "    * a dictionnary dictLog, saving the status of each frame (see below) \n",
    "                             and all of the user inputs (points and clicks) during the tracking,\n",
    "    * a pandas DataFrame detectBeadsResult, that contains the raw output of the bead tracking,\n",
    "    * metadata about the experiment (cellID, expType, loopStruct, loop_totalSize, loop_rampSize, \n",
    "                                        loop_excludedSize, nLoop, Nuplet, blackFramesPerLoop).\n",
    "    \n",
    "    When a PincherTimeLapse is initialised, most of these variables are initialised to zero values.\n",
    "    In order to compute the different fields, the following methods should be called in this order:\n",
    "    - ptl.checkIfBlackFrames() : detect if there are black images at the end of each loop in the time lapse and \n",
    "                                 classify them as not relevant by filling the appropriate fields.\n",
    "    - ptl.saveFluoAside() : save the fluo images in an other folder and classify them as not relevant \n",
    "                            for the rest of the image analysis.\n",
    "    - ptl.determineFramesStatus() : fill the status and status_2 column of the dictLog.\n",
    "                                    in the status field: -1 means excluded ; 0 means ramp ; >0 means *position in* the n-uplet\n",
    "                                    in the status_2 field: -1 means excluded ; 0 means ramp ; >0 means *number of* the n-uplet\n",
    "    - ptl.computeThreshold() : \n",
    "    - ptl.makeFramesList() :\n",
    "    - ptl.detectBeads() :\n",
    "    - ptl.findBestStd() :\n",
    "    - ptl.buildTrajectories() :\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, I, cellID, manipDict, NB = 2):\n",
    "        nS, ny, nx = I.shape[0], I.shape[1], I.shape[2]\n",
    "        self.I = I\n",
    "        self.threshold = 0\n",
    "        self.NB = NB\n",
    "        self.nx = nx\n",
    "        self.ny = ny\n",
    "        self.nS = nS\n",
    "        self.listFrames = []\n",
    "        self.listTrajectories = []\n",
    "        self.dictLog = {'Slice' : np.array([i+1 for i in range(nS)]),\n",
    "                        'Status' : np.zeros(nS, dtype = int),  # in the status field: -1 means excluded ; 0 means ramp ; >0 means position in the n-uplet\n",
    "                        'Status_2' : np.zeros(nS, dtype = int), # in the status_2 field: -1 means excluded ; 0 means ramp ; >0 means number of the n-uplet\n",
    "#                         Deprecated fields:\n",
    "#                         'Fluo' : np.zeros(nS, dtype = bool),\n",
    "#                         'Black' : np.zeros(nS, dtype = bool),\n",
    "                        'UI' : np.zeros(nS, dtype = bool),\n",
    "                        'UILog' : np.array(['' for i in range(nS)], dtype = '<U8'),\n",
    "                        'UIxy' : np.zeros((nS,NB,2), dtype = int)}\n",
    "        \n",
    "        self.detectBeadsResult = pd.DataFrame(\n",
    "            {'Area' : [], 'StdDev' : [], 'XM' : [], 'YM' : [], 'Slice' : []})\n",
    "        \n",
    "        self.cellID = cellID\n",
    "        self.expType = manipDict['experimentType']\n",
    "#         self.wFluo = bool(manipDict['with fluo images'])\n",
    "        \n",
    "        loopStruct = manipDict['loop structure'].split('_')\n",
    "        self.loop_totalSize = int(loopStruct[0])\n",
    "        if self.expType == 'compressions':\n",
    "            self.loop_rampSize = int(loopStruct[1])\n",
    "        else:\n",
    "            self.loop_rampSize = 0\n",
    "        if len(loopStruct) == 3: # This 3rd part of the 'loopStruct' field is the nb of frames at the end\n",
    "        # of each loop which are not part of the main analysis and should be excluded. Typically fluo images.\n",
    "            self.loop_excludedSize = int(loopStruct[2])\n",
    "        else:\n",
    "            self.loop_excludedSize = 0\n",
    "        self.nLoop = int(np.round(nS/self.loop_totalSize))\n",
    "        self.Nuplet = manipDict['normal field multi images']\n",
    "        self.blackFramesPerLoop = np.zeros(self.nLoop)\n",
    "        \n",
    "    def checkIfBlackFrames(self):\n",
    "        for i in range(self.nLoop):\n",
    "            j = ((i+1)*self.loop_totalSize) - 1\n",
    "            checkSum = np.sum(self.I[j])\n",
    "            while checkSum == 0:\n",
    "#                 self.dictLog['Black'][j] = True\n",
    "                self.dictLog['Status'][j] = -1\n",
    "                self.dictLog['Status_2'][j] = -1\n",
    "                self.blackFramesPerLoop[i] += 1\n",
    "                j -= 1\n",
    "                checkSum = np.sum(self.I[j])\n",
    "              \n",
    "    def saveFluoAside(self, fluoDirPath = ''):\n",
    "        if self.loop_excludedSize == 1:\n",
    "#             if not os.path.exists(fluoDirPath):\n",
    "#                 os.makedirs(fluoDirPath)\n",
    "            for i in range(self.nLoop):\n",
    "                j = int(((i+1)*self.loop_totalSize) - 1 - self.blackFramesPerLoop[i])\n",
    "#                 self.dictLog['Fluo'][j] = True\n",
    "                self.dictLog['Status'][j] = -1\n",
    "                self.dictLog['Status_2'][j] = -1\n",
    "                \n",
    "    def determineFramesStatus(self):\n",
    "        N0 = self.loop_totalSize\n",
    "        Nramp0 = self.loop_rampSize\n",
    "        Nexclu = self.loop_excludedSize\n",
    "        nUp = self.Nuplet\n",
    "        N = N0 - Nexclu\n",
    "        Nct = N - Nramp0\n",
    "        i_nUp = 1\n",
    "        for i in range(self.nLoop):\n",
    "            jstart = int(i*N0)\n",
    "            if Nramp0 == 0:\n",
    "                for j in range(N):\n",
    "                    self.dictLog['Status'][jstart + j] = 1 + j%self.Nuplet\n",
    "                    self.dictLog['Status_2'][j] = i_nUp + j//self.Nuplet\n",
    "            else:\n",
    "                Nramp = Nramp0-self.blackFramesPerLoop[i]\n",
    "                for j in range(Nct//2):\n",
    "                    self.dictLog['Status'][jstart + j] = 1 + j%self.Nuplet\n",
    "                    self.dictLog['Status_2'][jstart + j] = i_nUp + j//self.Nuplet\n",
    "                i_nUp = max(self.dictLog['Status_2']) + 1\n",
    "                jstart += int(Nct//2 + Nramp)\n",
    "                for j in range(Nct//2):\n",
    "                    self.dictLog['Status'][jstart + j] = 1 + j%self.Nuplet\n",
    "                    self.dictLog['Status_2'][jstart + j] = i_nUp + j//self.Nuplet\n",
    "                i_nUp = max(self.dictLog['Status_2']) + 1\n",
    "                \n",
    "    def saveLog(self, display = 1, save = False, path = ''):\n",
    "        dL = {}\n",
    "        dL['Slice'], dL['Status'], dL['Status_2'] = \\\n",
    "            self.dictLog['Slice'], self.dictLog['Status'], self.dictLog['Status_2']\n",
    "#         dL['Fluo'], dL['Black'] = \\\n",
    "#             self.dictLog['Fluo'], self.dictLog['Black']\n",
    "        dL['UI'], dL['UILog'] = \\\n",
    "            self.dictLog['UI'], self.dictLog['UILog']\n",
    "        for i in range(self.NB):\n",
    "            dL['UIx'+str(i+1)] = self.dictLog['UIxy'][:,i,0]\n",
    "            dL['UIy'+str(i+1)] = self.dictLog['UIxy'][:,i,1]\n",
    "        dfLog = pd.DataFrame(dL)\n",
    "        if display == 1:\n",
    "            print('\\n\\n* Initialized Log Table:\\n')\n",
    "            print(dfLog)\n",
    "        if display == 2:\n",
    "            print('\\n\\n* Filled Log Table:\\n')\n",
    "            print(dfLog[dfLog['UI']])\n",
    "        if save:\n",
    "            dfLog.to_csv(path, sep='\\t')\n",
    "        \n",
    "    def importLog(self, path):\n",
    "        dfLog = pd.read_csv(path, sep='\\t')\n",
    "        dL = dfLog.to_dict()\n",
    "        self.dictLog['Slice'], self.dictLog['Status'], self.dictLog['Status_2'] = \\\n",
    "            dfLog['Slice'].values, dfLog['Status'].values, dfLog['Status_2'].values\n",
    "#         self.dictLog['Fluo'], self.dictLog['Black'] = \\\n",
    "#             dfLog['Fluo'].values, dfLog['Black'].values\n",
    "        self.dictLog['UI'], self.dictLog['UILog'] = \\\n",
    "            dfLog['UI'].values, dfLog['UILog'].values\n",
    "        for i in range(self.NB):\n",
    "            xkey, ykey = 'UIx'+str(i+1), 'UIy'+str(i+1)\n",
    "            self.dictLog['UIxy'][:,i,0] = dfLog[xkey].values\n",
    "            self.dictLog['UIxy'][:,i,1] = dfLog[ykey].values\n",
    "        \n",
    "    def computeThreshold(self, method = 'otsu'):\n",
    "        # TBC\n",
    "#         factorT = 0.8*(self.D == 4.5) + 0.6*(self.D == 2.7)\n",
    "        factorT = 0.35\n",
    "        threshold = factorT*filters.threshold_otsu(self.I)\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def testThresholding(self):\n",
    "        I_test = self.I[self.nS//2]\n",
    "        I_thresh = I_test > self.threshold\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        ax.imshow(I_thresh, cmap = 'gray')\n",
    "        fig.show()\n",
    "        \n",
    "    def makeFramesList(self):\n",
    "        for i in range(self.nS):\n",
    "            status = self.dictLog['Status'][i]\n",
    "            status_2 = self.dictLog['Status_2'][i]\n",
    "            if self.dictLog['Status'][i] >= 0:\n",
    "                self.listFrames.append(Frame(self.I[i], i, self.NB, self.threshold, self.Nuplet, status, status_2))\n",
    "    \n",
    "    def detectBeads(self, resFileImported, display = False):\n",
    "        for frame in self.listFrames: #[:3]:\n",
    "            if not resFileImported:\n",
    "                frame.detectBeads()\n",
    "                self.detectBeadsResult = pd.concat([self.detectBeadsResult, frame.resDf])\n",
    "            else:\n",
    "                resDf = self.detectBeadsResult.loc[self.detectBeadsResult['Slice'] == frame.iS+1]\n",
    "                frame.resDf = resDf\n",
    "                \n",
    "            frame.makeListBeads()\n",
    "            \n",
    "        if not resFileImported:\n",
    "            self.detectBeadsResult = self.detectBeadsResult.convert_dtypes()\n",
    "            self.detectBeadsResult.reset_index(inplace=True)\n",
    "            self.detectBeadsResult.drop(['index'], axis = 1, inplace=True)\n",
    "        \n",
    "        if display:\n",
    "            print('\\n\\n* Detected Beads Result:\\n')\n",
    "            print(self.detectBeadsResult)\n",
    "\n",
    "        \n",
    "#     def makeBeadsDetectResult(self, save=False, path=''):\n",
    "#         df = pd.DataFrame({'Area' : [], 'StdDev' : [], 'XM' : [], 'YM' : [], 'Slice' : []})\n",
    "#         df = pd.concat([pd.DataFrame(frame.resDict) for frame in self.listFrames])\n",
    "#         df = df.reset_index()\n",
    "#         df = df.drop(['index'], axis = 1) # To be checked\n",
    "#         if save:\n",
    "#             df.to_csv(path, sep=';')\n",
    "#         return(df)\n",
    "\n",
    "    def saveBeadsDetectResult(self, path=''):\n",
    "        self.detectBeadsResult.to_csv(path, sep='\\t')\n",
    "    \n",
    "    def importBeadsDetectResult(self, path=''):\n",
    "        df = pd.read_csv(path, sep='\\t')\n",
    "        for c in df.columns:\n",
    "            if 'Unnamed' in c:\n",
    "                df.drop([c], axis = 1, inplace=True)\n",
    "        self.detectBeadsResult = df\n",
    "        \n",
    "    def findBestStd_V0(self):\n",
    "        \"\"\"\n",
    "        This ugly function is my best attempt to implement sth very simple in a robust way.\n",
    "        In the 'status' field, -1 means excluded image, 0 means image that isn't part of a N-uplet of images, and k>0 means position in the N-uplet of images.\n",
    "        For each image in the N-uplet, I want to reconsititute this N-uplet (meaning the list of Nuplet consecutive images numbered from 1 to Nuplet, minus the images eventually with no beads detected).\n",
    "        Then for each N-uplet of images, i want to find the max standard deviation and report its position because it's for the max std that the X and Y detection is the most precise.\n",
    "        An exemple: with these inputs:\n",
    "        Nuplet = 3\n",
    "        status = [1,2,3,0,0,0,1,2, 3, 1, 2, 3, 1, 2]\n",
    "            iS = [0,1,2,3,4,5,6,7,11,12,13,14,15,16]\n",
    "           std = [1,5,9,5,5,5,1,5, 8, 2, 6, 9, 2, 6]\n",
    "        The function will return bestStd, a list of boolean with the same length.\n",
    "        Where status = 0, bestStd = True (the image is not part of a N-uplet, thus it need to be analysed regardless of its std).\n",
    "        Where satus > 0, the function will cut the lists in N-uplet of max size 3:\n",
    "        status -> [1,2,3] ; [1,2] ; [ 3] ; [ 1, 2, 3] ; [ 1, 2]\n",
    "            iS -> [0,1,2] ; [6,7] ; [11] ; [12,13,14] ; [15,16]\n",
    "           std -> [1,5,9] ; [1,5] ; [ 8] ; [ 2, 6, 9] ; [ 2, 6]\n",
    "             i -> [0,1,2] ; [6,7] ; [ 8] ; [ 9,10,11] ; [12,13]\n",
    "        and then will find the best std in each of those fragment and put a True at that position (list 'i') in bestStd, so in this example, at i = 2, 7, 8, 11 ,13\n",
    "        So the output is: bestStd = [False, False, True, True, True, True, False, True, True, False, False, True, False, True]\n",
    "        \"\"\"\n",
    "        \n",
    "        Nuplet = self.Nuplet\n",
    "        status = self.listTrajectories[0].dict['Status']\n",
    "        iS = self.listTrajectories[0].dict['iS']\n",
    "        nT = self.listTrajectories[0].nT\n",
    "        std = np.zeros(nT)\n",
    "        for i in range(0,self.NB):\n",
    "            std += np.array(self.listTrajectories[i].dict['StdDev'])\n",
    "        \n",
    "        bestStd = np.zeros(nT, dtype = bool)\n",
    "\n",
    "        current_Nup_status = []\n",
    "        current_Nup_iS = []\n",
    "        current_Nup_std = []\n",
    "        current_Nup_i = []\n",
    "        for i in range(nT):\n",
    "            if status[i] == 0:\n",
    "                bestStd[i] = True\n",
    "            else:\n",
    "                if len(current_Nup_i) == 0:\n",
    "                    current_Nup_status = [status[i]]\n",
    "                    current_Nup_iS = [iS[i]]\n",
    "                    current_Nup_std = [std[i]]\n",
    "                    current_Nup_i = [i]\n",
    "                else:\n",
    "                    if status[i] > current_Nup_status[-1] and (iS[i]-current_Nup_iS[-1]) < Nuplet:\n",
    "                        current_Nup_status.append(status[i])\n",
    "                        current_Nup_iS.append(iS[i])\n",
    "                        current_Nup_std.append(std[i])\n",
    "                        current_Nup_i.append(i)\n",
    "                    else:\n",
    "    #                     print(current_Nup_status, current_Nup_iS, current_Nup_std, current_Nup_i)\n",
    "                        i_bestStdInCurrentNuplet = int(np.argmax(np.array(current_Nup_std)))\n",
    "    #                     print(i_bestStdInCurrentNuplet)\n",
    "                        i_bestStd = int(current_Nup_i[i_bestStdInCurrentNuplet])\n",
    "                        bestStd[i_bestStd] = True\n",
    "                        # then:\n",
    "                        current_Nup_status = [status[i]]\n",
    "                        current_Nup_iS = [iS[i]]\n",
    "                        current_Nup_std = [std[i]]\n",
    "                        current_Nup_i = [i]\n",
    "\n",
    "        # Need to do it one last time at the end\n",
    "        i_bestStdInCurrentNuplet = int(np.argmax(np.array(current_Nup_std)))\n",
    "        i_bestStd = int(current_Nup_i[i_bestStdInCurrentNuplet])\n",
    "        bestStd[i_bestStd] = True\n",
    "\n",
    "        return(bestStd)\n",
    "    \n",
    "    def findBestStd(self):\n",
    "        \"\"\"\n",
    "        Simpler and better than findBestStd_V0 using the status_2 column of the dictLog.\n",
    "        ---\n",
    "        For each frame of the timelapse that belongs to a N-uplet, I want to reconsititute this N-uplet \n",
    "        (meaning the list of 'Nup' consecutive images numbered from 1 to Nup, \n",
    "        minus the images eventually with no beads detected).\n",
    "        Then for each N-uplet of images, i want to find the max standard deviation \n",
    "        and report its position because it's for the max std that the X and Y detection is the most precise.\n",
    "        ---\n",
    "        This is very easy thanks to the 'status_2', because it contains a different number for each N-Uplet.\n",
    "        \"\"\"\n",
    "        \n",
    "        Nup = self.Nuplet\n",
    "        nT = self.listTrajectories[0].nT\n",
    "        status_2 = self.listTrajectories[0].dict['Status_2']\n",
    "        std = np.zeros(nT)\n",
    "        for i in range(self.NB):\n",
    "            std += np.array(self.listTrajectories[i].dict['StdDev'])\n",
    "        \n",
    "        bestStd = np.zeros(nT, dtype = bool)\n",
    "        i = 0\n",
    "        while i < nT:\n",
    "            if status_2[i] == 0:\n",
    "                bestStd[i] = True\n",
    "                i += 1\n",
    "            elif status_2[i] > 0:\n",
    "                s2 = status_2[i]\n",
    "                L = [i]\n",
    "                j = 0\n",
    "                while i+j < nT-1 and status_2[i+j+1] == s2: # lazy evaluation of booleans\n",
    "                    j += 1\n",
    "                    L.append(i+j)\n",
    "                print(L)    \n",
    "                loc_std = std[L]\n",
    "                i_bestStd = i + int(np.argmax(loc_std))\n",
    "                bestStd[i_bestStd] = True\n",
    "                L = []\n",
    "                i = i + j + 1\n",
    "\n",
    "        return(bestStd)\n",
    "        \n",
    "    def buildTrajectories(self):\n",
    "        \"\"\"\n",
    "        One of the main functions.\n",
    "        \"\"\"\n",
    "        # NB: 'iF': index in a list of Frames ; \n",
    "        # 'iB': index in a list of Beads or a list of Trajectories ; \n",
    "        # 'iS': index of the slice in the image I\n",
    "        # Boi refers to the 'Beads of interest', ie the beads that are being tracked\n",
    "        \n",
    "        init_iF = 0\n",
    "        init_ok = False\n",
    "        while not init_ok:\n",
    "            init_iS = self.listFrames[init_iF].iS\n",
    "            if not self.dictLog['UI'][init_iS]:\n",
    "                self.listFrames[init_iF].show()\n",
    "                mngr = plt.get_current_fig_manager()\n",
    "                mngr.window.setGeometry(700,100,1000, 800)\n",
    "                QA = pyautogui.confirm(\n",
    "                    text='Can you point the beads of interest\\nin the image ' + str(init_iS + 1) + '?',\n",
    "                    title='Initialise tracker', \n",
    "                    buttons=['Yes', 'Next Frame', 'Quit'])\n",
    "                if QA == 'Yes':\n",
    "                    init_ok = True\n",
    "                    ui = plt.ginput(2, timeout=0)\n",
    "                    uiXY = ui2array(ui)\n",
    "                    fig = plt.gcf()\n",
    "                    plt.close(fig)\n",
    "                    self.dictLog['UI'][init_iS] = True\n",
    "                    self.dictLog['UILog'][init_iS] = 'init_' + QA\n",
    "                    self.dictLog['UIxy'][init_iS] = uiXY\n",
    "                elif QA == 'Next Frame':\n",
    "                    fig = plt.gcf()\n",
    "                    plt.close(fig)\n",
    "                    self.dictLog['UI'][init_iS] = True\n",
    "                    self.dictLog['UILog'][init_iS] = 'init_' + QA\n",
    "                    init_iF += 1\n",
    "                else:\n",
    "                    fig = plt.gcf()\n",
    "                    plt.close(fig)\n",
    "                    return('Bug')\n",
    "            else:\n",
    "                QA = self.dictLog['UILog'][init_iS]\n",
    "                if QA == 'init_Yes':\n",
    "                    init_ok = True\n",
    "                    uiXY = self.dictLog['UIxy'][init_iS]\n",
    "                elif QA == 'Next Frame':\n",
    "                    init_iF += 1\n",
    "                else:\n",
    "                    aa\n",
    "        \n",
    "        init_BXY = self.listFrames[init_iF].beadsXYarray()\n",
    "        M = compute_cost_matrix(uiXY,init_BXY)\n",
    "        row_ind, col_ind = linear_sum_assignment(M) # row_ind -> clicks / col_ind -> listBeads\n",
    "        # Sort the initial beads to have them ordered by growing x coord.\n",
    "        sortM = np.array([[init_BXY[col_ind[i],0], col_ind[i]] for i in range(len(col_ind))])\n",
    "        sortM = sortM[sortM[:, 0].argsort()]\n",
    "        init_iBoi = sortM[:, 1].astype(int)\n",
    "        init_BoiXY = np.array([init_BXY[col_ind[i]] for i in range(len(col_ind))])\n",
    "        \n",
    "        for iB in range(self.NB):\n",
    "            self.listTrajectories.append(Trajectory(self.I))\n",
    "#             self.listTrajectories[iB].seriesBeads.append(self.listFrames[init_iF].listBeads[col_ind[iB]])\n",
    "#             self.listTrajectories[iB].pointerBeads.append(init_iBoi[iB])\n",
    "#             self.listTrajectories[iB].series_iS.append(self.listFrames[init_iF].iS)\n",
    "#             self.listTrajectories[iB].seriesXY.append(init_BoiXY[iB].tolist())\n",
    "#             self.listTrajectories[iB].current_iS = self.listFrames[init_iF].iS\n",
    "            #\n",
    "            self.listTrajectories[iB].dict['Bead'].append(self.listFrames[init_iF].listBeads[init_iBoi[iB]])\n",
    "            self.listTrajectories[iB].dict['iF'].append(init_iF)\n",
    "            self.listTrajectories[iB].dict['iS'].append(self.listFrames[init_iF].iS)\n",
    "            self.listTrajectories[iB].dict['iB'].append(init_iBoi[iB])\n",
    "            self.listTrajectories[iB].dict['X'].append(init_BoiXY[iB][0])\n",
    "            self.listTrajectories[iB].dict['Y'].append(init_BoiXY[iB][1])\n",
    "            self.listTrajectories[iB].dict['StdDev'].append(self.listFrames[init_iF].beadsStdDevarray()[init_iBoi[iB]])\n",
    "            self.listTrajectories[iB].dict['Status'].append(self.listFrames[init_iF].status)\n",
    "            self.listTrajectories[iB].dict['Status_2'].append(self.listFrames[init_iF].status_2)\n",
    "            self.listTrajectories[iB].dict['idxCompression'].append(1 * (self.listFrames[init_iF].status == 0))\n",
    "\n",
    "        previous_iF = init_iF\n",
    "        previous_iBoi = init_iBoi\n",
    "        previous_BXY = init_BXY\n",
    "        previous_BoiXY = init_BoiXY\n",
    "        \n",
    "        for iF in range(init_iF+1, len(self.listFrames)):\n",
    "            validFrame = True\n",
    "            \n",
    "            if len(self.listFrames[iF].listBeads) < self.NB:\n",
    "                validFrame = False\n",
    "            \n",
    "            else:\n",
    "                BXY = self.listFrames[iF].beadsXYarray()\n",
    "                M = compute_cost_matrix(previous_BXY,BXY)\n",
    "                row_ind, col_ind = linear_sum_assignment(M)\n",
    "                costs = [M[row_ind[iB],col_ind[iB]] for iB in range(len(row_ind))]\n",
    "                \n",
    "                # Assess wether the algo should aks for user input\n",
    "                askUI = False\n",
    "                if (max(costs)**0.5) * (1/SCALE_100X) > 1: # If the greatest distance travelled by any object is greater than 1um\n",
    "                    askUI = True\n",
    "\n",
    "                if not askUI: # Automatically asign the positions of the next beads\n",
    "                    iBoi = [col_ind[row_ind.tolist().index(iB)] for iB in previous_iBoi]\n",
    "                    BoiXY = np.array([BXY[iB] for iB in iBoi])\n",
    "\n",
    "                elif askUI: # Ask user input to asign the positions of the next beads\n",
    "                    iS = self.listFrames[iF].iS\n",
    "                    # Case 1: the UI has not been previously saved in the dictLog\n",
    "                    # Then ask for UI and save it in the dictLog\n",
    "                    if not self.dictLog['UI'][iS]:\n",
    "                        # Display the image, plot beads positions and current trajectories & ask the question\n",
    "                        self.listFrames[iF].show()\n",
    "                        for iB in range(self.NB):\n",
    "                            T = self.listTrajectories[iB]\n",
    "                            ax = plt.gca()\n",
    "                            T.plot(ax, iB)\n",
    "                        mngr = plt.get_current_fig_manager()\n",
    "                        mngr.window.setGeometry(700,100,1000, 800)\n",
    "                        QA = pyautogui.confirm(\n",
    "                            text='Can you point the beads of interest\\nin the image ' + str(iS + 1) + '?',\n",
    "                            title='', \n",
    "                            buttons=['No', 'Yes', 'Abort Mission!'])\n",
    "                        \n",
    "                        # According to the question's answer:\n",
    "                        if QA == 'Yes':\n",
    "                            ui = plt.ginput(2, timeout=0)\n",
    "                            uiXY = ui2array(ui)\n",
    "                            fig = plt.gcf()\n",
    "                            plt.close(fig)\n",
    "                            self.dictLog['UI'][iS] = True\n",
    "                            self.dictLog['UILog'][iS] = QA\n",
    "                            print(QA)\n",
    "                            print(self.dictLog['UILog'][iS])\n",
    "                            self.dictLog['UIxy'][iS] = uiXY\n",
    "                        elif QA == 'No':\n",
    "                            validFrame = False\n",
    "                            fig = plt.gcf()\n",
    "                            plt.close(fig)\n",
    "                            self.dictLog['UI'][iS] = True\n",
    "                            self.dictLog['UILog'][iS] = QA\n",
    "                            print(QA)\n",
    "                            print(self.dictLog['UILog'][iS])\n",
    "                        elif QA == 'Abort Mission!':\n",
    "                            validFrame = False\n",
    "                            fig = plt.gcf()\n",
    "                            plt.close(fig)\n",
    "                            return('Bug')\n",
    "                    \n",
    "                    # Case 2: the UI has been previously saved in the dictLog.\n",
    "                    # Then just import the previous answer from the dictLog\n",
    "                    else:\n",
    "                        QA = self.dictLog['UILog'][iS]\n",
    "                        if QA == 'Yes':\n",
    "                            uiXY = self.dictLog['UIxy'][iS]\n",
    "                            \n",
    "                        elif QA == 'No':\n",
    "                            validFrame = False\n",
    "                            fig = plt.gcf()\n",
    "                            plt.close(fig)\n",
    "            \n",
    "            # If there were more than NB objects, and then the QA wasn't 'No', the frame is valid.\n",
    "            if validFrame:\n",
    "                M = compute_cost_matrix(uiXY,BXY)\n",
    "                row_ind, col_ind = linear_sum_assignment(M)\n",
    "                sortM = np.array([[BXY[col_ind[i],0], col_ind[i]] for i in range(len(col_ind))])\n",
    "                sortM = sortM[sortM[:, 0].argsort()]\n",
    "                iBoi = sortM[:, 1].astype(int)\n",
    "                BoiXY = np.array([BXY[iB] for iB in iBoi])\n",
    "                # idxCompression = 0 if not in a ramp, and = number of ramp else. Basically increase by 1 each time you have an interval between two ramps.\n",
    "                idxCompression = (self.listFrames[iF].status == 0) * (max(self.listTrajectories[iB].dict['idxCompression']) + 1 * (self.listTrajectories[iB].dict['idxCompression'][-1] == 0))\n",
    "                for iB in range(self.NB):\n",
    "#                     self.listTrajectories[iB].seriesBeads.append(self.listFrames[iF].listBeads[iBoi[iB]])\n",
    "#                     self.listTrajectories[iB].pointerBeads.append(iBoi[iB])\n",
    "#                     self.listTrajectories[iB].series_iS.append(self.listFrames[iF].iS)\n",
    "#                     self.listTrajectories[iB].seriesXY.append(BoiXY[iB].tolist())\n",
    "#                     self.listTrajectories[iB].current_iS = self.listFrames[iF].iS\n",
    "                    #\n",
    "                    self.listTrajectories[iB].dict['Bead'].append(self.listFrames[iF].listBeads[iBoi[iB]])\n",
    "                    self.listTrajectories[iB].dict['iF'].append(iF)\n",
    "                    self.listTrajectories[iB].dict['iS'].append(self.listFrames[iF].iS)\n",
    "                    self.listTrajectories[iB].dict['iB'].append(iBoi[iB])\n",
    "                    self.listTrajectories[iB].dict['X'].append(BoiXY[iB][0])\n",
    "                    self.listTrajectories[iB].dict['Y'].append(BoiXY[iB][1])\n",
    "                    self.listTrajectories[iB].dict['StdDev'].append(self.listFrames[iF].beadsStdDevarray()[iBoi[iB]])\n",
    "                    self.listTrajectories[iB].dict['Status'].append(self.listFrames[iF].status)\n",
    "                    self.listTrajectories[iB].dict['Status_2'].append(self.listFrames[iF].status_2)\n",
    "                    self.listTrajectories[iB].dict['idxCompression'].append(idxCompression)\n",
    "                    \n",
    "                previous_iF = iF\n",
    "                previous_iBoi = iBoi\n",
    "                previous_BXY = BXY\n",
    "                previous_BoiXY = BoiXY\n",
    "                \n",
    "        for iB in range(self.NB):\n",
    "            for k in self.listTrajectories[iB].dict.keys():\n",
    "                self.listTrajectories[iB].dict[k] = np.array(self.listTrajectories[iB].dict[k])\n",
    "                \n",
    "        # Now we have a functional Trajectory object\n",
    "        # Time to refine it\n",
    "        \n",
    "        nT = len(self.listTrajectories[0].dict['Bead'])\n",
    "        \n",
    "        # (a) Add the pointer to the correct line of the _Field.txt file.\n",
    "        # It's just exactly the iS already saved in the dict, except if there are black images at the end of loops.\n",
    "        # In that case you have to skip the X lines corresponding to the end of the ramp part, X being the nb of black images at the end of the current loop\n",
    "        # This is because when black images occurs, they do because of the high frame rate during ramp parts and thus replace these last ramp images.\n",
    "        \n",
    "        for iB in range(self.NB):\n",
    "            self.listTrajectories[iB].nT = nT\n",
    "            iField = []\n",
    "            for i in range(nT):\n",
    "                S = self.listTrajectories[iB].dict['iS'][i]\n",
    "                iLoop = (S//self.loop_totalSize)\n",
    "                offset = self.blackFramesPerLoop[iLoop]\n",
    "                i_lim = iLoop*self.loop_totalSize + (self.loop_totalSize - ((self.loop_totalSize-self.loop_rampSize)//2) - (self.loop_excludedSize + offset))\n",
    "                # i_lim is the first index after the end of the ramp\n",
    "                addOffset = (S >= i_lim)\n",
    "                SField = S + int(addOffset*offset)\n",
    "                iField.append(SField)\n",
    "            self.listTrajectories[iB].dict['iField'] = iField\n",
    "            \n",
    "        # (b) Find the image with the best std within each n-uplet\n",
    "            \n",
    "        bestStd = self.findBestStd()\n",
    "        \n",
    "        for i in range(self.NB):\n",
    "            self.listTrajectories[i].dict['bestStd'] = bestStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f3e4595",
   "metadata": {
    "code_folding": [
     0,
     2
    ]
   },
   "outputs": [],
   "source": [
    "# Test findBestStd\n",
    "\n",
    "# def findBestStd(Nuplet, status, iS, std):\n",
    "#     \"\"\"\n",
    "#     This ugly function is my best attempt to implement sth very simple in a robust way.\n",
    "#     In the 'status' field, -1 means excluded image, 0 means image that isn't part of a N-uplet of images, and k>0 means position in the N-uplet of images.\n",
    "#     For each image in the N-uplet, I want to reconsititute this N-uplet (meaning the list of Nuplet consecutive images numbered from 1 to Nuplet, minus the images eventually with no beads detected).\n",
    "#     Then for each N-uplet of images, i want to find the max standard deviation and report its position because it's for the max std that the X and Y detection is the most precise.\n",
    "#     An exemple: with these inputs:\n",
    "#     Nuplet = 3\n",
    "#     status = [1,2,3,0,0,0,1,2, 3, 1, 2, 3, 1, 2]\n",
    "#         iS = [0,1,2,3,4,5,6,7,11,12,13,14,15,16]\n",
    "#        std = [1,5,9,5,5,5,1,5, 8, 2, 6, 9, 2, 6]\n",
    "#     The function will return bestStd, a list of boolean with the same length.\n",
    "#     Where status = 0, bestStd = True (the image is not part of a N-uplet, thus it need to be analysed regardless of its std).\n",
    "#     Where satus > 0, the function will cut the lists in N-uplet of max size 3:\n",
    "#     status -> [1,2,3] ; [1,2] ; [ 3] ; [ 1, 2, 3] ; [ 1, 2]\n",
    "#         iS -> [0,1,2] ; [6,7] ; [11] ; [12,13,14] ; [15,16]\n",
    "#        std -> [1,5,9] ; [1,5] ; [ 8] ; [ 2, 6, 9] ; [ 2, 6]\n",
    "#          i -> [0,1,2] ; [6,7] ; [ 8] ; [ 9,10,11] ; [12,13]\n",
    "#     and then will find the best std in each of those fragment and put a True at that position (list 'i') in bestStd, so in this example, at i = 2, 7, 8, 11 ,13\n",
    "#     So the output is: bestStd = [False, False, True, True, True, True, False, True, True, False, False, True, False, True]\n",
    "#     \"\"\"\n",
    "    \n",
    "#     Ntraj = len(iS)\n",
    "#     bestStd = np.zeros(Ntraj, dtype = bool)\n",
    "#     M = np.array([status, iS, std])\n",
    "#     current_Nup_status = []\n",
    "#     current_Nup_iS = []\n",
    "#     current_Nup_std = []\n",
    "#     current_Nup_i = []\n",
    "#     for i in range(Ntraj):\n",
    "#         if status[i] == 0:\n",
    "#             bestStd[i] = True\n",
    "#         else:\n",
    "#             if len(current_Nup_i) == 0:\n",
    "#                 current_Nup_status = [status[i]]\n",
    "#                 current_Nup_iS = [iS[i]]\n",
    "#                 current_Nup_std = [std[i]]\n",
    "#                 current_Nup_i = [i]\n",
    "#             else:\n",
    "#                 if status[i] > current_Nup_status[-1] and (iS[i]-current_Nup_iS[-1]) < Nuplet:\n",
    "#                     current_Nup_status.append(status[i])\n",
    "#                     current_Nup_iS.append(iS[i])\n",
    "#                     current_Nup_std.append(std[i])\n",
    "#                     current_Nup_i.append(i)\n",
    "#                 else:\n",
    "# #                     print(current_Nup_status, current_Nup_iS, current_Nup_std, current_Nup_i)\n",
    "#                     i_bestStdInCurrentNuplet = int(np.argmax(np.array(current_Nup_std)))\n",
    "# #                     print(i_bestStdInCurrentNuplet)\n",
    "#                     i_bestStd = int(current_Nup_i[i_bestStdInCurrentNuplet])\n",
    "#                     bestStd[i_bestStd] = True\n",
    "#                     # then:\n",
    "#                     current_Nup_status = [status[i]]\n",
    "#                     current_Nup_iS = [iS[i]]\n",
    "#                     current_Nup_std = [std[i]]\n",
    "#                     current_Nup_i = [i]\n",
    "                    \n",
    "#     # Need to do it one last time at the end\n",
    "#     i_bestStdInCurrentNuplet = int(np.argmax(np.array(current_Nup_std)))\n",
    "#     i_bestStd = int(current_Nup_i[i_bestStdInCurrentNuplet])\n",
    "#     bestStd[i_bestStd] = True\n",
    "    \n",
    "#     return(bestStd)\n",
    "\n",
    "# Nuplet = 3\n",
    "# status = [1,2,3,0,0,0,1,2, 3, 1, 2, 3, 1, 2]\n",
    "# iS = [0,1,2,3,4,5,6,7,11,12,13,14,15,16]\n",
    "# std = [1,5,9,5,5,5,1,5, 8, 2, 6, 9, 2, 6]\n",
    "# bs = findBestStd(Nuplet, status, iS, std)\n",
    "# bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6313b4d8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Frame:\n",
    "    \n",
    "    def __init__(self, F, iS, NB, threshold, Nup, status, status_2):\n",
    "        ny, nx = F.shape[0], F.shape[1]\n",
    "        self.F = F # Note : Frame.F points directly to the i-th frame of the image I ! To have 2 different versions one should use np.copy(F)\n",
    "        self.threshold = threshold\n",
    "        self.NBoi = NB\n",
    "        self.NBdetected = 0\n",
    "        self.nx = nx\n",
    "        self.ny = ny\n",
    "        self.iS = iS\n",
    "        self.listBeads = []\n",
    "        self.trajPoint = []\n",
    "        self.Nuplet = Nup\n",
    "        self.status = status\n",
    "        self.status_2 = status_2\n",
    "        self.resDf = pd.DataFrame({'Area' : [], 'StdDev' : [], 'XM' : [], 'YM' : [], 'Slice' : []})\n",
    "\n",
    "        \n",
    "    def __str__(self):\n",
    "        text = 'a'\n",
    "        return(text)\n",
    "    \n",
    "    def show(self, strech = True):\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "#         fig_size = plt.gcf().get_size_inches()\n",
    "#         fig.set_size_inches(2 * fig_size)\n",
    "        if strech:\n",
    "            pStart, pStop = np.percentile(self.F, (1, 99))\n",
    "            ax.imshow(self.F, cmap = 'gray', vmin = pStart, vmax = pStop)\n",
    "        else:\n",
    "            ax.imshow(self.F, cmap = 'gray')\n",
    "        if len(self.listBeads) > 0:\n",
    "            for B in self.listBeads:\n",
    "                ax.plot([B.x], [B.y], c='orange', marker='o')\n",
    "        fig.show()\n",
    "    \n",
    "    def detectBeads(self):\n",
    "        F_bin = self.F > self.threshold\n",
    "        F_lab, nObj = ndi.label(F_bin)\n",
    "        props = measure.regionprops(F_lab)\n",
    "        listValidLabels = []\n",
    "        areas = np.zeros(nObj+1)\n",
    "        for k in range(1, nObj+1):\n",
    "            try:\n",
    "                bb = props[k-1].bbox\n",
    "                Valid = not (min(bb) == 0 or bb[2] == self.ny or bb[3] == self.nx) # Remove objects touching the edges of the frame\n",
    "\n",
    "    #             # OPTION 1 - Compute the metrics on the filled shape ; NB: takes a lot of time\n",
    "    #             F_fh = ndi.binary_fill_holes((F_lab == k).astype(int))\n",
    "    #             tmp_props = measure.regionprops(F_fh.astype(int))\n",
    "    #             A = tmp_props[0].area\n",
    "    #             P = tmp_props[0].perimeter\n",
    "    #             Circ = (4 * np.pi * A) / (P * P)\n",
    "    #             Valid = Valid and A >= 100 and Circ >= 0.75 # Area and circularity criterion\n",
    "\n",
    "                # OPTION 2 - Lower the criterion in circularity - NB: less selective\n",
    "                A = props[k-1].area\n",
    "                P = props[k-1].perimeter\n",
    "                Circ = (4 * np.pi * A) / (P * P)\n",
    "                Valid = Valid and A >= 100 and Circ >= 0.65 # Area and circularity criterion\n",
    "\n",
    "            except:\n",
    "                Valid = False\n",
    "            if Valid:\n",
    "                listValidLabels.append(k)\n",
    "                areas[k] = A\n",
    "                \n",
    "#         F_labValid, nObjValid = ndi.label(F_lab)    \n",
    "#         fig, ax = plt.subplots(1,1)\n",
    "#         ax.imshow(F_labValid)\n",
    "#         fig.show()\n",
    "        \n",
    "        centoids = np.array([ndi.center_of_mass(self.F, labels=F_lab, index=i) for i in listValidLabels])\n",
    "        resDict = {}\n",
    "        resDict['Area'] = np.array([areas[i] for i in listValidLabels]).astype(int)\n",
    "        resDict['StdDev'] = np.array([ndi.standard_deviation(self.F, labels=F_lab, index=i) for i in listValidLabels])\n",
    "        resDict['XM'] = centoids[:,1]\n",
    "        resDict['YM'] = centoids[:,0]\n",
    "        resDict['Slice'] = np.array([self.iS+1 for i in listValidLabels]).astype(int)\n",
    "        self.resDf = pd.DataFrame(resDict)\n",
    "        \n",
    "#         print(self.resDict)\n",
    "\n",
    "    def makeListBeads(self):\n",
    "        self.NBdetected = self.resDf.shape[0]\n",
    "        for i in range(self.NBdetected):\n",
    "            d = {}\n",
    "            for c in self.resDf.columns:\n",
    "                d[c] = self.resDf[c].values[i]\n",
    "            self.listBeads.append(Bead(d, self.F))\n",
    "            \n",
    "    def beadsXYarray(self):\n",
    "        A = np.zeros((len(self.listBeads), 2))\n",
    "        for i in range(len(self.listBeads)):\n",
    "            b = self.listBeads[i]\n",
    "            A[i,0], A[i,1] = b.x, b.y\n",
    "        return(A)\n",
    "    \n",
    "    def beadsStdDevarray(self):\n",
    "        A = np.zeros(len(self.listBeads))\n",
    "        for i in range(len(self.listBeads)):\n",
    "            b = self.listBeads[i]\n",
    "            A[i] = b.std\n",
    "        return(A)\n",
    "    \n",
    "    def detectDiameter(self, plot = 0):\n",
    "        for i in range(len(self.listBeads)):\n",
    "            B = self.listBeads[i]\n",
    "            roughSize = np.floor(5*SCALE_100X)\n",
    "            roughSize += roughSize%2\n",
    "            x1_roughROI = max(int(np.floor(B.x) - roughSize*0.5) - 1, 0)\n",
    "            x2_roughROI = min(int(np.floor(B.x) + roughSize*0.5), self.nx)\n",
    "            y1_roughROI = max(int(np.floor(B.y) - roughSize*0.5) - 1, 0)\n",
    "            y2_roughROI = min(int(np.floor(B.y) + roughSize*0.5), self.ny)\n",
    "            \n",
    "            F_roughRoi = self.F[y1_roughROI:y2_roughROI, x1_roughROI:x2_roughROI]   \n",
    "            \n",
    "            figh, axh = plt.subplots(1,1, figsize = (4,4))\n",
    "            axh.hist(F_roughRoi.ravel(), bins=256, histtype='step', color='black')\n",
    "\n",
    "            counts, binEdges = np.histogram(F_roughRoi.ravel(), bins=256)\n",
    "\n",
    "            peaks, peaksProp = find_peaks(counts, height=100, threshold=None, distance=None, prominence=None, \\\n",
    "                               width=None, wlen=None, rel_height=0.5, plateau_size=None)\n",
    "            \n",
    "            peakThreshVal = 750\n",
    "            \n",
    "            if counts[peaks[0]] > peakThreshVal:\n",
    "                B.D = 4.5\n",
    "                \n",
    "            else:\n",
    "                B.D = 2.7\n",
    "                \n",
    "            if plot == 1:    \n",
    "                print(B.D)\n",
    "                B.show()\n",
    "                \n",
    "    def detectNeighbours(self, B):\n",
    "        # To be completed\n",
    "        return('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaec9787",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Bead:\n",
    "    \n",
    "    def __init__(self, d, F):\n",
    "        self.x = d['XM']\n",
    "        self.y = d['YM']\n",
    "        self.D = 0\n",
    "        self.area = d['Area']\n",
    "        self.std = d['StdDev']\n",
    "        self.iS = d['Slice']-1\n",
    "        self.status = ''\n",
    "        self.hasRightNeighbour = False\n",
    "        self.hasLeftNeighbour = False\n",
    "        self.F = F\n",
    "\n",
    "    def show(self, strech = True):\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        if strech:\n",
    "            pStart, pStop = np.percentile(self.F, (1, 99))\n",
    "            ax.imshow(self.F, cmap = 'gray', vmin = pStart, vmax = pStop)\n",
    "        else:\n",
    "            ax.imshow(self.F, cmap = 'gray')\n",
    "        ax.plot([self.x], [self.y], c='orange', marker='o')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd1bd487",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Trajectory:\n",
    "    def __init__(self, I):\n",
    "        nS, ny, nx = I.shape[0], I.shape[1], I.shape[2]\n",
    "        self.I = I\n",
    "        self.nx = nx\n",
    "        self.ny = ny\n",
    "        self.nS = nS\n",
    "        self.D = 0\n",
    "        self.nT = 0\n",
    "#         self.seriesBeads = []\n",
    "#         self.pointerBeads = []\n",
    "#         self.series_iS = []\n",
    "#         self.seriesXY = []\n",
    "#         self.current_iS = 0\n",
    "        self.dict = {'X': [],'Y': [],'idxCompression': [],'StdDev': [], \\\n",
    "                     'Bead': [],'Status': [],'Status_2': [],'iF': [],'iS': [],'iB' : [],}\n",
    "        # These columns will be added later : 'Neighbours', 'Z', 'bestStd' and 'iField'\n",
    "        \n",
    "    def __str__(self):\n",
    "        text = 'iS : ' + str(self.series_iS)\n",
    "        text += '\\n'\n",
    "        text += 'XY : ' + str(self.seriesXY)\n",
    "        return(text)\n",
    "    \n",
    "    def to_df(self):\n",
    "        df = pd.DataFrame(self.dict)\n",
    "        return(df)\n",
    "    \n",
    "    def plot(self, ax, i_color):\n",
    "        colors = ['cyan', 'red', 'blue', 'orange']\n",
    "        c = colors[i_color]\n",
    "        ax.plot(self.dict['X'], self.dict['Y'], color=c, lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed94b31f",
   "metadata": {},
   "source": [
    "### Deptho classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d182859d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class MultiBeadsDeptho:\n",
    "   \n",
    "    def __init__(self, I, fileName, scale):\n",
    "        nz, ny, nx = I.shape[0], I.shape[1], I.shape[2]\n",
    "        \n",
    "        self.I = I\n",
    "        self.fileName = fileName\n",
    "        self.scale = scale\n",
    "        self.I_labeled = np.zeros([nz, ny, nx])\n",
    "        self.nz = nz\n",
    "        self.ny = ny\n",
    "        self.nx = nx\n",
    "        self.listDepthos = []\n",
    "        self.ND = 0\n",
    "        self.NDvalid = 0\n",
    "        self.z_max = 0\n",
    "        self.threshold = 0.5*filters.threshold_otsu(I)\n",
    "        self.summaryTable = pd.DataFrame({})\n",
    "        \n",
    "    def build_listDepthos(self, size = 'detect', plot = 0):\n",
    "        # Find a frame close to the focus for all beads\n",
    "        maxVal = np.zeros(self.nz)\n",
    "        for z in range(self.nz):\n",
    "            maxVal[z] = np.max(self.I[z])\n",
    "        z_max = np.argmax(maxVal)\n",
    "        self.z_max = z_max\n",
    "        F_max = self.I[z_max]\n",
    "        \n",
    "        # On the frame get the approximative position of the centers of all beads\n",
    "        threshold_z_max = filters.threshold_otsu(F_max)\n",
    "        F_max_bin = (F_max > threshold_z_max)\n",
    "        F_labeled, ND = measure.label(F_max_bin, return_num = True)\n",
    "        self.F_labeled, self.ND = F_labeled, ND\n",
    "        \n",
    "        # Summary plot, part 1/2\n",
    "        if plot >= 1:\n",
    "            pStart, pStop = np.percentile(I[self.z_max], (1, 99))\n",
    "            F_max_rescaled = exposure.rescale_intensity(I[self.z_max], in_range=(pStart, pStop))\n",
    "            figI, axI = plt.subplots(1,1, figsize = (15,5))\n",
    "            axI.imshow(F_max_rescaled, cmap = 'gray')\n",
    "        \n",
    "        # Building beadList\n",
    "        iValid = 0\n",
    "        for k in range(1,self.ND+1):\n",
    "            # Initialisation of a BeadDeptho for each bright spot detected on F_max\n",
    "            ym0, xm0 = ndi.center_of_mass(F_max, F_labeled, k)\n",
    "            bD = BeadDeptho(I, xm0, ym0, self.z_max, self.threshold, self.fileName, self.scale)\n",
    "            \n",
    "            # Creation of the depthograph (if possible)\n",
    "            bD.buildDeptho(size, plot)\n",
    "            \n",
    "            # If the bead was not acceptable (for instance too close to the edge of the image)\n",
    "            # then bD.validBead will be False\n",
    "            if not bD.validBead:\n",
    "                print('Not acceptable bead in x0, y0 = {:.2f}, {:.2f}'.format(bD.xm0, bD.ym0))\n",
    "            # Else, we can proceed.\n",
    "            else: \n",
    "                print('Job done for the bead in x0, y0 = {:.2f}, {:.2f}'.format(bD.xm0, bD.ym0))\n",
    "                \n",
    "                # Creation of the z profiles\n",
    "                bD.build_zProfiles(plot)\n",
    "                \n",
    "                # Each valid bead get assigned an index iValid\n",
    "                bD.iValid = iValid\n",
    "                iValid += 1\n",
    "                \n",
    "                # The beadDeptho is added to listDepthos\n",
    "                self.listDepthos.append(bD)\n",
    "                self.NDvalid += 1\n",
    "                \n",
    "                # Deprecated plot\n",
    "#                 if plot >= 1:\n",
    "#                     fig, ax = plt.subplots(1,1, figsize = (8, 5))\n",
    "#                     dV = bD.depthosDict['deptho_v']\n",
    "#                     pStart, pStop = np.percentile(dV, (1, 99))\n",
    "#                     dV_rescaled = exposure.rescale_intensity(dV, in_range=(pStart, pStop))\n",
    "#                     ax.imshow(dV_rescaled, cmap='gray')\n",
    "#                     ax.set_ylim([bD.zLast, bD.zFirst])\n",
    "            \n",
    "            # Summary plot, part 2/2\n",
    "            if plot >= 1:\n",
    "                if bD.validBead:\n",
    "                    axI.plot([bD.XYm[self.z_max, 0]], [bD.XYm[self.z_max, 1]], 'c+')\n",
    "                    axI.text(bD.XYm[self.z_max, 0] + 5, bD.XYm[self.z_max, 1] - 5, str(bD.D), c = 'c')\n",
    "                    bD.plotDeptho()\n",
    "                else:\n",
    "                    axI.plot([bD.xm0], [bD.ym0], 'r+')\n",
    "            \n",
    "            print('\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23068ca4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Building summaryTable\n",
    "#         d = {'D' : [], 'x' : [], 'y' : []}\n",
    "#         otherCols = [c for c in self.beadList[0].ZfocusDict.keys()]\n",
    "#         for c in otherCols:\n",
    "#             d[c] = []\n",
    "#         for k in range(1,self.NDvalid+1):\n",
    "#             bD = self.beadList[k-1]\n",
    "#             d['D'].append(bD.D)\n",
    "#             d['x'].append(bD.XYm[0,bD.z_max])\n",
    "#             d['y'].append(bD.XYm[1,bD.z_max])\n",
    "#             for c in otherCols:\n",
    "#                 d[c].append(bD.ZfocusDict[c])        \n",
    "#         self.summaryTable = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18389fbd",
   "metadata": {
    "code_folding": [
     160,
     246,
     324,
     331,
     365
    ]
   },
   "outputs": [],
   "source": [
    "class BeadDeptho:\n",
    "    def __init__(self, I, xm0, ym0, z_max, threshold, fileName, scale):\n",
    "        \n",
    "        nz, ny, nx = I.shape[0], I.shape[1], I.shape[2]\n",
    "        \n",
    "        self.I = I\n",
    "        self.nz = nz\n",
    "        self.ny = ny\n",
    "        self.nx = nx\n",
    "        self.scale = scale\n",
    "        self.xm0 = xm0\n",
    "        self.ym0 = ym0\n",
    "        self.fileName = fileName\n",
    "        \n",
    "        self.D = 0\n",
    "        self.threshold = threshold\n",
    "        self.I_cleanROI = np.array([])\n",
    "#         self.cleanROI = np.zeros((self.nz, 4), dtype = int)\n",
    "        self.XYm = np.zeros((self.nz, 2))\n",
    "        self.validBead = True\n",
    "        self.iValid = -1\n",
    "        \n",
    "        self.z_max = z_max\n",
    "        self.validSlice = np.zeros(nz, dtype = bool)\n",
    "        self.zFirst = 0\n",
    "        self.zLast = nz\n",
    "        self.validDepth = nz\n",
    "        \n",
    "        self.depthosDict = {}\n",
    "        self.profileDict = {}\n",
    "        self.ZfocusDict = {}\n",
    "        \n",
    "    def buildDeptho(self, size = 'detect', plot = 0):\n",
    "        # Determine if the bead is to close to the edge on the max frame\n",
    "        roughSize = np.floor(5*self.scale)\n",
    "        x1, y1, x2, y2, validROI = getROI(roughSize, self.xm0, self.ym0, self.nx, self.ny)\n",
    "        F_zmax = self.I[self.z_max, y1:y2, x1:x2]           \n",
    "        F_zmax_bin = (F_zmax > self.threshold)\n",
    "        F_zmax_lab, nBzmax = measure.label(F_zmax_bin, return_num = True)\n",
    "        validBead =  validROI and (nBzmax == 1)\n",
    "        self.validBead = validBead\n",
    "        \n",
    "        # If it's the case we can proceed\n",
    "        if validBead:\n",
    "            # Detect or infer the size of the beads we are measuring\n",
    "            if size == 'detect':\n",
    "                counts, binEdges = np.histogram(self.I[self.z_max,y1:y2,x1:x2].ravel(), bins=256)\n",
    "                peaks, peaksProp = find_peaks(counts, height=100, threshold=None, distance=None, prominence=None, \\\n",
    "                                   width=None, wlen=None, rel_height=0.5, plateau_size=None)\n",
    "                peakThreshVal = 1200\n",
    "                if counts[peaks[0]] > peakThreshVal:\n",
    "                    self.D = 4.5\n",
    "                else:\n",
    "                    self.D = 2.7\n",
    "            \n",
    "            elif size == 'M450':\n",
    "                self.D = 4.5   \n",
    "            elif size == 'M270':\n",
    "                self.D = 2.7 \n",
    "            else:\n",
    "                print('invalid size input')\n",
    "                return('invalid size input')\n",
    "            \n",
    "            # Initialise the list of centers of mass\n",
    "            self.XYm[self.z_max] = [self.xm0, self.ym0]\n",
    "            \n",
    "            # Track this bead among all frames\n",
    "            # a) from z_max to the last frame\n",
    "            previous_BoiXY = np.array([self.xm0, self.ym0])\n",
    "            for z in range(self.z_max+1, self.nz):\n",
    "                previous_BoiXY = self.trackBeadDeptho(z, previous_BoiXY)\n",
    "                if not self.validSlice[z]:\n",
    "                    break\n",
    "            \n",
    "            # b) from z_max to the first frame\n",
    "            previous_BoiXY = np.array([self.xm0, self.ym0])\n",
    "            for z in range(self.z_max-1, -1, -1):\n",
    "                previous_BoiXY = self.trackBeadDeptho(z, previous_BoiXY)\n",
    "                if not self.validSlice[z]:\n",
    "                    break\n",
    "        \n",
    "#         print(self.XYm)\n",
    "#         print(self.validSlice)\n",
    "        \n",
    "        zFirst = np.argmax(self.validSlice)\n",
    "        zLast = self.nz - np.argmax(self.validSlice[::-1])\n",
    "\n",
    "        roughSize = int(np.floor(1.2*self.D*self.scale))\n",
    "        roughSize += 1 + roughSize%2\n",
    "        roughCenter = int((roughSize+1)//2)\n",
    "        cleanSize = int(np.floor(1*self.D*self.scale))\n",
    "        cleanSize += 1 + cleanSize%2\n",
    "        I_cleanROI = np.zeros([self.nz, cleanSize, cleanSize])\n",
    "#         print(zFirst, zLast)\n",
    "#         print(roughSize, roughCenter, cleanSize)\n",
    "\n",
    "        try:\n",
    "            for i in range(zFirst, zLast):\n",
    "                xm0, ym0 = self.XYm[i,0], self.XYm[i,1]\n",
    "                x1, y1, x2, y2, validBead = getROI(roughSize, xm0, ym0, self.nx, self.ny)\n",
    "                xm1, ym1 = xm0-x1, ym0-y1\n",
    "                I_roughRoi = self.I[i,y1:y2,x1:x2]\n",
    "                translation = (xm1-roughCenter, ym1-roughCenter)\n",
    "\n",
    "    #             if i == zFirst:\n",
    "    #                 print('roughSize, roughCenter')\n",
    "    #                 print(x2-x1, roughCenter)\n",
    "    #                 print('xm0, ym0')\n",
    "    #                 print(xm0, ym0)\n",
    "    #                 print('x1, y1, x2, y2')\n",
    "    #                 print(x1, y1, x2, y2)\n",
    "    #                 print('xm1, ym1')\n",
    "    #                 print(xm1, ym1)\n",
    "    #                 print('I_roughRoi')\n",
    "    #                 print(I_roughRoi)\n",
    "    #                 print('translation')\n",
    "    #                 print(translation)\n",
    "\n",
    "                tform = transform.EuclideanTransform(rotation=0, \\\n",
    "                                                     translation = (xm1-roughCenter, ym1-roughCenter))\n",
    "                I_tmp = transform.warp(I_roughRoi, tform, order = 1, preserve_range = True)\n",
    "\n",
    "                I_cleanROI[i] = np.copy(I_tmp[roughCenter-cleanSize//2:roughCenter+cleanSize//2+1,\\\n",
    "                                              roughCenter-cleanSize//2:roughCenter+cleanSize//2+1])\n",
    "\n",
    "    #             if i%30 == 0:\n",
    "    #                 fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "    #                 ax[0].imshow(self.I[i], cmap='gray')\n",
    "    #                 ax[0].plot([xm0], [ym0], 'b+')\n",
    "    #                 ax[0].plot([x1,x1], [y1,y2], 'c--')\n",
    "    #                 ax[0].plot([x1,x2], [y2,y2], 'c--')\n",
    "    #                 ax[0].plot([x2,x2], [y1,y2], 'c--')\n",
    "    #                 ax[0].plot([x1,x2], [y1,y1], 'c--')\n",
    "    #                 mid = roughCenter\n",
    "    #                 ax[1].imshow(I_roughRoi, cmap='gray')\n",
    "    #                 ax[1].plot([0,2*mid],[mid, mid], 'r--', lw = 0.5)\n",
    "    #                 ax[1].plot([mid, mid],[0,2*mid], 'r--', lw = 0.5)\n",
    "    #                 ax[1].plot([xm1], [ym1], 'b+')\n",
    "    #                 I_tmp_binary = (I_tmp > self.threshold)\n",
    "    #                 y, x = ndi.center_of_mass(I_tmp, labels=I_tmp_binary, index=1)\n",
    "    #                 ax[2].imshow(I_tmp, cmap='gray')\n",
    "    #                 ax[2].plot([0,2*mid],[mid, mid], 'r--', lw = 0.5)\n",
    "    #                 ax[2].plot([mid, mid],[0,2*mid], 'r--', lw = 0.5)\n",
    "    #                 ax[2].plot([x], [y], 'b+')\n",
    "    #                 fig.suptitle('Translation: ' + str(translation))\n",
    "    #                 fig.show()\n",
    "\n",
    "            self.zFirst = zFirst\n",
    "            self.zLast = zLast\n",
    "            self.validDepth = zLast-zFirst\n",
    "            self.I_cleanROI = I_cleanROI.astype(np.uint16)\n",
    "\n",
    "            # VISUALISE\n",
    "            if plot >= 2:\n",
    "                for i in range(zFirst, zLast, 50):\n",
    "                    self.plotROI(i)\n",
    "\n",
    "        except:\n",
    "            print('Error for the bead in x0, y0 = {:.2f}, {:.2f}'.format(self.xm0, self.ym0))\n",
    "              \n",
    "    def trackBeadDeptho(self, z, previous_BoiXY):\n",
    "        self.validSlice[z] = True\n",
    "        \n",
    "        roughSize = np.floor(2*self.D*self.scale)\n",
    "        x1, y1, x2, y2, validROI = getROI(roughSize, previous_BoiXY[0], previous_BoiXY[1], self.nx, self.ny)\n",
    "    \n",
    "        if not validROI:\n",
    "            self.validSlice[z] = False\n",
    "#             self.validBead = False\n",
    "            return(previous_BoiXY)\n",
    "\n",
    "        else:\n",
    "            F_z = self.I[z, y1:y2, x1:x2]\n",
    "            previous_BoiXY_ROI = previous_BoiXY - np.array([x1, y1])                  \n",
    "            F_z_bin = (F_z > self.threshold)\n",
    "            F_z_bin_fh = ndi.binary_fill_holes(F_z_bin).astype(int)\n",
    "            F_z_lab, nB_ROI = measure.label(F_z_bin_fh, return_num = True)\n",
    "\n",
    "            if nB_ROI == 0:\n",
    "                self.validSlice[z] = False\n",
    "                return(previous_BoiXY)\n",
    "\n",
    "            else: # (if nB_ROI > 0)\n",
    "                props = measure.regionprops(F_z_lab)\n",
    "                listValidLabels = []\n",
    "                for k in range(1, nB_ROI+1):\n",
    "                    try:\n",
    "                        bb = props[k-1].bbox\n",
    "                        validObj = not (min(bb) == 0 or bb[2] == self.ny or bb[3] == self.nx) # Remove objects touching the edges of the frame\n",
    "                        A = props[k-1].area\n",
    "                        P = props[k-1].perimeter\n",
    "                        Circ = (4 * np.pi * A) / (P * P)\n",
    "                        validObj = validObj and A >= 50 and Circ >= 0.75 # Area and circularity criterion\n",
    "                    except:\n",
    "                        validObj = False\n",
    "                    if validObj:\n",
    "                        listValidLabels.append(k)\n",
    "\n",
    "                if len(listValidLabels) == 0:\n",
    "                    self.validSlice[z] = False\n",
    "                    return(previous_BoiXY)\n",
    "\n",
    "                else:\n",
    "                    centroidsYX_list = [ndi.center_of_mass(F_z, labels=F_z_lab, index=i) for i in listValidLabels]\n",
    "                    centroidsXY = np.array([[centroidsYX_list[k][1], centroidsYX_list[k][0]] for k in range(len(centroidsYX_list))])\n",
    "                    M = compute_cost_matrix(np.array([previous_BoiXY_ROI]), centroidsXY)\n",
    "                    i_best = np.argmin(M[0])\n",
    "                    cost_best = M[0][i_best]**0.5\n",
    "\n",
    "                    if cost_best/SCALE_100X > 0.5:\n",
    "                        fig, ax = plt.subplots(1,1, figsize = (8,8))\n",
    "                        pStart, pStop = np.percentile(F_z, (1, 99))\n",
    "                        ax.imshow(F_z, cmap = 'gray', vmin = pStart, vmax = pStop)\n",
    "                        ax.plot(centroidsXY[:,0], centroidsXY[:,1], c='orange', marker='o')\n",
    "                        fig.show()\n",
    "                        mngr = plt.get_current_fig_manager()\n",
    "                        mngr.window.setGeometry(700,100,1000, 800)\n",
    "                        QA = pyautogui.confirm(\n",
    "                            text='Can you point the bead of interest\\nin the image ' + str(z + 1) + '?',\n",
    "                            title='', \n",
    "                            buttons=['No', 'Yes', 'Abort Mission!'])\n",
    "                        # According to the question's answer:\n",
    "                        if QA == 'Yes':\n",
    "                            ui = plt.ginput(1, timeout=0)\n",
    "                            uiXY = ui2array(ui)\n",
    "                            fig = plt.gcf()\n",
    "                            plt.close(fig)\n",
    "                            M = compute_cost_matrix(uiXY,centroidsXY)\n",
    "                            i_best = np.argmin(M[0])\n",
    "                        elif QA == 'No':\n",
    "                            fig = plt.gcf()\n",
    "                            plt.close(fig)\n",
    "                            self.validSlice[z] = False\n",
    "                        elif QA == 'Abort Mission!':\n",
    "                            fig = plt.gcf()\n",
    "                            plt.close(fig)\n",
    "                            return('Abort!')\n",
    "                            \n",
    "                    if self.validSlice[z]:\n",
    "                        BoiXY = np.array(centroidsXY[i_best,:]) + np.array([x1, y1])\n",
    "                        self.XYm[z] = BoiXY\n",
    "                        # self.validSlice[z] = True (already the case)\n",
    "                        return(BoiXY)\n",
    "                    else:\n",
    "                        return(previous_BoiXY)\n",
    "    \n",
    "    def build_zProfiles(self, plot = 0):\n",
    "        side_ROI = self.I_cleanROI.shape[1]\n",
    "        mid_ROI = side_ROI//2\n",
    "        nbPixToAvg = 3 # Have to be an odd number\n",
    "        deptho_v = np.zeros([self.nz, side_ROI], dtype = np.float64)\n",
    "        deptho_h = np.zeros([self.nz, side_ROI], dtype = np.float64)\n",
    "        \n",
    "        for z in range(self.zFirst, self.zLast):\n",
    "            templine = side_ROI\n",
    "            deptho_v[z] = self.I_cleanROI[z,:,mid_ROI] * (1/nbPixToAvg)\n",
    "#             print(self.I_cleanROI[z,:,mid_ROI])\n",
    "#             print(1/nbPixToAvg)\n",
    "#             print(self.deptho_v[z])\n",
    "            deptho_h[z] = self.I_cleanROI[z,mid_ROI,:] * (1/nbPixToAvg)\n",
    "    \n",
    "            for i in range(1, 1 + nbPixToAvg//2):\n",
    "#                 print(self.I_cleanROI[z,:,mid_ROI - i] * (1/nbPixToAvg) )\n",
    "                deptho_v[z] += self.I_cleanROI[z,:,mid_ROI - i] * (1/nbPixToAvg) \n",
    "                deptho_v[z] += self.I_cleanROI[z,:,mid_ROI + i] * (1/nbPixToAvg)\n",
    "                \n",
    "                deptho_h[z] += self.I_cleanROI[z,mid_ROI - i,:] * (1/nbPixToAvg) \n",
    "                deptho_h[z] += self.I_cleanROI[z,mid_ROI + i,:] * (1/nbPixToAvg)\n",
    "          \n",
    "        deptho_v = deptho_v.astype(np.uint16)\n",
    "        deptho_h = deptho_h.astype(np.uint16)\n",
    "        \n",
    "        self.depthosDict['deptho_v'] = deptho_v\n",
    "        self.depthosDict['deptho_h'] = deptho_h\n",
    "        \n",
    "        \n",
    "        # 3D caracterisation\n",
    "        I_binary = np.zeros([self.I_cleanROI.shape[0], self.I_cleanROI.shape[1], self.I_cleanROI.shape[2]])\n",
    "        I_binary[self.zFirst:self.zLast] = (self.I_cleanROI[self.zFirst:self.zLast] > self.threshold)\n",
    "        Zm3D, Ym3D, Xm3D = ndi.center_of_mass(self.I_cleanROI, labels=I_binary, index=1)\n",
    "        self.ZfocusDict['Zm3D'] = Zm3D\n",
    "        \n",
    "        \n",
    "        # Raw profiles\n",
    "        \n",
    "        Z = np.array([z for z in range(self.I_cleanROI.shape[0])])\n",
    "        intensity_tot = np.array([np.sum(self.I_cleanROI[z][I_binary[z].astype(bool)])/(1+np.sum(I_binary[z])) for z in range(self.I_cleanROI.shape[0])]).astype(np.float64)\n",
    "        intensity_v = np.array([np.sum(deptho_v[z,:])/side_ROI for z in range(deptho_v.shape[0])]).astype(np.float64)\n",
    "        intensity_h = np.array([np.sum(deptho_h[z,:])/side_ROI for z in range(deptho_h.shape[0])]).astype(np.float64)\n",
    "        \n",
    "        Zm_v, Zm_h, Zm_tot = np.argmax(intensity_v), np.argmax(intensity_h), np.argmax(intensity_tot)\n",
    "        \n",
    "        self.profileDict['intensity_v'] = intensity_v\n",
    "        self.profileDict['intensity_h'] = intensity_h\n",
    "        self.profileDict['intensity_tot'] = intensity_tot\n",
    "        self.ZfocusDict['Zm_v'] = Zm_v\n",
    "        self.ZfocusDict['Zm_h'] = Zm_h\n",
    "        self.ZfocusDict['Zm_tot'] = Zm_tot\n",
    "\n",
    "\n",
    "        # Smoothed profiles\n",
    "        \n",
    "        Z_hd = np.arange(0,self.I_cleanROI.shape[0],0.2)\n",
    "        intensity_v_hd = np.interp(Z_hd, Z, intensity_v)\n",
    "        intensity_h_hd = np.interp(Z_hd, Z, intensity_h)\n",
    "        intensity_tot_hd = np.interp(Z_hd, Z, intensity_tot)\n",
    "        intensity_v_smooth = savgol_filter(intensity_v_hd, 101, 7)\n",
    "        intensity_h_smooth = savgol_filter(intensity_h_hd, 101, 7)\n",
    "        intensity_tot_smooth = savgol_filter(intensity_tot_hd, 101, 7)\n",
    "        \n",
    "        Zm_v_hd, Zm_h_hd, Zm_tot_hd = Z_hd[np.argmax(intensity_v_smooth)], Z_hd[np.argmax(intensity_h_smooth)], Z_hd[np.argmax(intensity_tot_smooth)]\n",
    "        \n",
    "        self.profileDict['intensity_v_smooth'] = intensity_v_smooth \n",
    "        self.profileDict['intensity_h_smooth'] = intensity_h_smooth\n",
    "        self.profileDict['intensity_tot_smooth'] = intensity_tot_smooth\n",
    "        self.ZfocusDict['Zm_v_hd'] = Zm_v_hd \n",
    "        self.ZfocusDict['Zm_h_hd'] = Zm_h_hd\n",
    "        self.ZfocusDict['Zm_tot_hd'] = Zm_tot_hd\n",
    "        \n",
    "        # VISUALISE\n",
    "        if plot >= 2:\n",
    "            self.plotProfiles()\n",
    "            \n",
    "\n",
    "    def plotXYm(self):\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        pStart, pStop = np.percentile(self.I[self.z_max], (1, 99))\n",
    "        ax.imshow(self.I[self.z_max], cmap = 'gray', vmin = pStart, vmax = pStop)\n",
    "        ax.plot(self.XYm[self.validSlice,0],self.XYm[self.validSlice,1],'r-')\n",
    "        fig.show()\n",
    "        \n",
    "    def plotROI(self, i = 'auto'):\n",
    "        if i == 'auto':\n",
    "            i = self.z_max\n",
    "        \n",
    "        fig, ax = plt.subplots(1,3, figsize = (16,4))\n",
    "        \n",
    "        xm, ym = np.mean(self.XYm[self.validSlice,0]),  np.mean(self.XYm[self.validSlice,1])\n",
    "        ROIsize_x = self.D*1.25*self.scale + (max(self.XYm[self.validSlice,0])-min(self.XYm[self.validSlice,0]))\n",
    "        ROIsize_y = self.D*1.25*self.scale + (max(self.XYm[self.validSlice,1])-min(self.XYm[self.validSlice,1]))\n",
    "        x1_ROI, y1_ROI, x2_ROI, y2_ROI = int(xm - ROIsize_x//2), int(ym - ROIsize_y//2), int(xm + ROIsize_x//2), int(ym + ROIsize_y//2)        \n",
    "\n",
    "        pStart, pStop = np.percentile(self.I[i], (1, 99))\n",
    "        ax[0].imshow(self.I[i], cmap = 'gray', vmin = pStart, vmax = pStop)\n",
    "        ax[0].plot([x1_ROI,x1_ROI], [y1_ROI,y2_ROI], 'c--')\n",
    "        ax[0].plot([x1_ROI,x2_ROI], [y2_ROI,y2_ROI], 'c--')\n",
    "        ax[0].plot([x2_ROI,x2_ROI], [y1_ROI,y2_ROI], 'c--')\n",
    "        ax[0].plot([x1_ROI,x2_ROI], [y1_ROI,y1_ROI], 'c--')\n",
    "\n",
    "        I_ROI = self.I[i,y1_ROI:y2_ROI,x1_ROI:x2_ROI] \n",
    "        pStart, pStop = np.percentile(I_ROI, (1, 99))\n",
    "        ax[1].imshow(I_ROI, cmap = 'gray', vmin = pStart, vmax = pStop)\n",
    "        ax[1].plot(self.XYm[self.validSlice,0]-x1_ROI, self.XYm[self.validSlice,1]-y1_ROI, 'r-', lw=0.75)\n",
    "        ax[1].plot(self.XYm[i,0]-x1_ROI, self.XYm[i,1]-y1_ROI, 'b+', lw=0.75)\n",
    "        \n",
    "        pStart, pStop = np.percentile(self.I_cleanROI[i], (1, 99))\n",
    "        mid = self.I_cleanROI[i].shape[0]//2\n",
    "        I_cleanROI_binary = (self.I_cleanROI[i] > self.threshold)\n",
    "        y, x = ndi.center_of_mass(self.I_cleanROI[i], labels=I_cleanROI_binary, index=1)\n",
    "        ax[2].imshow(self.I_cleanROI[i], cmap = 'gray', vmin = pStart, vmax = pStop)\n",
    "        ax[2].plot([0,2*mid],[mid, mid], 'r--', lw = 0.5)\n",
    "        ax[2].plot([mid, mid],[0,2*mid], 'r--', lw = 0.5)\n",
    "        ax[2].plot([x],[y], 'b+')\n",
    "        fig.show()\n",
    "\n",
    "    def plotProfiles(self):\n",
    "        Z = np.array([z for z in range(self.I_cleanROI.shape[0])])\n",
    "        Z_hd = np.arange(0,self.I_cleanROI.shape[0],0.2)\n",
    "        intensity_v = self.profileDict['intensity_v']\n",
    "        intensity_h = self.profileDict['intensity_h']\n",
    "        intensity_tot = self.profileDict['intensity_tot']\n",
    "        Zm_v = self.ZfocusDict['Zm_v']\n",
    "        Zm_h = self.ZfocusDict['Zm_h']\n",
    "        Zm_tot = self.ZfocusDict['Zm_tot']\n",
    "        intensity_v_smooth = self.profileDict['intensity_v_smooth']\n",
    "        intensity_h_smooth = self.profileDict['intensity_h_smooth']\n",
    "        intensity_tot_smooth = self.profileDict['intensity_tot_smooth']\n",
    "        Zm_v_hd = self.ZfocusDict['Zm_v_hd']\n",
    "        Zm_h_hd = self.ZfocusDict['Zm_h_hd']\n",
    "        Zm_tot_hd = self.ZfocusDict['Zm_tot_hd']\n",
    "        \n",
    "#             fig, ax = plt.subplots(1,3, figsize = (12, 4))\n",
    "#             ax[0].plot(Z, intensity_v)\n",
    "#             ax[1].plot(Z, intensity_h)\n",
    "#             ax[2].plot(Z, (intensity_tot))\n",
    "#             ax[0].plot([Zm_v, Zm_v], [0, ax[0].get_ylim()[1]], 'r--', lw = 0.8, label = 'Zm_v = {:.2f}'.format(Zm_v))\n",
    "#             ax[1].plot([Zm_h, Zm_h], [0, ax[1].get_ylim()[1]], 'r--', lw = 0.8, label = 'Zm_h = {:.2f}'.format(Zm_h))\n",
    "#             ax[2].plot([Zm_tot, Zm_tot], [0, ax[2].get_ylim()[1]], 'r--', lw = 0.8, label = 'Zm_tot = {:.2f}'.format(Zm_tot))\n",
    "#             ax[0].legend(loc = 'lower right')\n",
    "#             ax[1].legend(loc = 'lower right')\n",
    "#             ax[2].legend(loc = 'lower right')\n",
    "        \n",
    "        fig, ax = plt.subplots(1,3, figsize = (12, 4))\n",
    "        ax[0].plot(Z, intensity_v, 'b-')\n",
    "        ax[1].plot(Z, intensity_h, 'b-')\n",
    "        ax[2].plot(Z, (intensity_tot), 'b-')\n",
    "        ax[0].plot(Z_hd, intensity_v_smooth, 'k--')\n",
    "        ax[1].plot(Z_hd, intensity_h_smooth, 'k--')\n",
    "        ax[2].plot(Z_hd, intensity_tot_smooth, 'k--')\n",
    "        ax[0].plot([Zm_v_hd, Zm_v_hd], [0, ax[0].get_ylim()[1]], 'r--', lw = 0.8, label = 'Zm_v_hd = {:.2f}'.format(Zm_v_hd))\n",
    "        ax[1].plot([Zm_h_hd, Zm_h_hd], [0, ax[1].get_ylim()[1]], 'r--', lw = 0.8, label = 'Zm_h_hd = {:.2f}'.format(Zm_h_hd))\n",
    "        ax[2].plot([Zm_tot_hd, Zm_tot_hd], [0, ax[2].get_ylim()[1]], 'r--', lw = 0.8, label = 'Zm_tot_hd = {:.2f}'.format(Zm_tot_hd))\n",
    "        ax[0].legend(loc = 'lower right')\n",
    "        ax[1].legend(loc = 'lower right')\n",
    "        ax[2].legend(loc = 'lower right')\n",
    "\n",
    "        #         print('Zm_v = {:.2f}, Zm_h = {:.2f}, Zm_tot = {:.2f}'\\\n",
    "        #               .format(Zm_v, Zm_h, Zm_tot))\n",
    "        #         print('Zm_v_hd = {:.2f}, Zm_h_hd = {:.2f}, Zm_tot_hd = {:.2f}'\\\n",
    "        #               .format(Zm_v_hd, Zm_h_hd, Zm_tot_hd))\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "    def plotDeptho(self, d = 'v'):\n",
    "        fig, ax = plt.subplots(1,1, figsize = (4, 6))\n",
    "        if d == 'v':\n",
    "            D = self.depthosDict['deptho_v']\n",
    "            z_focus = self.ZfocusDict['Zm_v_hd']\n",
    "        elif d == 'h':\n",
    "            D = self.depthosDict['deptho_h']\n",
    "            z_focus = self.ZfocusDict['Zm_h_hd']\n",
    "        ny, nx = D.shape[0], D.shape[1]\n",
    "        pStart, pStop = np.percentile(D, (1, 99))\n",
    "        ax.imshow(D, cmap='gray', vmin = pStart, vmax = pStop)\n",
    "        ax.plot([0, nx], [self.zFirst, self.zFirst], 'r--')\n",
    "        ax.text(nx//2, self.zFirst - 10, str(self.zFirst), c = 'r')\n",
    "        ax.plot([0, nx], [self.zLast, self.zLast], 'r--')\n",
    "        ax.text(nx//2, self.zLast - 10, str(self.zLast), c = 'r')\n",
    "        ax.plot([0, nx], [z_focus, z_focus], 'c--')\n",
    "        ax.text(nx//2, z_focus - 10, str(z_focus), c = 'c')\n",
    "        fig.suptitle('File ' + self.fileName + ' - Bead ' + str(self.iValid))\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "521199c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depthoMaker(dirPath, scale, d = 'v'):\n",
    "    listDepthosFileNames = [f for f in os.listdir(dirPath) if (os.path.isfile(os.path.join(dirPath, f)) and f.endswith(\".tif\"))]\n",
    "    listMBDepthos = []\n",
    "    listSizes = []\n",
    "    dirMaxValidDepth\n",
    "    for f in listDepthosFileNames:\n",
    "        filePath = os.path.join(dirPath, f)\n",
    "        I = io.imread(filePath)\n",
    "        mbd = MultiBeadsDeptho(I, f[:-4], scale)\n",
    "        mbd.build_listDepthos(size = 'detect', plot = 1)\n",
    "        listMBDepthos.append(mbd)\n",
    "        for bD in mbd.listDepthos:\n",
    "            if bD.D not in listSizes:\n",
    "                listSizes.append(bD.D)\n",
    "        print(listSizes)\n",
    "# TBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb403ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multiDeptho10.tif', 'multiDeptho9.tif']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testDataFolder = 'C://Users//JosephVermeil//Desktop//test_DepthoMaking'\n",
    "testDataFolder = 'C://Users//JosephVermeil//Desktop//test_AnalyseDepthos'\n",
    "listDepthos = [f for f in os.listdir(testDataFolder) if (os.path.isfile(os.path.join(testDataFolder, f)) and f.endswith(\".tif\"))]\n",
    "listDepthos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ba65b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for the bead in x0, y0 = 2031.70, 21.24\n",
      "Not acceptable bead in x0, y0 = 2031.70, 21.24\n",
      "\n",
      "\n",
      "Job done for the bead in x0, y0 = 1903.86, 115.13\n",
      "\n",
      "\n",
      "Error for the bead in x0, y0 = 1256.49, 122.10\n",
      "Not acceptable bead in x0, y0 = 1256.49, 122.10\n",
      "\n",
      "\n",
      "Error for the bead in x0, y0 = 1296.29, 135.56\n",
      "Not acceptable bead in x0, y0 = 1296.29, 135.56\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JosephVermeil\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:188: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job done for the bead in x0, y0 = 669.32, 218.49\n",
      "\n",
      "\n",
      "Job done for the bead in x0, y0 = 1443.07, 275.02\n",
      "\n",
      "\n",
      "Job done for the bead in x0, y0 = 982.62, 275.52\n",
      "\n",
      "\n",
      "Job done for the bead in x0, y0 = 1318.99, 417.28\n",
      "\n",
      "\n",
      "Job done for the bead in x0, y0 = 1027.75, 503.07\n",
      "\n",
      "\n",
      "Error for the bead in x0, y0 = 82.49, 579.09\n",
      "Not acceptable bead in x0, y0 = 82.49, 579.09\n",
      "\n",
      "\n",
      "Error for the bead in x0, y0 = 1692.01, 586.24\n",
      "Not acceptable bead in x0, y0 = 1692.01, 586.24\n",
      "\n",
      "\n",
      "Error for the bead in x0, y0 = 150.52, 597.67\n",
      "Not acceptable bead in x0, y0 = 150.52, 597.67\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = listDepthos[1]\n",
    "filePath = os.path.join(testDataFolder, f)\n",
    "I = io.imread(filePath)\n",
    "mbd = MultiBeadsDeptho(I, f[:-4], SCALE_100X)\n",
    "mbd.build_listDepthos(size = 'detect', plot = 1)\n",
    "# listBeads = mbd.get_beadList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b7e384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4762.5\n"
     ]
    }
   ],
   "source": [
    "print(mbd.threshold)\n",
    "for bD in mbd.listDepthos:\n",
    "    bD.plotXYm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7aefa957",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bD in mbd.listDepthos:\n",
    "    fig, ax = plt.subplots(1,2, figsize = (12, 4))\n",
    "    Z = np.array([z for z in range(bD.I_cleanROI.shape[0])])\n",
    "    deptho_v = bD.depthosDict['deptho_v']\n",
    "    deptho_h = bD.depthosDict['deptho_h']\n",
    "    ax[0].imshow(deptho_v, cmap='gray')\n",
    "    ax[1].imshow(deptho_h, cmap='gray')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aeccdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JosephVermeil\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "bD = mbd.listDepthos[0]\n",
    "for z in range(bD.zFirst,bD.zLast):\n",
    "    if z%20==0:\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "        ax.imshow(bD.I_cleanROI[z], cmap='gray')\n",
    "#         ax.plot(bD.XYm)\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3144740",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDataDir = 'D://MagneticPincherData'\n",
    "# mainDataDir = 'C://Users//josep//Desktop//TestData_BeadTracker'\n",
    "rawDataDir = os.path.join(mainDataDir, 'Raw')\n",
    "interDataDir = os.path.join(mainDataDir, 'Intermediate')\n",
    "figureDir = os.path.join(mainDataDir, 'Figures')\n",
    "dateTest1 = '21-04-27'\n",
    "dateTest2 = '21.04.27'\n",
    "# 21-04-27_M1_P1_C4_R40_disc20um_wFluo\n",
    "# imagesToAnalyse.append(os.path.join(rd, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77401b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    dates = '21.01.21'\n",
    "#     dates = '21.04.27'\n",
    "#     manip = 'M1_P1_C4'\n",
    "#     manipID = '21-04-27_M1'\n",
    "    \n",
    "    manips = 1\n",
    "    wells = 1\n",
    "    cells = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 0. Load different data sources & Preprocess : fluo, black images, sort slices (ct/ramp ; down/middle/up)\n",
    "    # Make list of files to analyse\n",
    "    imagesToAnalyse = []\n",
    "    imagesToAnalyse_Paths = []\n",
    "    if not isinstance(dates, str):\n",
    "        rawDirList = [os.path.join(rawDataDir, d) for d in dates]\n",
    "    else:\n",
    "        rawDirList = [os.path.join(rawDataDir, dates)]\n",
    "    for rd in rawDirList:\n",
    "        fileList = os.listdir(rd)\n",
    "        for f in fileList:\n",
    "            if isFileOfInterest(f, manips, wells, cells):\n",
    "                imagesToAnalyse.append(f)\n",
    "                imagesToAnalyse_Paths.append(os.path.join(rd, f))          \n",
    "    \n",
    "    # Begining of the MAIN LOOP\n",
    "    for i in range(len(imagesToAnalyse)): \n",
    "        f, fP = imagesToAnalyse[i], imagesToAnalyse_Paths[i]\n",
    "        manipID = findInfosInFileName(f, 'manipID')\n",
    "        cellID = findInfosInFileName(f, 'cellID')\n",
    "        \n",
    "        # Load exp data\n",
    "        if manipID not in expDf['manipID'].values:\n",
    "            print('Error! No experimental data found for: ' + manipID)\n",
    "            bug\n",
    "        else:\n",
    "            expDf_line = expDf.loc[expDf['manipID'] == manipID]\n",
    "            manipDict = {}\n",
    "            for c in expDf_line.columns.values:\n",
    "                manipDict[c] = expDf_line[c].values[0]\n",
    "    \n",
    "        # Load image and init ptl\n",
    "        I = io.imread(fP) # Approx 0.5s per image\n",
    "        ptl = PincherTimeLapse(I, cellID, manipDict, NB = 2)\n",
    "    \n",
    "        # Load field file\n",
    "        fieldFilePath = fP[:-4] + '_Field.txt'\n",
    "        fieldCols = ['B_set', 'T_abs', 'B', 'Z']\n",
    "        fieldDf = pd.read_csv(fieldFilePath, sep = '\\t', names = fieldCols)\n",
    "        \n",
    "        # Check if a log file exists and load it if required\n",
    "        logFilePath = fP[:-4] + '_Log.txt'\n",
    "        logFileImported = False\n",
    "        if os.path.isfile(logFilePath):\n",
    "            ptl.importLog(logFilePath)\n",
    "            ptl.dictLog['UILog'] = ptl.dictLog['UILog'].astype(str)\n",
    "            logFileImported = True\n",
    "        \n",
    "        # Detect fluo & black images\n",
    "        ptl.checkIfBlackFrames()\n",
    "        ptl.saveFluoAside()\n",
    "        if not logFileImported:\n",
    "            pass # I may change the organization of this part later\n",
    "        \n",
    "        # Sort slices\n",
    "        if not logFileImported:\n",
    "            ptl.determineFramesStatus()\n",
    "        ptl.saveLog(display = True, save = (not logFileImported), path = logFilePath)\n",
    "        \n",
    "        # Determine global threshold\n",
    "        ptl.computeThreshold() # Approx 3s per image\n",
    "#         ptl.testThresholding()\n",
    "        \n",
    "        # Create list of Frame objects\n",
    "        ptl.makeFramesList()\n",
    "    \n",
    "    \n",
    "    # 1. Detect beads\n",
    "        # Check if a _Results.txt exists and import it if so\n",
    "        resFilePath = fP[:-4] + '_ResultsPY.txt'\n",
    "        resFileImported = False\n",
    "        if os.path.isfile(resFilePath):\n",
    "            ptl.importBeadsDetectResult(resFilePath)\n",
    "            resFileImported = True\n",
    "    \n",
    "        # Dectect the beads and create the BeadsDetectResult dataframe [if no file has been loaded before] \n",
    "        # OR input the results in each Frame objects [if the results have been loaded at the previous step]\n",
    "        ptl.detectBeads(resFileImported, display = 1)\n",
    "        \n",
    "        # Save the new results if necessary\n",
    "        if not resFileImported:\n",
    "            ptl.saveBeadsDetectResult(path=resFilePath)\n",
    "\n",
    "        \n",
    "    # 2. Make trajectories for beads of interest\n",
    "        # Display the first image to ask for the 2 beads of interest\n",
    "        issue = ptl.buildTrajectories()\n",
    "        if issue == 'Bug':\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "        ptl.saveLog(display = 2, save = True, path = logFilePath)\n",
    "        \n",
    "        # \n",
    "    \n",
    "    # 3. Qualify - Detect boi sizes and neighbours\n",
    "        # Detect Boi sizes in the first image and propagate it across the trajectories\n",
    "        ptl.listFrames[0].detectDiameter(plot = 0)\n",
    "        for iB in range(ptl.NB):\n",
    "            traj = ptl.listTrajectories[iB]\n",
    "            B0 = traj.dict['Bead'][0]\n",
    "            D = B0.D\n",
    "            traj.D = D\n",
    "            for B in traj.dict['Bead']:\n",
    "                B.D = D\n",
    "        \n",
    "        # Detect neighbours in every first image of loop\n",
    "        iL = 0\n",
    "        for iB in range(ptl.NB):\n",
    "            traj = ptl.listTrajectories[iB]\n",
    "            neighbours = np.array(['' for i in range(traj.nT)], dtype = '<U12')\n",
    "            current_neighbours = ''\n",
    "            for i in range(traj.nT):\n",
    "                iS = traj.dict['iS'][i]\n",
    "                if iS >= iL*ptl.loop_totalSize:\n",
    "                    # Redo the detection\n",
    "                    iF = traj.dict['iF'][i]\n",
    "                    bead = traj.dict['Bead'][i]\n",
    "                    frame = ptl.listFrames[iF]\n",
    "                    current_neighbours = frame.detectNeighbours(bead)\n",
    "                    neighbours[i] = current_neighbours\n",
    "                    #\n",
    "                    iL += 1\n",
    "                else:\n",
    "                    # Just take the previous neighbour situation\n",
    "                    neighbours[i] = current_neighbours\n",
    "                    \n",
    "            traj.dict['neighbours'] = neighbours\n",
    "    \n",
    "        \n",
    "    # 4. Compute dz\n",
    "        # Import depthographs\n",
    "        \n",
    "        \n",
    "        # Compute z for each traj\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 5. Define pairs and compute dx, dy\n",
    "    \n",
    "        if ptl.NB == 2:\n",
    "            traj1 = ptl.listTrajectories[0]\n",
    "            traj2 = ptl.listTrajectories[1]\n",
    "            nT = traj1.nT\n",
    "            \n",
    "            # Create a dict to prepare the export of the results\n",
    "            timeSeries = {\n",
    "                'idxCompression' : np.zeros(nT), \\\n",
    "                'T' : np.zeros(nT), \\\n",
    "                'Tabs' : np.zeros(nT), \\\n",
    "                'B' : np.zeros(nT), \\\n",
    "                'F' : np.zeros(nT), \\\n",
    "                'dx' : np.zeros(nT), \\\n",
    "                'dy' : np.zeros(nT), \\\n",
    "                'dz' : np.zeros(nT), \\\n",
    "                'D2' : np.zeros(nT), \\\n",
    "                'D3' : np.zeros(nT)\n",
    "            }\n",
    "\n",
    "            # Input common values:\n",
    "            T0 = fieldDf['T_abs'].values[0]/1000\n",
    "            timeSeries['idxCompression'] = traj1.dict['idxCompression']\n",
    "            timeSeries['Tabs'] = (fieldDf['T_abs'][traj1.dict['iField']])/1000\n",
    "            timeSeries['T'] = timeSeries['Tabs'].values - T0*np.ones(nT)\n",
    "            timeSeries['B'] = fieldDf['B'][traj1.dict['iField']]\n",
    "\n",
    "            # Compute distances\n",
    "            timeSeries['dx'] = traj2.dict['X'] - traj1.dict['X']\n",
    "            timeSeries['dy'] = traj2.dict['Y'] - traj1.dict['Y']\n",
    "            timeSeries['D2'] = (timeSeries['dx']**2 +  timeSeries['dy']**2)**0.5\n",
    "            \n",
    "            timeSeries_DF = pd.DataFrame(timeSeries)\n",
    "            print('\\n\\n* timeSeries:\\n')\n",
    "            print(timeSeries_DF)\n",
    "            \n",
    "    # 6. Compute forces\n",
    "    # 7. Export the results\n",
    "    \n",
    "    print('\\nTotal time:')\n",
    "    print(time.time()-start)\n",
    "    return(ptl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f818a03a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ptl = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dcd1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PTL.listTrajectories[0].to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ad6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = PTL.listFrames[-5].show()\n",
    "ax = plt.gca()\n",
    "for i in range(PTL.NB):\n",
    "    PTL.listTrajectories[i].plot(ax, i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e0547",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traj = PTL.listTrajectories[1]\n",
    "traj.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4dfa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = PTL.listTrajectories[1]\n",
    "a = np.sum(np.array(traj.dict['idxCompression']) == 1)\n",
    "traj.dict['bestStd'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b47bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = PTL.listTrajectories[1]\n",
    "traj.dict['iField'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = PTL.listTrajectories[1]\n",
    "np.array(traj.dict['idxRamp']) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028fb1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PTL.dictLog['UILog'] = PTL.dictLog['UILog'].astype(str)\n",
    "a = PTL.dictLog['UILog'].astype(str)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7bcfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a1ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp = 'D://MagneticPincherData//Raw//21.04.27//21-04-27_M1_P1_C4_R40_disc20um_wFluo.tif'\n",
    "# fp = \"C://Users//JosephVermeil//Desktop//Fichier 3BiocheVsPhy@2x.png\"\n",
    "# fp = \"C://Users//JosephVermeil//Desktop//21-04-27_M1_P1_C4_R40_disc20um_wFluo.tif\"\n",
    "# I = io.imread(fp)\n",
    "# I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['a']\n",
    "b = 'a'\n",
    "len(a[0][0])\n",
    "len(b[0][0])\n",
    "isinstance(b, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b06cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e204a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "354px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
