{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "from copy import copy\n",
    "from cycler import cycler\n",
    "from datetime import date\n",
    "from scipy.optimize import curve_fit\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "pd.set_option('mode.chained_assignment',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "dateFormatExcel = re.compile('\\d{2}/\\d{2}/\\d{4}')\n",
    "dateFormatOk = re.compile('\\d{2}-\\d{2}-\\d{2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib widget \n",
    "# %matplotlib inline\n",
    "matplotlib.rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "\n",
    "SMALLER_SIZE = 10\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALLER_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "# colors = prop_cycle.by_key()['color']\n",
    "my_default_color_list = ['#ff7f0e', '#1f77b4', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "my_default_color_cycle = cycler(color=my_default_color_list)\n",
    "plt.rcParams['axes.prop_cycle'] = my_default_color_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a', '#d62728', '#ff9896', '#9467bd', '#c5b0d5', '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f', '#c7c7c7', '#bcbd22', '#dbdb8d', '#17becf', '#9edae5']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg  width=\"1100\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#1f77b4;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#aec7e8;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ff7f0e;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ffbb78;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#2ca02c;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#98df8a;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"330\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#d62728;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"385\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ff9896;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"440\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#9467bd;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"495\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#c5b0d5;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"550\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#8c564b;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"605\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#c49c94;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"660\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#e377c2;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"715\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#f7b6d2;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"770\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#7f7f7f;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"825\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#c7c7c7;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"880\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#bcbd22;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"935\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#dbdb8d;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"990\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#17becf;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"1045\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#9edae5;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "['#1f77b4',\n",
       " '#aec7e8',\n",
       " '#ff7f0e',\n",
       " '#ffbb78',\n",
       " '#2ca02c',\n",
       " '#98df8a',\n",
       " '#d62728',\n",
       " '#ff9896',\n",
       " '#9467bd',\n",
       " '#c5b0d5',\n",
       " '#8c564b',\n",
       " '#c49c94',\n",
       " '#e377c2',\n",
       " '#f7b6d2',\n",
       " '#7f7f7f',\n",
       " '#c7c7c7',\n",
       " '#bcbd22',\n",
       " '#dbdb8d',\n",
       " '#17becf',\n",
       " '#9edae5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairedPalette = sns.color_palette(\"tab20\")\n",
    "pairedPalette = pairedPalette.as_hex()\n",
    "print(pairedPalette)\n",
    "pairedPalette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg  width=\"330\" height=\"55\"><rect x=\"0\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#1f77b4;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"55\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#aec7e8;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"110\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ff7f0e;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"165\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#ffbb78;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"220\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#2ca02c;stroke-width:2;stroke:rgb(255,255,255)\"/><rect x=\"275\" y=\"0\" width=\"55\" height=\"55\" style=\"fill:#98df8a;stroke-width:2;stroke:rgb(255,255,255)\"/></svg>"
      ],
      "text/plain": [
       "[(0.12156862745098039, 0.4666666666666667, 0.7058823529411765),\n",
       " (0.6823529411764706, 0.7803921568627451, 0.9098039215686274),\n",
       " (1.0, 0.4980392156862745, 0.054901960784313725),\n",
       " (1.0, 0.7333333333333333, 0.47058823529411764),\n",
       " (0.17254901960784313, 0.6274509803921569, 0.17254901960784313),\n",
       " (0.596078431372549, 0.8745098039215686, 0.5411764705882353)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clist = ['#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a']\n",
    "sns.color_palette(clist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.2.min.js\": \"XypntL49z55iwGVUW4qsEu83zKL3XEcz0MjuGOQ9SlaaQ68X/g+k1FcioZi7oQAc\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.2.min.js\": \"bEsM86IHGDTLCS0Zod8a8WM6Y4+lafAL/eSiyQcuPzinmWNgNO2/olUF0Z2Dkn5i\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.2.min.js\": \"TX0gSQTdXTTeScqxj6PVQxTiRW8DOoGVwinyi1D3kxv7wuxQ02XkOxv0xwiypcAH\"};\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.2.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.2.min.js\": \"XypntL49z55iwGVUW4qsEu83zKL3XEcz0MjuGOQ9SlaaQ68X/g+k1FcioZi7oQAc\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.2.min.js\": \"bEsM86IHGDTLCS0Zod8a8WM6Y4+lafAL/eSiyQcuPzinmWNgNO2/olUF0Z2Dkn5i\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.2.min.js\": \"TX0gSQTdXTTeScqxj6PVQxTiRW8DOoGVwinyi1D3kxv7wuxQ02XkOxv0xwiypcAH\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.2.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Range1d\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.layouts import gridplot\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainDir = \"C://Users//JosephVermeil//Desktop//ActinCortexAnalysis\"\n",
    "# mainDir = \"C://Users//josep//Desktop//ActinCortexAnalysis\"\n",
    "experimentalDataDir = os.path.join(mainDir, \"ExperimentalData\")\n",
    "dataDir = os.path.join(mainDir, \"DataAnalysis\")\n",
    "figDir = os.path.join(dataDir, \"Figures\")\n",
    "todayFigDir = os.path.join(figDir, \"Historique//\" + str(date.today()))\n",
    "timeSeriesDataDir = os.path.join(dataDir, \"TimeSeriesData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Display all detected time Series Data Files.\n",
    "\n",
    "# allTimeSeriesDataFiles = [f for f in os.listdir(timeSeriesDataDir) if (os.path.isfile(os.path.join(timeSeriesDataDir, f)) and f.endswith(\".csv\"))]\n",
    "# allTimeSeriesDataFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some generic useful subfunctions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0,
     8,
     31,
     55
    ]
   },
   "outputs": [],
   "source": [
    "def get_R2(Y1, Y2):\n",
    "    meanY = np.mean(Y1)\n",
    "    meanYarray = meanY*np.ones(len(Y1))\n",
    "    SST = np.sum((Y1-meanYarray)**2)\n",
    "    SSE = np.sum((Y2-meanYarray)**2)\n",
    "    R2 = SSE/SST\n",
    "    return(R2)\n",
    "\n",
    "def getDictAggMean(df):\n",
    "    dictAggMean = {}\n",
    "    for c in df.columns:\n",
    "    #         t = df[c].dtype\n",
    "    #         print(c, t)\n",
    "            try :\n",
    "                if np.array_equal(df[c], df[c].astype(bool)):\n",
    "                    dictAggMean[c] = 'min'\n",
    "                else:\n",
    "                    try:\n",
    "                        if not c.isnull().all():\n",
    "                            np.mean(df[c])\n",
    "                            dictAggMean[c] = 'mean'\n",
    "                    except:\n",
    "                        dictAggMean[c] = 'first'\n",
    "            except:\n",
    "                    dictAggMean[c] = 'first'\n",
    "    return(dictAggMean)\n",
    "\n",
    "def findFirst(x, A):\n",
    "    idx = (A==x).view(bool).argmax()\n",
    "    return(idx)\n",
    "\n",
    "def fitLine(X, Y):\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(Y, X)\n",
    "    results = model.fit()\n",
    "    params = results.params # Y=a*X+b ; params[0] = b,  params[1] = a\n",
    "#     print(dir(results))\n",
    "#     R2 = results.rsquared\n",
    "#     ci = results.conf_int(alpha=0.05)\n",
    "#     CovM = results.cov_params()\n",
    "#     p = results.pvalues\n",
    "\n",
    "# This is how are computed conf_int:\n",
    "#\n",
    "#     bse = results.bse\n",
    "#     dist = stats.t\n",
    "#     alpha = 0.05\n",
    "#     q = dist.ppf(1 - alpha / 2, results.df_resid)\n",
    "#     params = results.params\n",
    "#     lower = params - q * bse\n",
    "#     upper = params + q * bse\n",
    "#     print(lower, upper)\n",
    "    \n",
    "    return(results.params, results)\n",
    "\n",
    "def archiveFig(fig, ax, name='auto', figDir = todayFigDir, figSubDir=''):\n",
    "    if not os.path.exists(figDir):\n",
    "        os.makedirs(figDir)\n",
    "    \n",
    "    saveDir = os.path.join(todayFigDir, figSubDir)\n",
    "    if not os.path.exists(saveDir):\n",
    "        os.makedirs(saveDir)\n",
    "    \n",
    "    if name != 'auto':\n",
    "        fig.savefig(os.path.join(saveDir, name + '.png'))\n",
    "    \n",
    "    else:\n",
    "        suptitle = fig._suptitle.get_text()\n",
    "        if len(suptitle) > 0:\n",
    "            name = suptitle\n",
    "            fig.savefig(os.path.join(saveDir, name + '.png'))\n",
    "        \n",
    "        else:\n",
    "            try:\n",
    "                N = len(ax)\n",
    "                ax = ax[0]\n",
    "            except:\n",
    "                N = 1\n",
    "                ax = ax\n",
    "                \n",
    "            xlabel = ax.get_xlabel()\n",
    "            ylabel = ax.get_ylabel()\n",
    "            if len(xlabel) > 0 and len(ylabel) > 0:\n",
    "                name = ylabel + ' Vs ' + xlabel\n",
    "                if N > 1:\n",
    "                    name = name + '___etc'\n",
    "                fig.savefig(os.path.join(saveDir, name + '.png'))\n",
    "            \n",
    "            else:\n",
    "                title = ax.get_title()\n",
    "                if len(title) > 0:\n",
    "                    if N > 1:\n",
    "                        name = name + '___etc'\n",
    "                    fig.savefig(os.path.join(saveDir, name + '.png'))\n",
    "                \n",
    "                else:\n",
    "                    figNum = gcf().number\n",
    "                    name = 'figure ' + str(figNum) \n",
    "                    fig.savefig(os.path.join(saveDir, name + '.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: How to compute confidence invetervals of fitted parameters with (1-alpha) confidence:\n",
    "\n",
    "    0) from scipy import stats\n",
    "    1) df = nb_pts - nb_parms ; se = diag(cov)**0.5\n",
    "    2) Student t coefficient : q = stat.t.ppf(1 - alpha / 2, df)\n",
    "    3) ConfInt = [params - q*se, params + q*se]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Test of the fitLine function\n",
    "\n",
    "# Npts = 10\n",
    "# seed = 10\n",
    "# std = 2\n",
    "\n",
    "# np.random.seed(seed)\n",
    "# X = np.array([i for i in range(Npts)])\n",
    "# Y = np.array([i for i in range(Npts)])\n",
    "# Y = Y + np.random.normal(0, std, Npts)\n",
    "# p, R = fitLine(X, Y)\n",
    "\n",
    "# Ypred = p[1]*X+p[0]\n",
    "# fig, ax = plt.subplots(1,1)\n",
    "# ax.plot(X, Y, 'bo')\n",
    "# ax.plot(X, Ypred, 'r-', label='best fit')\n",
    "# ax.legend(loc='best')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Test of the lmfit library // <examples/doc_model_gaussian.py>\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from lmfit import Model\n",
    "\n",
    "# np.random.seed(seed)\n",
    "\n",
    "# x = np.array([i for i in range(Npts)])\n",
    "# y = np.array([i for i in range(Npts)])\n",
    "# y = y + np.random.normal(0, std, Npts)\n",
    "\n",
    "\n",
    "# # def gaussian(x, amp, cen, wid):\n",
    "# #     \"\"\"1-d gaussian: gaussian(x, amp, cen, wid)\"\"\"\n",
    "# #     return (amp / (sqrt(2*pi) * wid)) * exp(-(x-cen)**2 / (2*wid**2))\n",
    "\n",
    "# def linear(x, a, b):\n",
    "#     \"\"\"linear function\"\"\"\n",
    "#     return (a*x + b)\n",
    "\n",
    "# # gmodel = Model(gaussian)\n",
    "# # result = gmodel.fit(y, x=x, amp=5, cen=5, wid=1)\n",
    "\n",
    "# # print(result.fit_report())\n",
    "\n",
    "# # plt.plot(x, y, 'bo')\n",
    "# # plt.plot(x, result.init_fit, 'k--', label='initial fit')\n",
    "# # plt.plot(x, result.best_fit, 'r-', label='best fit')\n",
    "# # plt.legend(loc='best')\n",
    "# # plt.show()\n",
    "\n",
    "# lmodel = Model(linear)\n",
    "# result = lmodel.fit(y, x=x, a=1.5, b=-1)\n",
    "\n",
    "# print(result.fit_report())\n",
    "\n",
    "# fig, ax = plt.subplots(1,1)\n",
    "# ax.plot(x, y, 'bo')\n",
    "# # ax.plot(x, result.init_fit, 'k--', label='initial fit')\n",
    "# ax.plot(x, result.best_fit, 'r-', label='best fit')\n",
    "# ax.legend(loc='best')\n",
    "# fig.show()\n",
    "\n",
    "# # print(dir(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test of the curve_fit function and subsequent computation of confidence intervals\n",
    "\n",
    "# np.random.seed(seed)\n",
    "\n",
    "# x = np.array([i for i in range(Npts)])\n",
    "# y = np.array([i for i in range(Npts)])\n",
    "# y = y + np.random.normal(0, std, Npts)\n",
    "\n",
    "# def linear(x, a, b):\n",
    "#     \"\"\"linear function\"\"\"\n",
    "#     return (a*x + b)\n",
    "\n",
    "\n",
    "# initialParameters = [1.5, -1]\n",
    "# #     print(initialParameters)\n",
    "\n",
    "# # bounds on parameters - initial parameters must be within these\n",
    "# lowerBounds = (-np.Inf, -np.Inf)\n",
    "# upperBounds = (np.Inf, np.Inf)\n",
    "# parameterBounds = [lowerBounds, upperBounds]\n",
    "\n",
    "# # fittedParameters, pcov = curve_fit(chadwickModel, hCompr, fCompr, initialParameters, bounds = parameterBounds)\n",
    "# fittedParameters, pcov = curve_fit(linear, x, y, initialParameters, bounds = parameterBounds)\n",
    "\n",
    "# A, B = fittedParameters\n",
    "# print(A, B)\n",
    "# ypredict = linear(x, A, B)\n",
    "\n",
    "# varA = pcov[0,0]\n",
    "# print(pcov)\n",
    "# print(pcov[0,0]**0.5)\n",
    "# SSR = np.sum((np.array(y)-np.array(ypredict))**2)\n",
    "# seA = ((SSR/(len(x)-2))*varA)**0.5\n",
    "# seA = (varA)**0.5\n",
    "# confIntA = st.t.interval(alpha=0.95, df=len(x)-2, loc=A, scale=seA)\n",
    "# confIntAHalfWidthBis = st.t.ppf(0.975, len(x)-2) * seA\n",
    "# print(confIntAHalfWidthBis)\n",
    "# # confIntA = (A + seA*st.t.interval(alpha=0.95, df=len(x), loc=0, scale=1)[0], A + seA*st.t.interval(alpha=0.95, df=len(x), loc=0, scale=1)[1])\n",
    "# confIntAWidth = confIntA[1] - confIntA[0]\n",
    "# confIntAHalfWidth = confIntAWidth/2\n",
    "# R2 = get_R2(y,ypredict)\n",
    "\n",
    "# print(str(A) + ' +/- ' + str(confIntAHalfWidth))\n",
    "\n",
    "# fig, ax = plt.subplots(1,1)\n",
    "# ax.plot(x, y, 'bo')\n",
    "# ax.plot(x, ypredict, 'r-', label='best fit')\n",
    "# ax.legend(loc='best')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Test of the get_R2 function.\n",
    "# T = df['T']\n",
    "# Y = df['D3']\n",
    "# plt.plot(T,Y)\n",
    "# p, residuals, rank, singular_values, rcond = np.polyfit(T, Y, deg=5, full=True)\n",
    "# plt.plot(T, Y)\n",
    "# Y2 = np.zeros(len(T))\n",
    "# for i in range(len(T)):\n",
    "#     deg = len(p)-1\n",
    "#     for k in range(deg+1):\n",
    "#         Y2[i] += p[k]*(T[i]**(deg-k))\n",
    "# plt.plot(T,Y2)\n",
    "# get_R2(Y, Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TimeSeries functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     16,
     20,
     39,
     60
    ]
   },
   "outputs": [],
   "source": [
    "def getCellTimeSeriesData(cellID):\n",
    "    allTimeSeriesDataFiles = [f for f in os.listdir(timeSeriesDataDir) if (os.path.isfile(os.path.join(timeSeriesDataDir, f)) and f.endswith(\".csv\"))]\n",
    "    fileFound = False\n",
    "    nFile = len(allTimeSeriesDataFiles)\n",
    "    iFile = 0\n",
    "    while (not fileFound) and (iFile < nFile):\n",
    "        f = allTimeSeriesDataFiles[iFile]\n",
    "        if f.startswith(cellID):\n",
    "            timeSeriesDataFilePath = os.path.join(timeSeriesDataDir, f)\n",
    "            timeSeriesDataFrame = pd.read_csv(timeSeriesDataFilePath, sep=';')\n",
    "            fileFound = True\n",
    "        iFile += 1\n",
    "    if not fileFound:\n",
    "        timeSeriesDataFrame = pd.DataFrame([])\n",
    "    else:\n",
    "        for c in timeSeriesDataFrame.columns:\n",
    "                if 'Unnamed' in c:\n",
    "                    timeSeriesDataFrame = timeSeriesDataFrame.drop([c], axis=1)\n",
    "    return(timeSeriesDataFrame)\n",
    "\n",
    "def plotCellTimeSeriesData(cellID):\n",
    "    X = 'T'\n",
    "    Y = np.array(['B', 'F', 'dx', 'dy', 'dz', 'D2', 'D3'])\n",
    "    units = np.array([' (mT)', ' (pN)', ' (µm)', ' (µm)', ' (µm)', ' (µm)', ' (µm)'])\n",
    "    timeSeriesDataFrame = getCellTimeSeriesData(cellID)\n",
    "    if not timeSeriesDataFrame.size == 0:\n",
    "#         plt.tight_layout()\n",
    "#         fig.show() # figsize=(20,20)\n",
    "        axes = timeSeriesDataFrame.plot(x=X, y=Y, kind='line', ax=None, subplots=True, sharex=True, sharey=False, layout=None, \\\n",
    "                       figsize=(8,10), use_index=True, title = cellID + '- Time dependant data', grid=None, legend=False, style=None, logx=False, logy=False, \\\n",
    "                       loglog=False, xticks=None, yticks=None, xlim=None, ylim=None, rot=None, fontsize=None, colormap=None, \\\n",
    "                       table=False, yerr=None, xerr=None, secondary_y=False, sort_columns=False)\n",
    "        plt.gcf().tight_layout()\n",
    "        for i in range(len(Y)):\n",
    "            axes[i].set_ylabel(Y[i] + units[i])\n",
    "        \n",
    "    else:\n",
    "        print('cell not found')\n",
    "        \n",
    "def addExcludedCell(cellID, motive):\n",
    "    f = open(os.path.join(experimentalDataDir, 'ExcludedCells.txt'), 'r')\n",
    "    lines = f.readlines()\n",
    "    nLines = len(lines)\n",
    "    excludedCellsList = []\n",
    "    for iLine in range(nLines):\n",
    "        line = lines[iLine]\n",
    "        splitLine = line[:-1].split(',')\n",
    "        excludedCellsList.append(splitLine[0])\n",
    "    if cellID in excludedCellsList:\n",
    "        newlines = copy(lines)\n",
    "        iLineOfInterest = excludedCellsList.index(cellID)\n",
    "        if motive not in newlines[iLineOfInterest][:-1].split(','):\n",
    "            newlines[iLineOfInterest] = newlines[iLineOfInterest][:-1] + ',' + motive + '\\n'            \n",
    "    else:\n",
    "        newlines = copy(lines)\n",
    "        newlines.append('' + cellID + ',' + motive + '\\n')\n",
    "    f.close()\n",
    "    f = open(os.path.join(experimentalDataDir, 'ExcludedCells.txt'), 'w')\n",
    "    f.writelines(newlines)\n",
    "    \n",
    "def getExcludedCells():\n",
    "    f = open(os.path.join(experimentalDataDir, 'ExcludedCells.txt'), 'r')\n",
    "    lines = f.readlines()\n",
    "    nLines = len(lines)\n",
    "    excludedCellsDict = {}\n",
    "    for iLine in range(nLines):\n",
    "        line = lines[iLine]\n",
    "        splitLine = line[:-1].split(',')\n",
    "        excludedCellsDict[splitLine[0]] = splitLine[1:]\n",
    "    return(excludedCellsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idxCompression</th>\n",
       "      <th>T</th>\n",
       "      <th>Tabs</th>\n",
       "      <th>B</th>\n",
       "      <th>F</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "      <th>dz</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.726</td>\n",
       "      <td>16717.461</td>\n",
       "      <td>6.15123</td>\n",
       "      <td>142.903483</td>\n",
       "      <td>4.598671</td>\n",
       "      <td>0.425696</td>\n",
       "      <td>0.278339</td>\n",
       "      <td>4.618332</td>\n",
       "      <td>4.626712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.326</td>\n",
       "      <td>16718.061</td>\n",
       "      <td>6.15369</td>\n",
       "      <td>142.810633</td>\n",
       "      <td>4.600063</td>\n",
       "      <td>0.434620</td>\n",
       "      <td>0.262935</td>\n",
       "      <td>4.620549</td>\n",
       "      <td>4.628025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.926</td>\n",
       "      <td>16718.661</td>\n",
       "      <td>6.15492</td>\n",
       "      <td>143.290588</td>\n",
       "      <td>4.597342</td>\n",
       "      <td>0.440633</td>\n",
       "      <td>0.246409</td>\n",
       "      <td>4.618410</td>\n",
       "      <td>4.624979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.526</td>\n",
       "      <td>16719.261</td>\n",
       "      <td>6.15369</td>\n",
       "      <td>143.970811</td>\n",
       "      <td>4.594241</td>\n",
       "      <td>0.436266</td>\n",
       "      <td>0.228916</td>\n",
       "      <td>4.614908</td>\n",
       "      <td>4.620582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.125</td>\n",
       "      <td>16719.860</td>\n",
       "      <td>6.15492</td>\n",
       "      <td>143.961890</td>\n",
       "      <td>4.595886</td>\n",
       "      <td>0.437468</td>\n",
       "      <td>0.210633</td>\n",
       "      <td>4.616660</td>\n",
       "      <td>4.621462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>0</td>\n",
       "      <td>119.675</td>\n",
       "      <td>16836.410</td>\n",
       "      <td>6.15123</td>\n",
       "      <td>149.158059</td>\n",
       "      <td>4.568418</td>\n",
       "      <td>0.416835</td>\n",
       "      <td>-0.050157</td>\n",
       "      <td>4.587395</td>\n",
       "      <td>4.587669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>0</td>\n",
       "      <td>120.275</td>\n",
       "      <td>16837.010</td>\n",
       "      <td>6.15123</td>\n",
       "      <td>148.984697</td>\n",
       "      <td>4.568861</td>\n",
       "      <td>0.417595</td>\n",
       "      <td>-0.078146</td>\n",
       "      <td>4.587905</td>\n",
       "      <td>4.588571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>0</td>\n",
       "      <td>120.875</td>\n",
       "      <td>16837.610</td>\n",
       "      <td>6.15369</td>\n",
       "      <td>148.166412</td>\n",
       "      <td>4.573797</td>\n",
       "      <td>0.420506</td>\n",
       "      <td>-0.107096</td>\n",
       "      <td>4.593087</td>\n",
       "      <td>4.594335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>0</td>\n",
       "      <td>121.474</td>\n",
       "      <td>16838.209</td>\n",
       "      <td>6.15492</td>\n",
       "      <td>148.665066</td>\n",
       "      <td>4.568797</td>\n",
       "      <td>0.423038</td>\n",
       "      <td>-0.136590</td>\n",
       "      <td>4.588341</td>\n",
       "      <td>4.590373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0</td>\n",
       "      <td>122.074</td>\n",
       "      <td>16838.809</td>\n",
       "      <td>6.15492</td>\n",
       "      <td>148.286553</td>\n",
       "      <td>4.568101</td>\n",
       "      <td>0.433797</td>\n",
       "      <td>-0.166413</td>\n",
       "      <td>4.588652</td>\n",
       "      <td>4.591669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1595 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      idxCompression        T       Tabs        B           F        dx  \\\n",
       "0                  0    0.726  16717.461  6.15123  142.903483  4.598671   \n",
       "1                  0    1.326  16718.061  6.15369  142.810633  4.600063   \n",
       "2                  0    1.926  16718.661  6.15492  143.290588  4.597342   \n",
       "3                  0    2.526  16719.261  6.15369  143.970811  4.594241   \n",
       "4                  0    3.125  16719.860  6.15492  143.961890  4.595886   \n",
       "...              ...      ...        ...      ...         ...       ...   \n",
       "1590               0  119.675  16836.410  6.15123  149.158059  4.568418   \n",
       "1591               0  120.275  16837.010  6.15123  148.984697  4.568861   \n",
       "1592               0  120.875  16837.610  6.15369  148.166412  4.573797   \n",
       "1593               0  121.474  16838.209  6.15492  148.665066  4.568797   \n",
       "1594               0  122.074  16838.809  6.15492  148.286553  4.568101   \n",
       "\n",
       "            dy        dz        D2        D3  \n",
       "0     0.425696  0.278339  4.618332  4.626712  \n",
       "1     0.434620  0.262935  4.620549  4.628025  \n",
       "2     0.440633  0.246409  4.618410  4.624979  \n",
       "3     0.436266  0.228916  4.614908  4.620582  \n",
       "4     0.437468  0.210633  4.616660  4.621462  \n",
       "...        ...       ...       ...       ...  \n",
       "1590  0.416835 -0.050157  4.587395  4.587669  \n",
       "1591  0.417595 -0.078146  4.587905  4.588571  \n",
       "1592  0.420506 -0.107096  4.593087  4.594335  \n",
       "1593  0.423038 -0.136590  4.588341  4.590373  \n",
       "1594  0.433797 -0.166413  4.588652  4.591669  \n",
       "\n",
       "[1595 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = getCellTimeSeriesData('21-01-18_M1_P1_C1')\n",
    "# plotCellTimeSeriesData('21-01-21_M1_P1_C11')\n",
    "# plotCellTimeSeriesData('21-04-21_M1_P1_C5')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GlobalTables functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def getExperimentalConditions(save = False):\n",
    "    # Getting the table\n",
    "    experimentalDataFile = 'ExperimentalConditions.csv'\n",
    "    experimentalDataFilePath = os.path.join(experimentalDataDir, experimentalDataFile)\n",
    "    expConditionsDF = pd.read_csv(experimentalDataFilePath, sep=';',header=0)\n",
    "    print('Extracted a table with ' + str(expConditionsDF.shape[0]) + ' lines and ' + str(expConditionsDF.shape[1]) + ' columns.')\n",
    "    \n",
    "    # Cleaning the table\n",
    "    try:\n",
    "        for c in expConditionsDF.columns:\n",
    "            if 'Unnamed' in c:\n",
    "                expConditionsDF = expConditionsDF.drop([c], axis=1)\n",
    "        expConditionsDF = expConditionsDF.convert_dtypes()\n",
    "\n",
    "        listTextColumns = []\n",
    "        for col in expConditionsDF.columns:\n",
    "            try:\n",
    "                if expConditionsDF[col].dtype == 'string':\n",
    "                    listTextColumns.append(col)\n",
    "            except:\n",
    "                aaaa=0\n",
    "                #Ok\n",
    "\n",
    "        expConditionsDF[listTextColumns] = expConditionsDF[listTextColumns].apply(lambda x: x.str.replace(',','.'))\n",
    "\n",
    "        expConditionsDF['scale pixel per um'] = expConditionsDF['scale pixel per um'].astype(float)\n",
    "        try:\n",
    "            expConditionsDF['optical index correction'] = \\\n",
    "                      expConditionsDF['optical index correction'].apply(lambda x: x.split('/')[0]).astype(float) \\\n",
    "                    / expConditionsDF['optical index correction'].apply(lambda x: x.split('/')[1]).astype(float)\n",
    "        except:\n",
    "            print('optical index correction already in ' + str(expConditionsDF['optical index correction'].dtype) + ' type.')\n",
    "\n",
    "        expConditionsDF['magnetic field correction'] = expConditionsDF['magnetic field correction'].astype(float)\n",
    "        expConditionsDF['with fluo images'] = expConditionsDF['with fluo images'].astype(bool)\n",
    "\n",
    "        try:\n",
    "            expConditionsDF['ramp field'] = \\\n",
    "            expConditionsDF['ramp field'].apply(lambda x: [x.split(';')[0], x.split(';')[1]] if not pd.isnull(x) else [])\n",
    "        except:\n",
    "            aaaa=0\n",
    "            #Ok\n",
    "\n",
    "        dateExemple = expConditionsDF.loc[expConditionsDF.index[1],'date']\n",
    "\n",
    "        if re.match(dateFormatExcel, dateExemple):\n",
    "            print('dates corrected')\n",
    "            expConditionsDF.loc[1:,'date'] = expConditionsDF.loc[1:,'date'].apply(lambda x: x.split('/')[0] + '-' + x.split('/')[1] + '-' + x.split('/')[2][2:])        \n",
    "        \n",
    "    except:\n",
    "        print('Unexpected bug with the cleaning step')\n",
    "\n",
    "    if save:\n",
    "        saveName = 'ExperimentalConditions.csv'\n",
    "        savePath = os.path.join(experimentalDataDir, saveName)\n",
    "        expConditionsDF.to_csv(savePath, sep=';')\n",
    "\n",
    "    expConditionsDF['manipID'] = expConditionsDF['date'] + '_' + expConditionsDF['manip']\n",
    "    \n",
    "    return(expConditionsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted a table with 40 lines and 22 columns.\n",
      "optical index correction already in Float64 type.\n",
      "dates corrected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>manip</th>\n",
       "      <th>experimentType</th>\n",
       "      <th>drug</th>\n",
       "      <th>substrate</th>\n",
       "      <th>objective magnification</th>\n",
       "      <th>scale pixel per um</th>\n",
       "      <th>objective immersion</th>\n",
       "      <th>optical index correction</th>\n",
       "      <th>magnetic field correction</th>\n",
       "      <th>...</th>\n",
       "      <th>bead type</th>\n",
       "      <th>bead diameter</th>\n",
       "      <th>normal field</th>\n",
       "      <th>ramp field</th>\n",
       "      <th>compression duration</th>\n",
       "      <th>with fluo images</th>\n",
       "      <th>bacteria</th>\n",
       "      <th>comments</th>\n",
       "      <th>beads bright spot delta</th>\n",
       "      <th>manipID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEFAULT</td>\n",
       "      <td>DEFAULT</td>\n",
       "      <td>DEFAULT</td>\n",
       "      <td>DEFAULT</td>\n",
       "      <td>DEFAULT</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DEFAULT_DEFAULT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20-08-04</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions and constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>BSA coated glass</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>10</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20-08-04_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20-08-04</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions and constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>BSA coated glass</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>10</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20-08-04_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20-08-05</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions and constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>BSA coated glass</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>10</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20-08-05_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20-08-05</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions and constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>BSA coated glass</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>10</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20-08-05_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20-08-07</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions and constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>BSA coated glass</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>10</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20-08-07_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20-08-07</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions and constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>BSA coated glass</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>10</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20-08-07_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21-01-18</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-01-18_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21-01-18</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-01-18_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21-01-18</td>\n",
       "      <td>M3</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-01-18_M3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21-01-21</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-01-21_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21-01-21</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-01-21_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21-01-21</td>\n",
       "      <td>M3</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-01-21_M3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21-02-10</td>\n",
       "      <td>M1</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.20</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-02-10_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21-02-10</td>\n",
       "      <td>M2</td>\n",
       "      <td>constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.20</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-02-10_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21-02-15</td>\n",
       "      <td>M1</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>diverse fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-02-15_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21-02-15</td>\n",
       "      <td>M2</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>diverse fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-02-15_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21-02-15</td>\n",
       "      <td>M3</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>diverse fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-02-15_M3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20-12-16</td>\n",
       "      <td>M1</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20-12-16_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20-12-16</td>\n",
       "      <td>M2</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20-12-16_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21-03-25</td>\n",
       "      <td>M1</td>\n",
       "      <td>constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.12</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-03-25_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21-03-25</td>\n",
       "      <td>M2</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.12</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-03-25_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21-04-21</td>\n",
       "      <td>M1</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-04-21_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21-04-21</td>\n",
       "      <td>M2</td>\n",
       "      <td>constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-04-21_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21-04-23</td>\n",
       "      <td>M1</td>\n",
       "      <td>constant field</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-04-23_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>21-04-23</td>\n",
       "      <td>M2</td>\n",
       "      <td>constant field</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-04-23_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21-04-27</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-04-27_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21-04-27</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-04-27_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>21-04-28</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-04-28_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>21-04-28</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-04-28_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>21-06-16</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-06-16_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21-06-16</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-06-16_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>21-06-17</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>doxycyclin</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-06-17_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>21-06-17</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M450</td>\n",
       "      <td>4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-06-17_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>21-05-21</td>\n",
       "      <td>M1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M450_M270</td>\n",
       "      <td>4503_2691</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.2</td>\n",
       "      <td>21-05-21_M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>21-07-08</td>\n",
       "      <td>M1.1</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M270_M450</td>\n",
       "      <td>2691_4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-07-08_M1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>21-07-08</td>\n",
       "      <td>M1.2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M270_M270</td>\n",
       "      <td>2691_2691</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-07-08_M1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>21-07-08</td>\n",
       "      <td>M2</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M270_M270</td>\n",
       "      <td>2691_2691</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-07-08_M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>21-07-08</td>\n",
       "      <td>M3</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M450_M270</td>\n",
       "      <td>4503_2691</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-07-08_M3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>21-07-08</td>\n",
       "      <td>M4</td>\n",
       "      <td>compressions</td>\n",
       "      <td>none</td>\n",
       "      <td>20um fibronectin discs</td>\n",
       "      <td>100X</td>\n",
       "      <td>15.8</td>\n",
       "      <td>oil</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>M450_M450</td>\n",
       "      <td>4503_4503</td>\n",
       "      <td>5</td>\n",
       "      <td>['3'. '40']</td>\n",
       "      <td>1s</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>21-07-08_M4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    manip                   experimentType        drug  \\\n",
       "0    DEFAULT  DEFAULT                          DEFAULT     DEFAULT   \n",
       "1   20-08-04       M1  compressions and constant field        none   \n",
       "2   20-08-04       M2  compressions and constant field  doxycyclin   \n",
       "3   20-08-05       M1  compressions and constant field  doxycyclin   \n",
       "4   20-08-05       M2  compressions and constant field        none   \n",
       "5   20-08-07       M1  compressions and constant field  doxycyclin   \n",
       "6   20-08-07       M2  compressions and constant field        none   \n",
       "7   21-01-18       M1                     compressions  doxycyclin   \n",
       "8   21-01-18       M2                     compressions        none   \n",
       "9   21-01-18       M3                     compressions  doxycyclin   \n",
       "10  21-01-21       M1                     compressions        none   \n",
       "11  21-01-21       M2                     compressions  doxycyclin   \n",
       "12  21-01-21       M3                     compressions        none   \n",
       "13  21-02-10       M1                   constant field        none   \n",
       "14  21-02-10       M2                   constant field  doxycyclin   \n",
       "15  21-02-15       M1                   constant field        none   \n",
       "16  21-02-15       M2                   constant field        none   \n",
       "17  21-02-15       M3                   constant field        none   \n",
       "18  20-12-16       M1                   constant field        none   \n",
       "19  20-12-16       M2                   constant field        none   \n",
       "20  21-03-25       M1                   constant field  doxycyclin   \n",
       "21  21-03-25       M2                   constant field        none   \n",
       "22  21-04-21       M1                   constant field        none   \n",
       "23  21-04-21       M2                   constant field  doxycyclin   \n",
       "24  21-04-23       M1                   constant field  doxycyclin   \n",
       "25  21-04-23       M2                   constant field        none   \n",
       "26  21-04-27       M1                     compressions        none   \n",
       "27  21-04-27       M2                     compressions  doxycyclin   \n",
       "28  21-04-28       M1                     compressions  doxycyclin   \n",
       "29  21-04-28       M2                     compressions        none   \n",
       "30  21-06-16       M1                     compressions        none   \n",
       "31  21-06-16       M2                     compressions  doxycyclin   \n",
       "32  21-06-17       M1                     compressions  doxycyclin   \n",
       "33  21-06-17       M2                     compressions        none   \n",
       "34  21-05-21       M1                     compressions        none   \n",
       "35  21-07-08     M1.1                     compressions        none   \n",
       "36  21-07-08     M1.2                     compressions        none   \n",
       "37  21-07-08       M2                     compressions        none   \n",
       "38  21-07-08       M3                     compressions        none   \n",
       "39  21-07-08       M4                     compressions        none   \n",
       "\n",
       "                    substrate objective magnification  scale pixel per um  \\\n",
       "0                     DEFAULT                    100X                15.8   \n",
       "1            BSA coated glass                    100X                15.8   \n",
       "2            BSA coated glass                    100X                15.8   \n",
       "3            BSA coated glass                    100X                15.8   \n",
       "4            BSA coated glass                    100X                15.8   \n",
       "5            BSA coated glass                    100X                15.8   \n",
       "6            BSA coated glass                    100X                15.8   \n",
       "7      20um fibronectin discs                    100X                15.8   \n",
       "8      20um fibronectin discs                    100X                15.8   \n",
       "9      20um fibronectin discs                    100X                15.8   \n",
       "10     20um fibronectin discs                    100X                15.8   \n",
       "11     20um fibronectin discs                    100X                15.8   \n",
       "12     20um fibronectin discs                    100X                15.8   \n",
       "13     20um fibronectin discs                    100X                15.8   \n",
       "14     20um fibronectin discs                    100X                15.8   \n",
       "15  diverse fibronectin discs                    100X                15.8   \n",
       "16  diverse fibronectin discs                    100X                15.8   \n",
       "17  diverse fibronectin discs                    100X                15.8   \n",
       "18     20um fibronectin discs                    100X                15.8   \n",
       "19     20um fibronectin discs                    100X                15.8   \n",
       "20     20um fibronectin discs                    100X                15.8   \n",
       "21     20um fibronectin discs                    100X                15.8   \n",
       "22     20um fibronectin discs                    100X                15.8   \n",
       "23     20um fibronectin discs                    100X                15.8   \n",
       "24     20um fibronectin discs                    100X                15.8   \n",
       "25     20um fibronectin discs                    100X                15.8   \n",
       "26     20um fibronectin discs                    100X                15.8   \n",
       "27     20um fibronectin discs                    100X                15.8   \n",
       "28     20um fibronectin discs                    100X                15.8   \n",
       "29     20um fibronectin discs                    100X                15.8   \n",
       "30     20um fibronectin discs                    100X                15.8   \n",
       "31     20um fibronectin discs                    100X                15.8   \n",
       "32     20um fibronectin discs                    100X                15.8   \n",
       "33     20um fibronectin discs                    100X                15.8   \n",
       "34     20um fibronectin discs                    100X                15.8   \n",
       "35     20um fibronectin discs                    100X                15.8   \n",
       "36     20um fibronectin discs                    100X                15.8   \n",
       "37     20um fibronectin discs                    100X                15.8   \n",
       "38     20um fibronectin discs                    100X                15.8   \n",
       "39     20um fibronectin discs                    100X                15.8   \n",
       "\n",
       "   objective immersion  optical index correction  magnetic field correction  \\\n",
       "0                  oil                     0.875                       1.15   \n",
       "1                  oil                     0.875                       1.15   \n",
       "2                  oil                     0.875                       1.15   \n",
       "3                  oil                     0.875                       1.15   \n",
       "4                  oil                     0.875                       1.15   \n",
       "5                  oil                     0.875                       1.15   \n",
       "6                  oil                     0.875                       1.15   \n",
       "7                  oil                     0.875                       1.23   \n",
       "8                  oil                     0.875                       1.23   \n",
       "9                  oil                     0.875                       1.23   \n",
       "10                 oil                     0.875                       1.23   \n",
       "11                 oil                     0.875                       1.23   \n",
       "12                 oil                     0.875                       1.23   \n",
       "13                 oil                     0.875                       1.20   \n",
       "14                 oil                     0.875                       1.20   \n",
       "15                 oil                     0.875                       1.10   \n",
       "16                 oil                     0.875                       1.10   \n",
       "17                 oil                     0.875                       1.10   \n",
       "18                 oil                     0.875                       1.26   \n",
       "19                 oil                     0.875                       1.26   \n",
       "20                 oil                     0.875                       1.12   \n",
       "21                 oil                     0.875                       1.12   \n",
       "22                 oil                     0.875                       1.15   \n",
       "23                 oil                     0.875                       1.15   \n",
       "24                 oil                     0.875                       1.15   \n",
       "25                 oil                     0.875                       1.15   \n",
       "26                 oil                     0.875                       1.15   \n",
       "27                 oil                     0.875                       1.15   \n",
       "28                 oil                     0.875                       1.15   \n",
       "29                 oil                     0.875                       1.15   \n",
       "30                 oil                     0.875                       1.10   \n",
       "31                 oil                     0.875                       1.10   \n",
       "32                 oil                     0.875                       1.10   \n",
       "33                 oil                     0.875                       1.10   \n",
       "34                 oil                     0.875                       1.10   \n",
       "35                 oil                     0.875                       1.10   \n",
       "36                 oil                     0.875                       1.10   \n",
       "37                 oil                     0.875                       1.10   \n",
       "38                 oil                     0.875                       1.10   \n",
       "39                 oil                     0.875                       1.10   \n",
       "\n",
       "    ...  bead type bead diameter normal field   ramp field  \\\n",
       "0   ...       M450          4503            5  ['3'. '40']   \n",
       "1   ...       M450          4503           10  ['3'. '40']   \n",
       "2   ...       M450          4503           10  ['3'. '40']   \n",
       "3   ...       M450          4503           10  ['3'. '40']   \n",
       "4   ...       M450          4503           10  ['3'. '40']   \n",
       "5   ...       M450          4503           10  ['3'. '40']   \n",
       "6   ...       M450          4503           10  ['3'. '40']   \n",
       "7   ...       M450          4503            5  ['3'. '40']   \n",
       "8   ...       M450          4503            5  ['3'. '40']   \n",
       "9   ...       M450          4503            5  ['3'. '40']   \n",
       "10  ...       M450          4503            5  ['3'. '40']   \n",
       "11  ...       M450          4503            5  ['3'. '40']   \n",
       "12  ...       M450          4503            5  ['3'. '40']   \n",
       "13  ...       M450          4503            5           []   \n",
       "14  ...       M450          4503            5           []   \n",
       "15  ...       M450          4503            5           []   \n",
       "16  ...       M450          4503            5           []   \n",
       "17  ...       M450          4503            5           []   \n",
       "18  ...       M450          4503            5           []   \n",
       "19  ...       M450          4503            5           []   \n",
       "20  ...       M450          4503            5           []   \n",
       "21  ...       M450          4503            5           []   \n",
       "22  ...       M450          4503            5           []   \n",
       "23  ...       M450          4503            5           []   \n",
       "24  ...       M450          4503            5           []   \n",
       "25  ...       M450          4503            5           []   \n",
       "26  ...       M450          4503            5  ['3'. '40']   \n",
       "27  ...       M450          4503            5  ['3'. '40']   \n",
       "28  ...       M450          4503            5  ['3'. '40']   \n",
       "29  ...       M450          4503            5  ['3'. '40']   \n",
       "30  ...       M450          4503            5  ['3'. '40']   \n",
       "31  ...       M450          4503            5  ['3'. '40']   \n",
       "32  ...       M450          4503            5  ['3'. '40']   \n",
       "33  ...       M450          4503            5  ['3'. '40']   \n",
       "34  ...  M450_M270     4503_2691            5  ['3'. '40']   \n",
       "35  ...  M270_M450     2691_4503            5  ['3'. '40']   \n",
       "36  ...  M270_M270     2691_2691            5  ['3'. '40']   \n",
       "37  ...  M270_M270     2691_2691            5  ['3'. '40']   \n",
       "38  ...  M450_M270     4503_2691            5  ['3'. '40']   \n",
       "39  ...  M450_M450     4503_4503            5  ['3'. '40']   \n",
       "\n",
       "    compression duration with fluo images bacteria  comments  \\\n",
       "0                     1s            False     <NA>      <NA>   \n",
       "1                     1s            False     <NA>      <NA>   \n",
       "2                     1s            False     <NA>      <NA>   \n",
       "3                     1s            False     <NA>      <NA>   \n",
       "4                     1s            False     <NA>      <NA>   \n",
       "5                     1s            False     <NA>      <NA>   \n",
       "6                     1s            False     <NA>      <NA>   \n",
       "7                     1s             True     <NA>      <NA>   \n",
       "8                     1s             True     <NA>      <NA>   \n",
       "9                     1s             True     <NA>      <NA>   \n",
       "10                    1s             True     <NA>      <NA>   \n",
       "11                    1s             True     <NA>      <NA>   \n",
       "12                    1s             True     <NA>      <NA>   \n",
       "13                  <NA>             True     <NA>      <NA>   \n",
       "14                  <NA>             True     <NA>      <NA>   \n",
       "15                  <NA>            False     <NA>      <NA>   \n",
       "16                  <NA>            False     <NA>      <NA>   \n",
       "17                  <NA>            False     <NA>      <NA>   \n",
       "18                  <NA>            False     <NA>      <NA>   \n",
       "19                  <NA>            False     <NA>      <NA>   \n",
       "20                  <NA>             True     <NA>      <NA>   \n",
       "21                  <NA>             True     <NA>      <NA>   \n",
       "22                  <NA>             True     <NA>      <NA>   \n",
       "23                  <NA>             True     <NA>      <NA>   \n",
       "24                  <NA>             True     <NA>      <NA>   \n",
       "25                  <NA>             True     <NA>      <NA>   \n",
       "26                    1s             True     <NA>      <NA>   \n",
       "27                    1s             True     <NA>      <NA>   \n",
       "28                    1s             True     <NA>      <NA>   \n",
       "29                    1s            False     <NA>      <NA>   \n",
       "30                    1s             True     <NA>      <NA>   \n",
       "31                    1s             True     <NA>      <NA>   \n",
       "32                    1s             True     <NA>      <NA>   \n",
       "33                    1s             True     <NA>      <NA>   \n",
       "34                    1s             True     <NA>      <NA>   \n",
       "35                    1s            False     <NA>      <NA>   \n",
       "36                    1s            False     <NA>      <NA>   \n",
       "37                    1s            False     <NA>      <NA>   \n",
       "38                    1s            False     <NA>      <NA>   \n",
       "39                    1s            False     <NA>      <NA>   \n",
       "\n",
       "    beads bright spot delta          manipID  \n",
       "0                       0.0  DEFAULT_DEFAULT  \n",
       "1                       0.0      20-08-04_M1  \n",
       "2                       0.0      20-08-04_M2  \n",
       "3                       0.0      20-08-05_M1  \n",
       "4                       0.0      20-08-05_M2  \n",
       "5                       0.0      20-08-07_M1  \n",
       "6                       0.0      20-08-07_M2  \n",
       "7                       0.0      21-01-18_M1  \n",
       "8                       0.0      21-01-18_M2  \n",
       "9                       0.0      21-01-18_M3  \n",
       "10                      0.0      21-01-21_M1  \n",
       "11                      0.0      21-01-21_M2  \n",
       "12                      0.0      21-01-21_M3  \n",
       "13                      0.0      21-02-10_M1  \n",
       "14                      0.0      21-02-10_M2  \n",
       "15                      0.0      21-02-15_M1  \n",
       "16                      0.0      21-02-15_M2  \n",
       "17                      0.0      21-02-15_M3  \n",
       "18                      0.0      20-12-16_M1  \n",
       "19                      0.0      20-12-16_M2  \n",
       "20                      0.0      21-03-25_M1  \n",
       "21                      0.0      21-03-25_M2  \n",
       "22                      0.0      21-04-21_M1  \n",
       "23                      0.0      21-04-21_M2  \n",
       "24                      0.0      21-04-23_M1  \n",
       "25                      0.0      21-04-23_M2  \n",
       "26                      0.0      21-04-27_M1  \n",
       "27                      0.0      21-04-27_M2  \n",
       "28                      0.0      21-04-28_M1  \n",
       "29                      0.0      21-04-28_M2  \n",
       "30                      0.0      21-06-16_M1  \n",
       "31                      0.0      21-06-16_M2  \n",
       "32                      0.0      21-06-17_M1  \n",
       "33                      0.0      21-06-17_M2  \n",
       "34                      1.2      21-05-21_M1  \n",
       "35                     <NA>    21-07-08_M1.1  \n",
       "36                     <NA>    21-07-08_M1.2  \n",
       "37                     <NA>      21-07-08_M2  \n",
       "38                     <NA>      21-07-08_M3  \n",
       "39                     <NA>      21-07-08_M4  \n",
       "\n",
       "[40 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getExperimentalConditions(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5,
     26,
     47,
     95
    ]
   },
   "outputs": [],
   "source": [
    "listColumnsCtField = ['date','cellName','cellID','manipID',\\\n",
    "                      'duration','medianRawB','medianThickness',\\\n",
    "                      '1stDThickness','9thDThickness','fluctuAmpli',\\\n",
    "                      'R2_polyFit','validated']\n",
    "\n",
    "def analyseTimeSeries_ctField(tsDf):\n",
    "    results = {}\n",
    "    results['duration'] = np.max(tsDf['T'])\n",
    "    results['medianRawB'] = np.median(tsDf.B)\n",
    "    results['medianThickness'] = np.median(tsDf.D3)\n",
    "    results['1stDThickness'] = np.percentile(tsDf.D3, 10)\n",
    "    results['9thDThickness'] = np.percentile(tsDf.D3, 90)\n",
    "    results['fluctuAmpli'] = results['9thDThickness'] - results['1stDThickness']\n",
    "    results['validated'] = (results['1stDThickness'] > 0)\n",
    "    X, Y = tsDf['T'], tsDf['D3']\n",
    "    p, residuals, rank, singular_values, rcond = np.polyfit(X, Y, deg=5, full=True)\n",
    "    Y2 = np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        deg = len(p)-1\n",
    "        for k in range(deg+1):\n",
    "            Y2[i] += p[k]*(X[i]**(deg-k))\n",
    "    results['R2_polyFit'] = get_R2(Y, Y2)\n",
    "    return(results)\n",
    "\n",
    "\n",
    "\n",
    "def createDataDict_ctField(list_ctFieldFiles):\n",
    "    tableDict = {}\n",
    "    tableDict['date'], tableDict['cellName'], tableDict['cellID'], tableDict['manipID'] = [], [], [], []\n",
    "    tableDict['duration'], tableDict['medianRawB'], tableDict['medianThickness'] = [], [], []\n",
    "    tableDict['1stDThickness'], tableDict['9thDThickness'], tableDict['fluctuAmpli'] = [], [], []\n",
    "    tableDict['R2_polyFit'], tableDict['validated'] = [], []\n",
    "    for f in list_ctFieldFiles:\n",
    "        split_f = f.split('_')\n",
    "        tableDict['date'].append(split_f[0])\n",
    "        tableDict['cellName'].append(split_f[1] + '_' + split_f[2] + '_' + split_f[3])\n",
    "        tableDict['cellID'].append(split_f[0] + '_' + split_f[1] + '_' + split_f[2] + '_' + split_f[3])\n",
    "        tableDict['manipID'].append(split_f[0] + '_' + split_f[1])\n",
    "        tS_DataFilePath = os.path.join(timeSeriesDataDir, f)\n",
    "        current_tsDf = pd.read_csv(tS_DataFilePath, ';')\n",
    "        current_resultDict = analyseTimeSeries_ctField(current_tsDf)\n",
    "        for k in current_resultDict.keys():\n",
    "            tableDict[k].append(current_resultDict[k])\n",
    "    return(tableDict)\n",
    "\n",
    "\n",
    "\n",
    "def computeGlobalTable_ctField(task = 'fromScratch', fileName = 'Global_CtFieldData', save = False):\n",
    "    ctFieldTimeSeriesDataFiles = [f for f in os.listdir(timeSeriesDataDir) \\\n",
    "                                  if (os.path.isfile(os.path.join(timeSeriesDataDir, f)) and f.endswith(\".csv\") \\\n",
    "                                      and ('thickness' in f))]\n",
    "#     print(ctFieldTimeSeriesDataFiles)\n",
    "    if task == 'fromScratch':\n",
    "        # create a dict containing the data\n",
    "        tableDict = createDataDict_ctField(ctFieldTimeSeriesDataFiles) # MAIN SUBFUNCTION\n",
    "        # create the table\n",
    "        CtField_DF = pd.DataFrame(tableDict)\n",
    "        \n",
    "    elif task == 'updateExisting':\n",
    "        # get existing table\n",
    "        try:\n",
    "            savePath = os.path.join(dataDir, (fileName + '.csv'))\n",
    "            existing_CtField_DF = pd.read_csv(savePath, sep=';')\n",
    "            for c in existing_CtField_DF.columns:\n",
    "                if 'Unnamed' in c:\n",
    "                    existing_CtField_DF = existing_CtField_DF.drop([c], axis=1)\n",
    "        except:\n",
    "            print('No existing table found')\n",
    "        # find which of the time series files are new\n",
    "        new_ctFieldTimeSeriesDataFiles = []\n",
    "        for f in ctFieldTimeSeriesDataFiles:\n",
    "            split_f = f.split('_')\n",
    "            currentCellID = split_f[0] + '_' + split_f[1] + '_' + split_f[2] + '_' + split_f[3]\n",
    "            if currentCellID not in existing_CtField_DF.cellID.values:\n",
    "                new_ctFieldTimeSeriesDataFiles.append(f)\n",
    "        new_tableDict = createDataDict_ctField(new_ctFieldTimeSeriesDataFiles) # MAIN SUBFUNCTION\n",
    "        # create the table with new data\n",
    "        new_CtField_DF = pd.DataFrame(new_tableDict)\n",
    "        # fuse the two\n",
    "        new_CtField_DF.index += existing_CtField_DF.shape[0]\n",
    "        CtField_DF = pd.concat([existing_CtField_DF, new_CtField_DF])\n",
    "    \n",
    "    dateExemple = CtField_DF.loc[CtField_DF.index[0],'date']\n",
    "    if re.match(dateFormatExcel, dateExemple):\n",
    "        CtField_DF.loc[:,'date'] = CtField_DF.loc[:,'date'].apply(lambda x: x.split('/')[0] + '-' + x.split('/')[1] + '-' + x.split('/')[2][2:])\n",
    "    \n",
    "    if save:\n",
    "        saveName = fileName + '.csv'\n",
    "        savePath = os.path.join(dataDir, saveName)\n",
    "        CtField_DF.to_csv(savePath, sep=';')\n",
    "        \n",
    "    return(CtField_DF)\n",
    "\n",
    "\n",
    "\n",
    "def getGlobalTable_ctField(fileName = 'Global_CtFieldData'):\n",
    "    try:\n",
    "        savePath = os.path.join(dataDir, (fileName + '.csv'))\n",
    "        CtField_DF = pd.read_csv(savePath, sep=';')\n",
    "        for c in CtField_DF.columns:\n",
    "            if 'Unnamed' in c:\n",
    "                CtField_DF = CtField_DF.drop([c], axis=1)\n",
    "        print('Extracted a table with ' + str(CtField_DF.shape[0]) + ' lines and ' + str(CtField_DF.shape[1]) + ' columns.')\n",
    "        \n",
    "    except:\n",
    "        print('No existing table found')\n",
    "        \n",
    "    dateExemple = CtField_DF.loc[CtField_DF.index[0],'date']\n",
    "    if re.match(dateFormatExcel, dateExemple):\n",
    "        print('dates corrected')\n",
    "        CtField_DF.loc[:,'date'] = CtField_DF.loc[:,'date'].apply(lambda x: x.split('/')[0] + '-' + x.split('/')[1] + '-' + x.split('/')[2][2:])\n",
    "#         mecaDF['ManipID'] = mecaDF['ExpDay'] + '_' + mecaDF['CellName'].apply(lambda x: x.split('_')[0])\n",
    "    return(CtField_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "computeGlobalTable_ctField(task='updateExisting',save=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getGlobalTable_ctField().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mechanics\n",
    "\n",
    "Workflow\n",
    "* analyseTimeSeries_meca() analyse 1 file and return the dict (with the results of the analysis)\n",
    "* createMecaDataDict() call the previous function on the given list of files and concatenate the results\n",
    "* computeGlobalTable_meca() call the previous function and convert the dict to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     81,
     316,
     336,
     410
    ]
   },
   "outputs": [],
   "source": [
    "listColumnsMeca = ['date','cellName','cellID','manipID',\\\n",
    "                   'compNum','compDuration','compStartTime','compAbsStartTime','compStartTimeThisDay',\\\n",
    "                   'initialThickness','minThickness','maxIndent','previousThickness','surroundingThickness',\\\n",
    "                   'validatedThickness',\\\n",
    "                   'ctFieldThickness','ctFieldFluctuAmpli',\\\n",
    "                   'H0Chadwick','EChadwick','R2Chadwick','EChadwick_CIWidth',\\\n",
    "                   'hysteresis',\\\n",
    "                   'critFit', 'validatedFit','comments'] # 'fitParams',\n",
    "\n",
    "def compressionFitChadwick(hCompr, fCompr, DIAMETER):\n",
    "    \n",
    "    error = False\n",
    "    \n",
    "    def chadwickModel(h, E, H0):\n",
    "        R = DIAMETER/2\n",
    "        f = (np.pi*E*R*((H0-h)**2))/(3*H0)\n",
    "        return(f)\n",
    "\n",
    "    def inversedChadwickModel(f, E, H0):\n",
    "        R = DIAMETER/2\n",
    "        h = H0 - ((3*H0*f)/(np.pi*E*R))**0.5\n",
    "        return(h)\n",
    "\n",
    "    # some initial parameter values - must be within bounds\n",
    "    initH0 = max(hCompr) # H0 ~ h_max\n",
    "    initE = (3*max(hCompr)*max(fCompr))/(np.pi*(DIAMETER/2)*(max(hCompr)-min(hCompr))**2) # E ~ 3*H0*F_max / pi*R*(H0-h_min)²\n",
    "#     initH0, initE = initH0*(initH0>0), initE*(initE>0)\n",
    "    \n",
    "    initialParameters = [initE, initH0]\n",
    "#     print(initialParameters)\n",
    "\n",
    "    # bounds on parameters - initial parameters must be within these\n",
    "    lowerBounds = (0, 0)\n",
    "    upperBounds = (np.Inf, np.Inf)\n",
    "    parameterBounds = [lowerBounds, upperBounds]\n",
    "    \n",
    "#     testH = inversedChadwickModel(fCompr, initE, initH0)\n",
    "#     fig, ax = plt.subplots(1,1)\n",
    "#     ax.plot(hCompr,fCompr,'b-', linewidth = 0.8)\n",
    "#     ax.plot(testH,fCompr,'kx', linewidth = 0.8)\n",
    "#     ax.set_xlabel('h (nm)')\n",
    "#     ax.set_ylabel('f (pN)')\n",
    "#     fig.show()\n",
    "#     print(initialParameters)\n",
    "\n",
    "    try:\n",
    "        params, covM = curve_fit(inversedChadwickModel, fCompr, hCompr, initialParameters, bounds = parameterBounds)\n",
    "\n",
    "        # Previously I fitted with y=F and x=H, but it didn't work so well cause H(t) isn't monotonous:\n",
    "        # params, covM = curve_fit(chadwickModel, hCompr, fCompr, initialParameters, bounds = parameterBounds)\n",
    "        # Fitting with the 'inverse Chadwick model', with y=H and x=F is more convenient\n",
    "\n",
    "        E, H0 = params\n",
    "        hPredict = inversedChadwickModel(fCompr, E, H0)\n",
    "\n",
    "        SSR = np.sum((hCompr-hPredict)**2)\n",
    "        alpha = 0.975\n",
    "        df = len(fCompr)-len(params)\n",
    "        q = st.t.ppf(alpha, df) # Student coefficient\n",
    "        R2 = get_R2(hCompr,hPredict)\n",
    "\n",
    "        varE = covM[0,0]\n",
    "        seE = (varE)**0.5\n",
    "        E, seE = E*1e6, seE*1e6\n",
    "        confIntE = [E-q*seE, E+q*seE]\n",
    "        confIntEWidth = 2*q*seE\n",
    "\n",
    "        varH0 = covM[1,1]\n",
    "        seH0 = (varH0)**0.5\n",
    "        confIntH0 = [H0-q*seH0, H0+q*seH0]\n",
    "        confIntH0Width = 2*q*seH0\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        error = True\n",
    "        E, H0, hPredict, R2, confIntE, confIntH0 = -1, -1, np.ones(len(hCompr))*(-1), -1, [-1,-1], [-1,-1]\n",
    "    \n",
    "    return(E, H0, hPredict, R2, confIntE, confIntH0, error)\n",
    "\n",
    "\n",
    "\n",
    "def analyseTimeSeries_meca(f, tsDF, expDf, listColumnsMeca, PLOT, PLOT_SHOW):\n",
    "    \n",
    "    split_f = f.split('_')\n",
    "    tsDF.dx, tsDF.dy, tsDF.dz, tsDF.D2, tsDF.D3 = tsDF.dx*1000, tsDF.dy*1000, tsDF.dz*1000, tsDF.D2*1000, tsDF.D3*1000\n",
    "    thisManipID = split_f[0] + '_' + split_f[1]\n",
    "    expDf['manipID'] = expDf['date'] + '_' + expDf['manip']\n",
    "    thisExpDf = expDf.loc[expDf['manipID'] == thisManipID]\n",
    "    DIAMETER = thisExpDf.at[thisExpDf.index.values[0], 'bead diameter']\n",
    "    \n",
    "    results = {}\n",
    "    for c in listColumnsMeca:\n",
    "        results[c] = []\n",
    "        \n",
    "    Ncomp = max(tsDF['idxCompression'])\n",
    "    NimgComp = np.sum((tsDF['idxCompression'] != 0))/Ncomp\n",
    "    NimgCompTh = round(0.49999999999 + np.sum((tsDF['idxCompression'] != 0))/Ncomp)\n",
    "    NimgBtwComp = np.sum((tsDF['idxCompression'] == 0))/Ncomp\n",
    "    NimgBtwCompTh = round(0.4999999999 + np.sum((tsDF['idxCompression'] == 0))/Ncomp)\n",
    "#     print('Ncomp : ' + str(Ncomp) + ' ; ' + 'NimgComp : ' + str(NimgComp) + '/' + str(NimgCompTh) + ' ; ' + 'NimgBtwComp : ' + str(NimgBtwComp) + '/' + str(NimgBtwCompTh))\n",
    "#     if not NimgBtwComp%2 == 0:\n",
    "#         print('Bug with the compressions sequence delimitation')\n",
    "\n",
    "    # These values are computed once for the whole cell D3 time series, but since the table has 1 line per compression, \n",
    "    # that same value will be put in the table for each line corresponding to that cell\n",
    "    ctFieldH = (tsDF.loc[tsDF['idxCompression'] == 0, 'D3'].values - DIAMETER)\n",
    "    ctFieldThickness   = np.median(ctFieldH)\n",
    "    ctFieldFluctuAmpli = np.percentile(ctFieldH,90) - np.percentile(ctFieldH,10)\n",
    "    \n",
    "    # First part of the plot [mainly ax1 and ax1bis]\n",
    "    if PLOT:\n",
    "        nColsSubplot = 5\n",
    "        nRowsSubplot = ((Ncomp-1) // nColsSubplot) + 1\n",
    "        fig1, ax1 = plt.subplots(1,1,figsize=(tsDF.shape[0]*(1/100),5))\n",
    "#         fig2, ax2 = plt.subplots(1,Ncomp,figsize=(3*Ncomp,3))\n",
    "        fig2, ax2 = plt.subplots(nRowsSubplot,nColsSubplot,figsize=(3*nColsSubplot,3*nRowsSubplot))\n",
    "        \n",
    "        color = 'blue'\n",
    "        ax1.plot(tsDF['T'].values, tsDF['D3'].values-DIAMETER, color = color, ls = '-', linewidth = 1)\n",
    "        ax1.set_xlabel('t (s)')\n",
    "        ax1.set_ylabel('h (nm)', color=color)\n",
    "        ax1.tick_params(axis='y', labelcolor=color)\n",
    "        (axm, axM) = ax1.get_ylim()\n",
    "        ax1.set_ylim([min(0,axm), axM])\n",
    "        if (max(tsDF['D3'].values-DIAMETER) > 200):\n",
    "            ax1.set_yticks(np.arange(0, max(tsDF['D3'].values-DIAMETER), 100))\n",
    "        \n",
    "        twinAxis = True\n",
    "        if twinAxis:\n",
    "            ax1.tick_params(axis='y', labelcolor='b')\n",
    "            ax1bis = ax1.twinx()\n",
    "            color = 'firebrick'\n",
    "            ax1bis.set_ylabel('F (pN)', color=color)\n",
    "            ax1bis.plot(tsDF['T'].values, tsDF['F'].values, color=color)\n",
    "            ax1bis.tick_params(axis='y', labelcolor=color)\n",
    "            ax1bis.set_yticks([0,500,1000,1500])\n",
    "            minh = np.min(tsDF['D3'].values-DIAMETER)\n",
    "            ratio = min(1/abs(minh/axM), 5)\n",
    "#             print(ratio)\n",
    "            (axmbis, axMbis) = ax1bis.get_ylim()\n",
    "            ax1bis.set_ylim([0, max(axMbis*ratio, 3*max(tsDF['F'].values))])\n",
    "            \n",
    "    \n",
    "    for i in range(1, Ncomp+1):#Ncomp+1):\n",
    "\n",
    "        # (1) Identifiers\n",
    "        results['date'].append(split_f[0])\n",
    "        results['cellName'].append(split_f[1] + '_' + split_f[2] + '_' + split_f[3])\n",
    "        results['cellID'].append(split_f[0] + '_' + split_f[1] + '_' + split_f[2] + '_' + split_f[3])\n",
    "        results['manipID'].append(split_f[0] + '_' + split_f[1])\n",
    "        \n",
    "        # (2) Segment the compression n°i\n",
    "        thisCompDf = tsDF.loc[tsDF['idxCompression'] == i,:]\n",
    "        iStart = (findFirst(tsDF['idxCompression'], i))\n",
    "        iStop = iStart+thisCompDf.shape[0]\n",
    "        \n",
    "        # Easy-to-get parameters\n",
    "        results['compNum'].append(i)\n",
    "        results['compDuration'].append(thisExpDf.at[thisExpDf.index.values[0], 'compression duration'])\n",
    "        results['compStartTime'].append(thisCompDf['T'].values[0])\n",
    "        results['compAbsStartTime'].append(thisCompDf['Tabs'].values[0])\n",
    "        results['compStartTimeThisDay'].append(thisCompDf['Tabs'].values[0]) # Will be modifyed later !\n",
    "        \n",
    "        # (3) Inside the compression n°i, delimit the compression and relaxation phases\n",
    "        \n",
    "        # Delimit the start of the increase of B (typically the moment when the field decrease from 5 to 3)\n",
    "        # and the end of its decrease (typically when it goes back from 3 to 5)\n",
    "        listB = thisCompDf.B.values\n",
    "        offsetStart, offsetStop = 0, 0\n",
    "        minB, maxB = min(listB), max(listB)\n",
    "        thresholdB = (maxB-minB)/50\n",
    "        \n",
    "        k = 0\n",
    "        while (listB[k] > minB+thresholdB) or (listB[-1-k] > minB+thresholdB):\n",
    "            offsetStart += int(listB[k] > minB+thresholdB)\n",
    "            offsetStop += int(listB[-1-k] > minB+thresholdB)\n",
    "            k += 1\n",
    "        jStart = offsetStart # Beginning of compression\n",
    "        jMax = np.argmax(thisCompDf.B) # End of compression, beginning of relaxation\n",
    "        jStop = thisCompDf.shape[0] - offsetStop # End of relaxation\n",
    "        \n",
    "        # Four arrays\n",
    "        hCompr = (thisCompDf.D3.values[jStart:jMax+1] - DIAMETER)\n",
    "        hRelax = (thisCompDf.D3.values[jMax+1:jStop] - DIAMETER)\n",
    "        fCompr = (thisCompDf.F.values[jStart:jMax+1])\n",
    "        fRelax = (thisCompDf.F.values[jMax+1:jStop])\n",
    "        \n",
    "        # Refinement of the compression delimitation.\n",
    "        # Remove the 1-2 points at the begining where there is just the viscous relaxation of the cortex\n",
    "        # because of the initial decrease of B and the cortex thickness increases.\n",
    "        offsetStart2 = 0\n",
    "        k = 0\n",
    "        while (hCompr[k] < np.max(hCompr[k+1:min(k+10, len(hCompr))])) and k<len(hCompr)-10:\n",
    "            offsetStart2 += 1\n",
    "            k += 1\n",
    "        # Better compressions arrays\n",
    "        hCompr = hCompr[offsetStart2:]\n",
    "        fCompr = fCompr[offsetStart2:]\n",
    "        \n",
    "        # Get the points of constant field preceding and surrounding the current compression\n",
    "        # Ex : if the labview code was set so that there is 6 points of ct field before and after each compression,\n",
    "        # previousPoints will contains D3[iStart-12:iStart]\n",
    "        # surroundingPoints will contains D3[iStart-6:iStart] and D3[iStop:iStop+6]\n",
    "        previousPoints = (tsDF.D3.values[max(0,iStart-(NimgBtwCompTh)):iStart]) - DIAMETER\n",
    "        surroundingPoints = np.concatenate([tsDF.D3.values[max(0,iStart-(NimgBtwCompTh//2)):iStart],tsDF.D3.values[iStop:iStop+(NimgBtwCompTh//2)]]) - DIAMETER\n",
    "        \n",
    "        # Parameters relative to the thickness ( = D3-DIAMETER)\n",
    "        results['initialThickness'].append(np.mean(hCompr[0:3]))\n",
    "        results['minThickness'].append(np.min(hCompr))\n",
    "        results['maxIndent'].append(results['initialThickness'][-1] - results['minThickness'][-1])\n",
    "        results['previousThickness'].append(np.median(previousPoints))\n",
    "        results['surroundingThickness'].append(np.median(surroundingPoints))\n",
    "        results['ctFieldThickness'].append(ctFieldThickness)\n",
    "        results['ctFieldFluctuAmpli'].append(ctFieldFluctuAmpli)\n",
    "        \n",
    "        validatedThickness = np.min([results['initialThickness'],results['minThickness'],results['previousThickness'],\\\n",
    "                                    results['surroundingThickness'],results['ctFieldThickness']]) > 0\n",
    "        results['validatedThickness'].append(validatedThickness)\n",
    "\n",
    "        # (4) Fit with Chadwick model of the force-thickness curve\n",
    "        \n",
    "        E, H0, hPredict, R2, confIntE, confIntH0, fitError = compressionFitChadwick(hCompr, fCompr, DIAMETER) # IMPORTANT SUBFUNCTION\n",
    "        \n",
    "        R2CRITERION = 0.9\n",
    "        critFit = 'R2 > ' + str(R2CRITERION)\n",
    "        results['critFit'].append(critFit)\n",
    "        validatedFit = (R2 > R2CRITERION)\n",
    "        \n",
    "        if PLOT:\n",
    "\n",
    "            # fig1\n",
    "            if not fitError:\n",
    "                if validatedFit:\n",
    "                    ax1.plot(thisCompDf['T'].values, thisCompDf['D3'].values-DIAMETER, color = 'chartreuse', linestyle = '-', linewidth = 1.25)\n",
    "                else:\n",
    "                    ax1.plot(thisCompDf['T'].values, thisCompDf['D3'].values-DIAMETER, color = 'gold', linestyle = '-', linewidth = 1.25)\n",
    "            else:\n",
    "                ax1.plot(thisCompDf['T'].values, thisCompDf['D3'].values-DIAMETER, color = 'crimson', linestyle = '-', linewidth = 1.25)\n",
    "\n",
    "            \n",
    "            fig1.suptitle(results['cellID'][-1])\n",
    "            \n",
    "            # fig2\n",
    "            colSp = (i-1) % nColsSubplot\n",
    "            rowSp = (i-1) // nColsSubplot\n",
    "            # ax2[i-1] with the 1 line plot\n",
    "            if nRowsSubplot == 1:\n",
    "                thisAx2 = ax2[colSp]\n",
    "            elif nRowsSubplot >= 1:\n",
    "                thisAx2 = ax2[rowSp,colSp]\n",
    "            \n",
    "            thisAx2.plot(hCompr,fCompr,'b-', linewidth = 0.8)\n",
    "            thisAx2.plot(hRelax,fRelax,'r-', linewidth = 0.8)\n",
    "            titleText = results['cellID'][-1] + '__c' + str(i)\n",
    "            legendText = ''\n",
    "            thisAx2.set_xlabel('h (nm)')\n",
    "            thisAx2.set_ylabel('f (pN)')\n",
    "            \n",
    "            if not fitError:\n",
    "                legendText += 'H0 = {:.1f}nm\\nE = {:.2e}Pa\\nR2 = {:.3f}'.format(H0, E, R2)\n",
    "                thisAx2.plot(hPredict,fCompr,'k--', linewidth = 0.8, label = legendText)\n",
    "                thisAx2.legend(loc = 'upper right', prop={'size': 6})\n",
    "                if not validatedFit:\n",
    "                    titleText += '\\nNON VALIDATED'\n",
    "            else:\n",
    "                titleText += '\\nFIT ERROR'\n",
    "            \n",
    "            thisAx2.title.set_text(titleText)\n",
    "\n",
    "            for item in ([thisAx2.title, thisAx2.xaxis.label, \\\n",
    "                          thisAx2.yaxis.label] + thisAx2.get_xticklabels() + thisAx2.get_yticklabels()):\n",
    "                item.set_fontsize(9)\n",
    "                \n",
    "\n",
    "        if not fitError:\n",
    "            confIntEWidth = abs(confIntE[0] - confIntE[1])\n",
    "\n",
    "            results['H0Chadwick'].append(H0)\n",
    "            results['EChadwick'].append(E)\n",
    "            results['R2Chadwick'].append(R2)\n",
    "            results['EChadwick_CIWidth'].append(confIntEWidth)\n",
    "            \n",
    "\n",
    "            results['validatedFit'].append(validatedFit)\n",
    "            if validatedFit:\n",
    "                results['comments'].append('ok')\n",
    "            else:\n",
    "                results['comments'].append('R2 < ' + str(R2CRITERION))\n",
    "                \n",
    "        if fitError:\n",
    "            validatedFit = False\n",
    "            results['H0Chadwick'].append(np.nan)\n",
    "            results['EChadwick'].append(np.nan)\n",
    "            results['R2Chadwick'].append(np.nan)\n",
    "            results['EChadwick_CIWidth'].append(np.nan)\n",
    "            results['validatedFit'].append(validatedFit)\n",
    "            results['comments'].append('fitFailure')\n",
    "            \n",
    "        \n",
    "        # (5) hysteresis (its definition may change)\n",
    "        results['hysteresis'].append(hCompr[0] - hRelax[-1])\n",
    "    \n",
    "    if PLOT:\n",
    "        archiveFig(fig1, ax1, name=results['cellID'][-1] + '_h(t)', figSubDir = 'MecaAnalysis_allCells')\n",
    "        archiveFig(fig2, ax2, name=results['cellID'][-1] + '_F(h)', figSubDir = 'MecaAnalysis_allCells')\n",
    "        if PLOT_SHOW:\n",
    "            fig1.show()\n",
    "            fig2.tight_layout()\n",
    "            fig2.show()\n",
    "        else:\n",
    "            plt.close('all')\n",
    "    \n",
    "    return(results)\n",
    "\n",
    "\n",
    "\n",
    "def createDataDict_meca(list_mecaFiles, listColumnsMeca, PLOT):\n",
    "    expDf = getExperimentalConditions()\n",
    "    tableDict = {}\n",
    "    Nfiles = len(list_mecaFiles)\n",
    "    PLOT_SHOW = (Nfiles<11)\n",
    "    if not PLOT_SHOW:\n",
    "        plt.ioff()\n",
    "    for c in listColumnsMeca:\n",
    "        tableDict[c] = []\n",
    "    for f in list_mecaFiles: #[:10]:\n",
    "        tS_DataFilePath = os.path.join(timeSeriesDataDir, f)\n",
    "        current_tsDF = pd.read_csv(tS_DataFilePath, ';')\n",
    "        current_resultDict = analyseTimeSeries_meca(f, current_tsDF, expDf, listColumnsMeca, PLOT, PLOT_SHOW) # MAIN SUBFUNCTION\n",
    "        for k in current_resultDict.keys():\n",
    "            tableDict[k] += current_resultDict[k]\n",
    "    plt.ion()\n",
    "    return(tableDict)\n",
    "\n",
    "\n",
    "\n",
    "def computeGlobalTable_meca(task = 'fromScratch', fileName = 'Global_MecaData', save = False, PLOT = False, \\\n",
    "                            listColumnsMeca=listColumnsMeca):\n",
    "    \"\"\"\n",
    "    Compute the GlobalTable_meca from the time series data files.\n",
    "    Option task='fromScratch' will analyse all the time series data files and construct a new GlobalTable from them regardless of the existing GlobalTable.\n",
    "    Option task='updateExisting' will open the existing GlobalTable and determine which of the time series data files are new ones, and will append the existing GlobalTable with the data analysed from those new fils.\n",
    "    listColumnsMeca have to contain all the fields of the table that will be constructed.\n",
    "    \"\"\"\n",
    "    top = time.time()\n",
    "    list_mecaFiles = [f for f in os.listdir(timeSeriesDataDir) \\\n",
    "                      if (os.path.isfile(os.path.join(timeSeriesDataDir, f)) and f.endswith(\".csv\") \\\n",
    "                      and ('R40' in f))] # Change to allow different formats in the future\n",
    "#     print(list_mecaFiles)\n",
    "    \n",
    "    if task == 'fromScratch':\n",
    "        # create a dict containing the data\n",
    "        tableDict = createDataDict_meca(list_mecaFiles, listColumnsMeca, PLOT) # MAIN SUBFUNCTION\n",
    "        # create the dataframe from it\n",
    "        meca_DF = pd.DataFrame(tableDict)\n",
    "        \n",
    "        # last step: now that the dataFrame is complete, one can use \"compStartTimeThisDay\" col to compute the start time of each compression relative to the first one done this day.\n",
    "        allDates = list(meca_DF['date'].unique())\n",
    "        for d in allDates:\n",
    "            subDf = meca_DF.loc[meca_DF['date'] == d]\n",
    "            experimentStartTime = np.min(subDf['compStartTimeThisDay'])\n",
    "            meca_DF['compStartTimeThisDay'].loc[meca_DF['date'] == d] = meca_DF['compStartTimeThisDay'] - experimentStartTime\n",
    "        \n",
    "    elif task == 'updateExisting':\n",
    "        # get existing table\n",
    "        try:\n",
    "            savePath = os.path.join(dataDir, (fileName + '.csv'))\n",
    "            existing_meca_DF = pd.read_csv(savePath, sep=';')\n",
    "        except:\n",
    "            print('No existing table found')\n",
    "            \n",
    "        # find which of the time series files are new\n",
    "        new_list_mecaFiles = []\n",
    "        for f in list_mecaFiles:\n",
    "            split_f = f.split('_')\n",
    "            currentCellID = split_f[0] + '_' + split_f[1] + '_' + split_f[2] + '_' + split_f[3]\n",
    "            if currentCellID not in existing_meca_DF.cellID.values:\n",
    "                new_list_mecaFiles.append(f)\n",
    "                \n",
    "        # create the dict with new data\n",
    "        new_tableDict = createDataDict_meca(new_list_mecaFiles, listColumnsMeca, PLOT) # MAIN SUBFUNCTION\n",
    "        # create the dataframe from it\n",
    "        new_meca_DF = pd.DataFrame(new_tableDict)\n",
    "        # fuse the existing table with the new one\n",
    "        meca_DF = pd.concat([existing_meca_DF, new_meca_DF])\n",
    "        \n",
    "        # Reset the relative time in the day for all rows and recompute it (not elegant but simpler to write)\n",
    "        meca_DF['compStartTimeThisDay'] = meca_DF['compAbsStartTime']\n",
    "        allDates = list(meca_DF['date'].unique())\n",
    "        for d in allDates:\n",
    "            subDf = meca_DF.loc[meca_DF['date'] == d]\n",
    "            experimentStartTime = np.min(subDf['compStartTimeThisDay'])\n",
    "            meca_DF['compStartTimeThisDay'].loc[meca_DF['date'] == d] = meca_DF['compStartTimeThisDay'] - experimentStartTime\n",
    "    \n",
    "    for c in meca_DF.columns:\n",
    "            if 'Unnamed' in c:\n",
    "                meca_DF = meca_DF.drop([c], axis=1)\n",
    "    \n",
    "    if save:\n",
    "        saveName = fileName + '.csv'\n",
    "        savePath = os.path.join(dataDir, saveName)\n",
    "        meca_DF.to_csv(savePath, sep=';')\n",
    "    \n",
    "    delta = time.time() - top\n",
    "    print(delta)\n",
    "    \n",
    "    return(meca_DF)\n",
    "            \n",
    "\n",
    "    \n",
    "def getGlobalTable_meca(fileName = 'Global_mecaData'):\n",
    "    try:\n",
    "        savePath = os.path.join(dataDir, (fileName + '.csv'))\n",
    "        meca_DF = pd.read_csv(savePath, sep=';')\n",
    "        print('Extracted a table with ' + str(meca_DF.shape[0]) + ' lines and ' + str(meca_DF.shape[1]) + ' columns.')\n",
    "    except:\n",
    "        print('No existing table found')\n",
    "    for c in meca_DF.columns:\n",
    "            if 'Unnamed' in c:\n",
    "                meca_DF = meca_DF.drop([c], axis=1)\n",
    "    \n",
    "    if 'ExpDay'in meca_DF.columns:\n",
    "        dateExemple = meca_DF.loc[meca_DF.index[0],'ExpDay']\n",
    "        if not ('manipID' in meca_DF.columns):\n",
    "            meca_DF['manipID'] = meca_DF['ExpDay'] + '_' + meca_DF['CellID'].apply(lambda x: x.split('_')[0])\n",
    "            \n",
    "    elif 'date'in meca_DF.columns:\n",
    "        dateExemple = meca_DF.loc[meca_DF.index[0],'date']\n",
    "        if not ('manipID' in meca_DF.columns):\n",
    "            meca_DF['manipID'] = meca_DF['date'] + '_' + meca_DF['cellName'].apply(lambda x: x.split('_')[0])\n",
    "    \n",
    "    if re.match(dateFormatExcel, dateExemple):\n",
    "        print('bad date')\n",
    "    return(meca_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# computeGlobalTable_meca(task = 'fromScratch', fileName = 'Global_MecaData_Py', save = False, PLOT = False) # task = 'updateExisting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getGlobalTable_meca().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getGlobalTable_meca('Global_MecaData_Py').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fluorescence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def getFluoData(save = False):\n",
    "    # Getting the table\n",
    "    fluoDataFile = 'FluoQuantification.csv'\n",
    "    fluoDataFilePath = os.path.join(dataDir, fluoDataFile)\n",
    "    fluoDF = pd.read_csv(fluoDataFilePath, sep=';',header=0)\n",
    "    print('Extracted a table with ' + str(fluoDF.shape[0]) + ' lines and ' + str(fluoDF.shape[1]) + ' columns.')\n",
    "    # Cleaning the table\n",
    "    try:\n",
    "        for c in fluoDF.columns:\n",
    "            if 'Unnamed' in c:\n",
    "                fluoDF = fluoDF.drop([c], axis=1)\n",
    "        \n",
    "    except:\n",
    "        print('Unexpected bug with the cleaning step')\n",
    "\n",
    "    if save:\n",
    "        saveName = 'FluoQuantification.csv'\n",
    "        savePath = os.path.join(dataDir, saveName)\n",
    "        fluoDF.to_csv(savePath, sep=';')\n",
    "\n",
    "    \n",
    "    return(fluoDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFluoData().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison meca tables from matlab vs python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comparison - Per compression\n",
    "\n",
    "Problems with an offset in the indexation of compression in the matlab table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Comparison of values obtained with the python code vs matlab\n",
    "\n",
    "table_ExpConditions = getExperimentalConditions()\n",
    "table_fluo = getFluoData()\n",
    "\n",
    "mecaPy = getGlobalTable_meca('Global_MecaData_Py')\n",
    "mecaPy = pd.merge(table_ExpConditions, mecaPy, how=\"inner\", on='manipID')\n",
    "mecaPy = pd.merge(mecaPy, table_fluo, how=\"left\", on='cellID')\n",
    "mecaPy = mecaPy.sort_values([\"cellID\", \"compNum\"], ascending = (True, True),ignore_index=True)\n",
    "# mecaPy = mecaPy.loc[(mecaPy['cell subtype'] == 'aSFL') | (mecaPy['cell subtype'] == 'aSFL-6FP')]\n",
    "mecaMat = getGlobalTable_meca('Global_MecaData')\n",
    "mecaMat = pd.merge(table_ExpConditions, mecaMat, how=\"inner\", on='manipID')\n",
    "mecaMat = pd.merge(mecaMat, table_fluo, how=\"left\", left_on='CellName', right_on='cellID')\n",
    "mecaMat = mecaMat.sort_values([\"CellName\", \"CompNum\"], ascending = (True, True),ignore_index=True)\n",
    "\n",
    "FiltersPy = [(mecaMat['Validated'] == True), (mecaPy['validatedFit'] == True)]\n",
    "filterGlobal = np.ones((mecaPy.shape[0]), dtype=bool)\n",
    "for fltr in FiltersPy:\n",
    "    filterGlobal = filterGlobal & fltr\n",
    "mecaPyF = mecaPy.loc[filterGlobal]\n",
    "mecaPyF_light = mecaPyF[['compNum','H0Chadwick','EChadwick','R2Chadwick','EChadwick_CIWidth']]\n",
    "mecaPyF.tail()\n",
    "np.sum(mecaPyF['validatedFit'].values)\n",
    "mecaPyF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "FiltersMat = [(mecaPy['validatedFit'] == True), (mecaMat['Validated'] == True)]\n",
    "filterGlobal = np.ones((mecaMat.shape[0]), dtype=bool)\n",
    "for fltr in FiltersPy:\n",
    "    filterGlobal = filterGlobal & fltr\n",
    "mecaMatF = mecaMat.loc[filterGlobal]\n",
    "mecaMatF = mecaMatF.rename(columns={'CompNum': 'compNum', 'CiEChadwick': 'EChadwick_CIWidth'})\n",
    "mecaMatF_light = mecaMatF[['compNum','H0Chadwick','EChadwick','R2Chadwick','EChadwick_CIWidth']]\n",
    "# mecaMat_light.index = [i for i in range(Bbis.shape[0])]\n",
    "mecaMatF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "mecaCompare = (mecaPyF_light-mecaMatF_light)/mecaMatF_light\n",
    "Th = 0.1\n",
    "mecaCompare['Evaries'] = (np.abs(mecaCompare.EChadwick) > Th)\n",
    "mecaCompare['H0varies'] = (np.abs(mecaCompare.H0Chadwick) > Th)\n",
    "mecaCompare['cellID'] = mecaPyF['cellID']\n",
    "mecaCompare['compNum'] = mecaPyF['compNum']\n",
    "mecaCompare['cellID2'] = mecaMatF['CellName']\n",
    "mecaCompare['compNum2'] = mecaMatF['compNum']\n",
    "mecaCompare = mecaCompare[['H0Chadwick','EChadwick','R2Chadwick','EChadwick_CIWidth','Evaries','H0varies','cellID','compNum','cellID2','compNum2']]\n",
    "print('Nb of signif changes in E : {:.0f} / {:.0f} ; in H0 : {:.0f} / {:.0f}'.format(np.sum(mecaCompare['Evaries']), mecaCompare.shape[0], np.sum(mecaCompare['H0varies']), mecaCompare.shape[0]))\n",
    "mecaCompare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comparison - Per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Comparison of values obtained with the python code vs matlab\n",
    "\n",
    "table_ExpConditions = getExperimentalConditions()\n",
    "table_fluo = getFluoData()\n",
    "\n",
    "mecaPy = getGlobalTable_meca('Global_MecaData_Py')\n",
    "mecaPy = pd.merge(table_ExpConditions, mecaPy, how=\"inner\", on='manipID')\n",
    "mecaPy = pd.merge(mecaPy, table_fluo, how=\"left\", on='cellID')\n",
    "mecaPy = mecaPy.sort_values([\"cellID\", \"compNum\"], ascending = (True, True),ignore_index=True)\n",
    "# mecaPy = mecaPy.loc[(mecaPy['cell subtype'] == 'aSFL') | (mecaPy['cell subtype'] == 'aSFL-6FP')]\n",
    "mecaMat = getGlobalTable_meca('Global_MecaData')\n",
    "mecaMat = pd.merge(table_ExpConditions, mecaMat, how=\"inner\", on='manipID')\n",
    "mecaMat = pd.merge(mecaMat, table_fluo, how=\"left\", left_on='CellName', right_on='cellID')\n",
    "mecaMat = mecaMat.sort_values([\"CellName\", \"CompNum\"], ascending = (True, True),ignore_index=True)\n",
    "\n",
    "FiltersPy = [(mecaMat['Validated'] == True), (mecaPy['validatedFit'] == True)]\n",
    "filterGlobal = np.ones((mecaPy.shape[0]), dtype=bool)\n",
    "for fltr in FiltersPy:\n",
    "    filterGlobal = filterGlobal & fltr\n",
    "mecaPyF = mecaPy.loc[filterGlobal]\n",
    "\n",
    "cellID = 'cellID'\n",
    "group = mecaPyF.groupby(cellID)\n",
    "dictAggMean = getDictAggMean(mecaPyF)\n",
    "mecaPyF_perCell = group.agg(dictAggMean)\n",
    "\n",
    "mecaPyF_perCell_light = mecaPyF_perCell[['H0Chadwick','EChadwick','R2Chadwick','EChadwick_CIWidth']]\n",
    "mecaPyF_perCell_light.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "FiltersMat = [(mecaPy['validatedFit'] == True), (mecaMat['Validated'] == True)]\n",
    "filterGlobal = np.ones((mecaMat.shape[0]), dtype=bool)\n",
    "for fltr in FiltersPy:\n",
    "    filterGlobal = filterGlobal & fltr\n",
    "mecaMatF = mecaMat.loc[filterGlobal]\n",
    "mecaMatF = mecaMatF.rename(columns={'CompNum': 'compNum', 'CiEChadwick': 'EChadwick_CIWidth'})\n",
    "\n",
    "cellID = 'CellName'\n",
    "group = mecaMatF.groupby(cellID)\n",
    "dictAggMean = getDictAggMean(mecaMatF)\n",
    "mecaMatF_perCell = group.agg(dictAggMean)\n",
    "\n",
    "\n",
    "mecaMatF_perCell_light = mecaMatF_perCell[['H0Chadwick','EChadwick','R2Chadwick','EChadwick_CIWidth']]\n",
    "# mecaMat_light.index = [i for i in range(Bbis.shape[0])]\n",
    "# mecaMatF_perCell\n",
    "mecaMatF_perCell_light.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mecaCompare = (mecaPyF_perCell_light-mecaMatF_perCell_light)/mecaMatF_perCell_light\n",
    "listE = []\n",
    "listH0 = []\n",
    "for i in range(1,20):\n",
    "    Th = 0.05*i\n",
    "    mecaCompare['Evaries'] = (np.abs(mecaCompare.EChadwick) > Th)\n",
    "    mecaCompare['H0varies'] = (np.abs(mecaCompare.H0Chadwick) > Th)\n",
    "    mecaCompare['cellID'] = mecaPyF_perCell['cellID']\n",
    "    mecaCompare['cellID2'] = mecaMatF_perCell['CellName']\n",
    "    listE.append(np.sum(mecaCompare['Evaries']))\n",
    "    listH0.append(np.sum(mecaCompare['H0varies']))\n",
    "    print('For T = {:.0f}%, E : {:.0f}/{:.0f} ; H0 : {:.0f}/{:.0f}'\\\n",
    "          .format(Th*100, np.sum(mecaCompare['Evaries']), mecaCompare.shape[0], np.sum(mecaCompare['H0varies']), mecaCompare.shape[0]))\n",
    "# mecaCompare #.loc[mecaCompare['Evaries']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import & DataFrame formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "# pd.reset_option('max_columns')\n",
    "pd.set_option('max_rows', None)\n",
    "pd.reset_option('max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getExperimentalConditions().head()\n",
    "# getGlobalTable_ctField().head()\n",
    "# getGlobalTable_meca().head()\n",
    "# getFluoData().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GlobalTable_ctField\n",
    "\n",
    "GlobalTable_ctField = getGlobalTable_ctField()\n",
    "table_ExpConditions = getExperimentalConditions()\n",
    "table_fluo = getFluoData()\n",
    "GlobalTable_ctField = pd.merge(table_ExpConditions, GlobalTable_ctField, how=\"inner\", on='manipID',\n",
    "#     left_on=None,right_on=None,left_index=False,right_index=False,sort=True,\n",
    "#     suffixes=(\"_x\", \"_y\"),copy=True,indicator=False,validate=None,\n",
    ")\n",
    "GlobalTable_ctField = pd.merge(GlobalTable_ctField, table_fluo, how=\"left\", on='cellID',\n",
    "#     left_on=None,right_on=None,left_index=False,right_index=False,sort=True,\n",
    "#     suffixes=(\"_x\", \"_y\"),copy=True,indicator=False,validate=None,\n",
    ")\n",
    "print('Merged table has ' + str(GlobalTable_ctField.shape[0]) + ' lines and ' + str(GlobalTable_ctField.shape[1]) + ' columns.')\n",
    "\n",
    "GlobalTable_ctField.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GlobalTable_meca\n",
    "\n",
    "GlobalTable_meca = getGlobalTable_meca()\n",
    "table_ExpConditions = getExperimentalConditions()\n",
    "table_fluo = getFluoData()\n",
    "GlobalTable_meca = pd.merge(GlobalTable_meca, table_ExpConditions, how=\"inner\", on='manipID',\n",
    "#     left_on=None,right_on=None,left_index=False,right_index=False,sort=True,\n",
    "#     suffixes=(\"_x\", \"_y\"),copy=True,indicator=False,validate=None,\n",
    ")\n",
    "GlobalTable_meca = pd.merge(GlobalTable_meca, table_fluo, how=\"left\", left_on='CellName', right_on='cellID'\n",
    "#     left_on=None,right_on=None,left_index=False,right_index=False,sort=True,\n",
    "#     suffixes=(\"_x\", \"_y\"),copy=True,indicator=False,validate=None,\n",
    ")\n",
    "print('Merged table has ' + str(GlobalTable_meca.shape[0]) + ' lines and ' + str(GlobalTable_meca.shape[1]) + ' columns.')\n",
    "\n",
    "GlobalTable_meca.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GlobalTable_mecaBis\n",
    "\n",
    "GlobalTable_meca_Py = getGlobalTable_meca('Global_MecaData_Py')\n",
    "\n",
    "table_ExpConditions = getExperimentalConditions()\n",
    "table_fluo = getFluoData()\n",
    "GlobalTable_meca_Py = pd.merge(GlobalTable_meca_Py, table_ExpConditions, how=\"inner\", on='manipID',\n",
    "#     left_on=None,right_on=None,left_index=False,right_index=False,sort=True,\n",
    "#     suffixes=(\"_x\", \"_y\"),copy=True,indicator=False,validate=None,\n",
    ")\n",
    "GlobalTable_meca_Py = pd.merge(GlobalTable_meca_Py, table_fluo, how=\"left\", left_on='cellID', right_on='cellID'\n",
    "#     left_on=None,right_on=None,left_index=False,right_index=False,sort=True,\n",
    "#     suffixes=(\"_x\", \"_y\"),copy=True,indicator=False,validate=None,\n",
    ")\n",
    "print('Merged table has ' + str(GlobalTable_meca_Py.shape[0]) + ' lines and ' + str(GlobalTable_meca_Py.shape[1]) + ' columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GlobalTable_meca_Py.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment counter - Matlab table\n",
    "\n",
    "# count ct field cells\n",
    "cellID = 'cellID'\n",
    "GlobalTable_ctField_CountCell = GlobalTable_ctField.groupby(['cell type', 'cell subtype', 'bead type', 'drug', 'substrate']).count()\n",
    "GlobalTable_ctField_CountCell = GlobalTable_ctField_CountCell.loc[:, [cellID]].rename(columns={cellID : 'Count cells - ctField'})\n",
    "\n",
    "# count meca compressions\n",
    "cellID = 'CellName'\n",
    "GlobalTable_meca_CountComp = GlobalTable_meca.groupby(['cell type', 'cell subtype', 'bead type', 'drug', 'substrate']).count()\n",
    "GlobalTable_meca_CountComp = GlobalTable_meca_CountComp.loc[:, [cellID]].rename(columns={cellID : 'Count compressions'})\n",
    "\n",
    "# count valid meca compressions\n",
    "cellID = 'CellName'\n",
    "GlobalTable_meca_CountCompOK = GlobalTable_meca[GlobalTable_meca['Validated'] == True].groupby(['cell type', 'cell subtype', 'bead type', 'drug', 'substrate']).count()\n",
    "GlobalTable_meca_CountCompOK = GlobalTable_meca_CountCompOK.loc[:, [cellID]].rename(columns={cellID : 'Count OK compressions'})\n",
    "\n",
    "# count meca cells\n",
    "cellID = 'CellName'\n",
    "group = GlobalTable_meca.groupby(cellID)\n",
    "dictAggMean = getDictAggMean(GlobalTable_meca)\n",
    "GlobalTable_meca_perCell = group.agg(dictAggMean)\n",
    "GlobalTable_meca_CountCell = GlobalTable_meca_perCell.groupby(['cell type', 'cell subtype', 'bead type', 'drug', 'substrate']).count()\n",
    "GlobalTable_meca_CountCell = GlobalTable_meca_CountCell.loc[:, [cellID]].rename(columns={cellID : 'Count cells - meca'})\n",
    "\n",
    "\n",
    "# Fuse all the previous tables\n",
    "GlobalTable_CountAll = pd.concat([GlobalTable_ctField_CountCell, GlobalTable_meca_CountCell, GlobalTable_meca_CountComp, GlobalTable_meca_CountCompOK], axis=1)\n",
    "GlobalTable_CountAll = GlobalTable_CountAll.fillna(0)\n",
    "GlobalTable_CountAll = GlobalTable_CountAll.loc[:,:].astype(int)\n",
    "GlobalTable_CountAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment counter - Python table\n",
    "\n",
    "# count ct field cells\n",
    "cellID = 'cellID'\n",
    "GlobalTable_ctField_CountCell = GlobalTable_ctField.groupby(['cell type', 'cell subtype', 'bead type', 'drug', 'substrate']).count()\n",
    "GlobalTable_ctField_CountCell = GlobalTable_ctField_CountCell.loc[:, [cellID]].rename(columns={cellID : 'Count cells - ctField'})\n",
    "\n",
    "# count meca compressions\n",
    "cellID = 'cellID'\n",
    "GlobalTable_meca_CountComp = GlobalTable_meca_Py.groupby(['cell type', 'cell subtype', 'bead type', 'drug', 'substrate']).count()\n",
    "GlobalTable_meca_CountComp = GlobalTable_meca_CountComp.loc[:, [cellID]].rename(columns={cellID : 'Count compressions'})\n",
    "\n",
    "# count valid meca compressions\n",
    "cellID = 'cellID'\n",
    "GlobalTable_meca_CountCompOK = GlobalTable_meca_Py[GlobalTable_meca_Py['validatedFit'] == True].groupby(['cell type', 'cell subtype', 'bead type', 'drug', 'substrate']).count()\n",
    "GlobalTable_meca_CountCompOK = GlobalTable_meca_CountCompOK.loc[:, [cellID]].rename(columns={cellID : 'Count OK compressions'})\n",
    "\n",
    "# count meca cells\n",
    "cellID = 'cellID'\n",
    "group = GlobalTable_meca_Py.groupby(cellID)\n",
    "dictAggMean = getDictAggMean(GlobalTable_meca_Py)\n",
    "GlobalTable_meca_perCell = group.agg(dictAggMean)\n",
    "GlobalTable_meca_CountCell = GlobalTable_meca_perCell.groupby(['cell type', 'cell subtype', 'bead type', 'drug', 'substrate']).count()\n",
    "GlobalTable_meca_CountCell = GlobalTable_meca_CountCell.loc[:, [cellID]].rename(columns={cellID : 'Count cells - meca'})\n",
    "\n",
    "\n",
    "# Fuse all the previous tables\n",
    "GlobalTable_CountAll = pd.concat([GlobalTable_ctField_CountCell, GlobalTable_meca_CountCell, GlobalTable_meca_CountComp, GlobalTable_meca_CountCompOK], axis=1)\n",
    "GlobalTable_CountAll = GlobalTable_CountAll.fillna(0)\n",
    "GlobalTable_CountAll = GlobalTable_CountAll.loc[:,:].astype(int)\n",
    "GlobalTable_CountAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filters = [(GlobalTable_meca_Py['validatedFit'] == True), (GlobalTable_meca_Py['validatedThickness'] == True), (GlobalTable_meca_Py['cell subtype'] == 'aSFL-A8')]\n",
    "# GlobalTable_meca_PyF = GlobalTable_meca_Py\n",
    "# for fltr in Filters:\n",
    "#         GlobalTable_meca_PyF = GlobalTable_meca_PyF.loc[fltr]\n",
    "# # GlobalTable_mecaBis\n",
    "# cellID = 'cellID'\n",
    "# group = GlobalTable_meca_PyF.groupby(cellID)\n",
    "# dictAggMean = getDictAggMean(GlobalTable_meca_PyF)\n",
    "# GlobalTable_meca_PyF_perCell = group.agg(dictAggMean)\n",
    "# GlobalTable_meca_PyF_perCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21-06-28 Export of E - h data for Julien\n",
    "# GlobalTable_meca_Py_expJ = GlobalTable_meca_Py.loc[GlobalTable_meca_Py['validatedFit'] & GlobalTable_meca_Py['validatedThickness']]\\\n",
    "#                                                [['cell type', 'cell subtype', 'bead type', 'drug', 'substrate', 'compNum', \\\n",
    "#                                                  'EChadwick', 'H0Chadwick', 'surroundingThickness', 'ctFieldThickness']]\n",
    "# GlobalTable_meca_Py_expJ = GlobalTable_meca_Py_expJ.reset_index()\n",
    "# GlobalTable_meca_Py_expJ = GlobalTable_meca_Py_expJ.drop('index', axis=1)\n",
    "# savePath = os.path.join(dataDir, 'mecanicsData_3T3.csv')\n",
    "# GlobalTable_meca_Py_expJ.to_csv(savePath, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Styles = {''} # Project of automatic formatting according to the type of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions use matplotlib.pyplot and seaborn libraries to display 1D categorical or 2D plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def D1Plot(data, CondCol=[],Parameters=[],Filters=[],Boxplot=True,AvgPerCell=False,cellID='cellID', co_order=[],\\\n",
    "           stats=True,statMethod='Mann-Whitney',box_pairs=[],figSizeFactor = 1,markerSizeFactor=1):\n",
    "    data_filtered = data\n",
    "    for fltr in Filters:\n",
    "        data_filtered = data_filtered.loc[fltr]    \n",
    "    NCond = len(CondCol)\n",
    "    \n",
    "    if NCond == 1:\n",
    "        CondCol = CondCol[0]\n",
    "        \n",
    "    elif NCond > 1:\n",
    "        newColName = ''\n",
    "        for i in range(NCond):\n",
    "            newColName += CondCol[i]\n",
    "            newColName += ' & '\n",
    "        newColName = newColName[:-3]\n",
    "        data_filtered[newColName] = ''\n",
    "        for i in range(NCond):\n",
    "            data_filtered[newColName] += data_filtered[CondCol[i]].astype(str)\n",
    "            data_filtered[newColName] = data_filtered[newColName].apply(lambda x : x + ' & ')\n",
    "        data_filtered[newColName] = data_filtered[newColName].apply(lambda x : x[:-3])\n",
    "        CondCol = newColName\n",
    "    \n",
    "    if AvgPerCell:\n",
    "        group = data_filtered.groupby(cellID)\n",
    "        dictAggMean = getDictAggMean(data_filtered)\n",
    "#         dictAggMean['EChadwick'] = 'median'\n",
    "        data_filtered = group.agg(dictAggMean)\n",
    "        \n",
    "    data_filtered.sort_values(CondCol, axis=0, ascending=True, inplace=True)\n",
    "    \n",
    "    if len(co_order) > 0:\n",
    "        p = getStyleLists(co_order, styleDict1)\n",
    "    else:\n",
    "        p = sns.color_palette()\n",
    "    \n",
    "    NPlots = len(Parameters)\n",
    "    Conditions = list(data_filtered[CondCol].unique())\n",
    "    if len(co_order) == 0:\n",
    "        co_order = Conditions\n",
    "        \n",
    "    fig, ax = plt.subplots(1, NPlots, figsize = (5*NPlots*NCond*figSizeFactor,5))\n",
    "    markerSize = 5*markerSizeFactor\n",
    "    \n",
    "    if NPlots > 1:\n",
    "        for k in range(NPlots):\n",
    "            \n",
    "            if Parameters[k] == 'EChadwick':\n",
    "                ax[k].set_yscale('log')\n",
    "                \n",
    "\n",
    "            if Boxplot:\n",
    "                sns.boxplot(x=CondCol, y=Parameters[k], data=data_filtered, ax=ax[k], \n",
    "                            color='w', linewidth = 2, width = 0.5, showfliers = False, order= co_order)\n",
    "                # data_filtered.boxplot(column=Parameters[k], by = CondCol, ax=ax[k],showfliers = False) # linewidth = 2, width = 0.5\n",
    "            \n",
    "            if stats:\n",
    "                if len(box_pairs) == 0:\n",
    "                    box_pairs = makeBoxPairs(co_order)\n",
    "                addStat(ax[k], data_filtered, box_pairs, Parameters[k], CondCol, test = statMethod)\n",
    "                # add_stat_annotation(ax[k], x=CondCol, y=Parameters[k], data=data_filtered,box_pairs = box_pairs,test=statMethod, text_format='star',loc='inside', verbose=2)\n",
    "                    \n",
    "            sns.swarmplot(x=CondCol, y=Parameters[k], data=data_filtered, ax=ax[k], order = co_order,\n",
    "                          size=markerSize, edgecolor='k', linewidth = 1*markerSizeFactor, palette = p)\n",
    "            \n",
    "            ax[k].set_xlabel('')\n",
    "            ax[k].set_ylabel(Parameters[k])\n",
    "            ax[k].tick_params(axis='x', labelrotation = 10)\n",
    "            ax[k].yaxis.grid(True)           \n",
    "            \n",
    "    else:\n",
    "        if Parameters[0] == 'EChadwick':\n",
    "            ax.set_yscale('log')\n",
    "                \n",
    "        if Boxplot:\n",
    "            sns.boxplot(x=CondCol, y=Parameters[0], data=data_filtered, ax=ax, \n",
    "                        color='w', linewidth = 2, width = 0.5, showfliers = False, order= co_order)\n",
    "            # data_filtered.boxplot(column=Parameters[k], by = CondCol, ax=ax[k],showfliers = False) # linewidth = 2, width = 0.5\n",
    "\n",
    "        if stats:\n",
    "            if len(box_pairs) == 0:\n",
    "                box_pairs = makeBoxPairs(co_order)\n",
    "            addStat(ax, data_filtered, box_pairs, Parameters[0], CondCol, test = statMethod)\n",
    "            # add_stat_annotation(ax, x=CondCol, y=Parameters[0], data=data_filtered,box_pairs = box_pairs,test=statMethod, text_format='star',loc='inside', verbose=2)\n",
    "\n",
    "        sns.swarmplot(x=CondCol, y=Parameters[0], data=data_filtered, ax=ax, order= co_order, \n",
    "                      size=markerSize, edgecolor='k',linewidth = 1*markerSizeFactor, palette = p)\n",
    "    \n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel(Parameters[0])\n",
    "        ax.tick_params(axis='x', labelrotation = 10)\n",
    "        ax.yaxis.grid(True)\n",
    "    \n",
    "    plt.rcParams['axes.prop_cycle'] = my_default_color_cycle\n",
    "    return(fig, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def D2Plot(data, XCol='',YCol='',CondCol='',Filters=[], cellID='cellID', AvgPerCell=False, modelFit=False, modelType='y=ax+b',\\\n",
    "           xscale = 'lin', yscale = 'lin', figSizeFactor = 1):\n",
    "    data_filtered = data\n",
    "    for fltr in Filters:\n",
    "        data_filtered = data_filtered.loc[fltr]\n",
    "    \n",
    "    NCond = len(CondCol)    \n",
    "    if NCond == 1:\n",
    "        CondCol = CondCol[0]\n",
    "    elif NCond > 1:\n",
    "        newColName = ''\n",
    "        for i in range(NCond):\n",
    "            newColName += CondCol[i]\n",
    "            newColName += ' & '\n",
    "        newColName = newColName[:-3]\n",
    "        data_filtered[newColName] = ''\n",
    "        for i in range(NCond):\n",
    "            data_filtered[newColName] += data_filtered[CondCol[i]].astype(str)\n",
    "            data_filtered[newColName] = data_filtered[newColName].apply(lambda x : x + ' & ')\n",
    "        data_filtered[newColName] = data_filtered[newColName].apply(lambda x : x[:-3])\n",
    "        CondCol = newColName\n",
    "    \n",
    "    if AvgPerCell:\n",
    "        group = data_filtered.groupby(cellID)\n",
    "        dictAggMean = getDictAggMean(data_filtered)\n",
    "        data_filtered = group.agg(dictAggMean.pop(cellID)) #.reset_index(level=0, inplace=True)\n",
    "        data_filtered.reset_index(level=0, inplace=True)\n",
    "        \n",
    "    Conditions = list(data_filtered[CondCol].unique())\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (8*figSizeFactor,5))\n",
    "    markerSize = 5\n",
    "    \n",
    "    if xscale == 'log':\n",
    "        ax.set_xscale('log')\n",
    "    if yscale == 'log':\n",
    "        ax.set_yscale('log')\n",
    "    \n",
    "    current_color_list = getStyleLists(Conditions, styleDict1).as_hex()\n",
    "    cc = cycler(color=current_color_list)\n",
    "    ax.set_prop_cycle(cc)\n",
    "    \n",
    "    if modelFit:\n",
    "        # Tweak the style cycle to plot for each condition: the points ('o') and then the fit ('-') with the same color.\n",
    "#         current_prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "#         current_color_list = prop_cycle.by_key()['color']\n",
    "        ncustom_color_list = list(np.array([current_color_list, current_color_list]).flatten(order='F'))\n",
    "        # if new_color_list was ['red', 'green', blue'], custom_color_list is now ['red', 'red', 'green', 'green', blue', blue']\n",
    "        cc = cycler(color=ncustom_color_list)\n",
    "        ax.set_prop_cycle(cc)\n",
    "    \n",
    "    for c in Conditions:\n",
    "        Xraw = data_filtered[data_filtered[CondCol] == c][XCol].values\n",
    "        Yraw = data_filtered[data_filtered[CondCol] == c][YCol].values\n",
    "        XYraw = np.array([Xraw,Yraw]).T\n",
    "        XY = XYraw[~np.isnan(XYraw).any(axis=1), :]\n",
    "        X, Y = XY[:,0], XY[:,1]\n",
    "        if len(X) == 0:\n",
    "            ax.plot([], [])\n",
    "            if modelFit:\n",
    "                ax.plot([], [])\n",
    "                \n",
    "        elif len(X) > 0:\n",
    "            eqnText = ''\n",
    "\n",
    "            if modelFit:\n",
    "                print('Fitting condition: ' + c + ' with model ' + modelType)\n",
    "                if modelType == 'y=ax+b':\n",
    "                    params, results = fitLine(X, Y) # Y=a*X+b ; params[0] = b,  params[1] = a\n",
    "                    pval = results.pvalues[1] # pvalue on the param 'a'\n",
    "                    eqnText += \" ; Y = {:.1f} X + {:.1f}\".format(params[1], params[0])\n",
    "                    eqnText += \" ; p-val = {:.2e}\".format(pval)\n",
    "                    print(\"Y = {:.5} X + {:.5}\".format(params[1], params[0]))\n",
    "                    print(\"p-value on the 'a' coefficient: {:.4e}\".format(pval))\n",
    "                    print('\\n')\n",
    "                    fitY = params[1]*X + params[0]\n",
    "                    imin = np.argmin(X)\n",
    "                    imax = np.argmax(X)\n",
    "                    ax.plot([X[imin],X[imax]], [fitY[imin],fitY[imax]], '--', lw = '1')\n",
    "\n",
    "                elif modelType == 'y=A*exp(kx)':\n",
    "                    params, results = fitLine(X, np.log(Y)) # Y=a*X+b ; params[0] = b,  params[1] = a\n",
    "                    pval = results.pvalues[1] # pvalue on the param 'a'\n",
    "                    eqnText += \" ; Y = {:.1f}*exp({:.1f}*X)\".format(params[0], params[1])\n",
    "                    eqnText += \" ; p-val = {:.2e}\".format(pval)\n",
    "                    print(\"Y = {:.5}*exp({:.5}*X)\".format(np.exp(params[0]), params[1]))\n",
    "                    print(\"p-value on the 'k' coefficient: {:.4e}\".format(pval))\n",
    "                    print('\\n')\n",
    "                    fitY = np.exp(params[0])*np.exp(params[1]*X)\n",
    "                    imin = np.argmin(X)\n",
    "                    imax = np.argmax(X)\n",
    "                    ax.plot([X[imin],X[imax]], [fitY[imin],fitY[imax]], '--', lw = '1')\n",
    "                    \n",
    "            ax.plot(X, Y, 'o', markersize = markerSize, markeredgecolor='k', markeredgewidth = 1, label=c + eqnText)\n",
    "            \n",
    "            \n",
    "    ax.set_xlabel(XCol)\n",
    "    ax.set_xlim([min(0,1.1*np.min(data_filtered[XCol])), 1.1*np.max(data_filtered[XCol])])\n",
    "    ax.set_ylabel(YCol)\n",
    "    if not yscale == 'log':\n",
    "        ax.set_ylim([min(0,1.1*np.min(data_filtered[YCol])), 1.1*np.max(data_filtered[YCol])])\n",
    "    ax.legend(loc='upper left')\n",
    "    return(fig, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions use the Bokeh library to display 1D categorical or 2D plots with interactive plots. They are less flexible but can be nice to explore the data set since you can display the cellID which is the source of each point by passing your pointer over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def D1PlotInteractive(data, CondCol='',Parameters=[],Filters=[],AvgPerCell=False,cellID='cellID'):\n",
    "    data_filtered = data\n",
    "    for fltr in Filters:\n",
    "        data_filtered = data_filtered.loc[fltr]\n",
    "        \n",
    "#     print(data_filtered[cellID])\n",
    "    if AvgPerCell:\n",
    "        group = data_filtered.groupby(cellID)\n",
    "        dictAggMean = getDictAggMean(data_filtered)\n",
    "        data_filtered = group.agg(dictAggMean.pop(cellID)) #.reset_index(level=0, inplace=True)\n",
    "        data_filtered.reset_index(level=0, inplace=True)\n",
    "    \n",
    "#     return(data_filtered)\n",
    "    \n",
    "    NPlots = len(Parameters)\n",
    "    Conditions = list(data_filtered[CondCol].unique())\n",
    "    if NPlots > 1:\n",
    "        plots = []\n",
    "        NCond = len(Conditions)\n",
    "        data_filtered['X'] = 0\n",
    "        data_filtered['X_jitter'] = 0.\n",
    "        dictTicks = {}\n",
    "        for i in range(NCond):\n",
    "            mask = data_filtered[CondCol] == Conditions[i]\n",
    "            data_filtered.loc[mask, 'X'] = i+1\n",
    "            dictTicks[i+1] = Conditions[i]\n",
    "        for i in data_filtered.index:\n",
    "            data_filtered.loc[i, 'X_jitter'] = data_filtered.loc[i, 'X'] + 0.4*(np.random.rand(1)[0]-0.5)\n",
    "        source = ColumnDataSource(\n",
    "            data=data_filtered[[cellID]+[CondCol]+Parameters+['X','X_jitter']]\n",
    "        )        \n",
    "        \n",
    "        for k in range(NPlots):\n",
    "            hover = HoverTool(\n",
    "                tooltips=[\n",
    "                    ('Cell ID', \"@\"+cellID),\n",
    "                    (Parameters[k], \"@\"+Parameters[k]),\n",
    "                ]\n",
    "            )\n",
    "            index_cmap = factor_cmap(CondCol, palette=Category10[10], factors=sorted(data_filtered[CondCol].unique()), end=1)\n",
    "            p = figure(plot_width=450, plot_height=500, tools=[hover], title=\"InteractivePlot\") # \n",
    "            p.circle('X_jitter', Parameters[k], size=8, alpha = 0.6, source=source,fill_color=index_cmap,line_color='black')\n",
    "            # Format\n",
    "            p.x_range = Range1d(0, NCond+1)\n",
    "            p.y_range = Range1d(min(0,1.1*np.min(data_filtered[Parameters[0]])), 1.1*np.max(data_filtered[Parameters[k]]))\n",
    "            p.xaxis.ticker = [i for i in range(1,NCond+1)]\n",
    "            p.xaxis.major_label_overrides = dictTicks\n",
    "            p.xaxis.axis_label = CondCol\n",
    "            p.xaxis.axis_label_text_font_size = '18pt'\n",
    "            p.xaxis.major_label_text_font_size = '16pt'\n",
    "            p.yaxis.axis_label = Parameters[k]\n",
    "            p.yaxis.axis_label_text_font_size = '18pt'\n",
    "            p.yaxis.major_label_text_font_size = '16pt'\n",
    "            \n",
    "            plots.append(p)\n",
    "            \n",
    "        p = gridplot(plots, ncols=2, toolbar_location=None)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        hover = HoverTool(\n",
    "            tooltips=[\n",
    "                ('Cell ID', \"@\"+cellID),\n",
    "                (Parameters[0], \"@\"+Parameters[0]),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        NCond = len(Conditions)\n",
    "        data_filtered['X'] = 0\n",
    "        data_filtered['X_jitter'] = 0.\n",
    "        dictTicks = {}\n",
    "        for i in range(NCond):\n",
    "            mask = data_filtered[CondCol] == Conditions[i]\n",
    "            data_filtered.loc[mask, 'X'] = i+1\n",
    "            dictTicks[i+1] = Conditions[i]\n",
    "        for i in data_filtered.index:\n",
    "            data_filtered.loc[i, 'X_jitter'] = data_filtered.loc[i, 'X'] + 0.4*(np.random.rand(1)[0]-0.5)\n",
    "        source = ColumnDataSource(\n",
    "            data=data_filtered[[cellID]+[CondCol]+Parameters+['X','X_jitter']]\n",
    "        )\n",
    "        index_cmap = factor_cmap(CondCol, palette=Category10[10], factors=sorted(data_filtered[CondCol].unique()), end=1)\n",
    "        TOOLS = \"hover,pan,box_zoom,wheel_zoom,reset,save,help\"\n",
    "        p = figure(plot_width=500, plot_height=500, tools=TOOLS, title=\"InteractivePlot\") # \n",
    "        p.circle('X_jitter', Parameters[0], size=8, alpha = 0.6, source=source,fill_color=index_cmap,line_color='black')\n",
    "        # Format\n",
    "        p.x_range = Range1d(0, NCond+1)\n",
    "        p.y_range = Range1d(min(0,1.1*np.min(data_filtered[Parameters[0]])), 1.1*np.max(data_filtered[Parameters[0]]))\n",
    "        p.xaxis.ticker = [i for i in range(1,NCond+1)]\n",
    "        p.xaxis.major_label_overrides = dictTicks\n",
    "        p.xaxis.axis_label = CondCol\n",
    "        p.xaxis.axis_label_text_font_size = '18pt'\n",
    "        p.xaxis.major_label_text_font_size = '16pt'\n",
    "        p.yaxis.axis_label = Parameters[0]\n",
    "        p.yaxis.axis_label_text_font_size = '18pt'\n",
    "        p.yaxis.major_label_text_font_size = '16pt'\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def D2PlotInteractive(data, XCol='',YCol='',CondCol='',Filters=[], cellID='cellID',AvgPerCell=False):\n",
    "    \n",
    "    data_filtered = data\n",
    "    for fltr in Filters:\n",
    "        data_filtered = data_filtered.loc[fltr]\n",
    "        \n",
    "    if AvgPerCell:\n",
    "        group = data_filtered.groupby(cellID)\n",
    "        dictAggMean = getDictAggMean(data_filtered)\n",
    "        data_filtered = group.agg(dictAggMean.pop(cellID)) #.reset_index(level=0, inplace=True)\n",
    "        data_filtered.reset_index(level=0, inplace=True)\n",
    "    \n",
    "    Conditions = list(data_filtered[CondCol].unique())\n",
    "\n",
    "    NCond = len(Conditions)\n",
    "    dictTicks = {}\n",
    "    for i in range(NCond):\n",
    "        dictTicks[i+1] = Conditions[i]\n",
    "    \n",
    "    source = ColumnDataSource(\n",
    "        data=data_filtered[[cellID,CondCol,XCol,YCol]]\n",
    "    )\n",
    "    \n",
    "    hover = HoverTool(\n",
    "        tooltips=[\n",
    "            ('Cell ID', \"@\"+cellID),\n",
    "            (XCol, \"@\"+XCol),\n",
    "            (YCol, \"@\"+YCol),\n",
    "            (CondCol, \"@\"+CondCol),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    index_cmap = factor_cmap(CondCol, palette=Category10[10], factors=sorted(data_filtered[CondCol].unique()), end=1)\n",
    "    TOOLS = \"pan,box_zoom,wheel_zoom,reset,save,help\"\n",
    "    p = figure(plot_width=900, plot_height=500, tools=TOOLS, title=\"InteractivePlot\",toolbar_location=\"below\") # \n",
    "    p.circle(XCol, YCol, size=8, alpha = 0.6, source=source,fill_color=index_cmap,line_color='black')\n",
    "    p.add_tools(hover)\n",
    "    # Format\n",
    "    p.x_range = Range1d(0, 1.1*np.max(data_filtered[XCol]))\n",
    "    p.y_range = Range1d(0, 1.1*np.max(data_filtered[YCol]))\n",
    "    p.xaxis.axis_label = XCol\n",
    "    p.xaxis.axis_label_text_font_size = '18pt'\n",
    "    p.xaxis.major_label_text_font_size = '16pt'\n",
    "    p.yaxis.axis_label = YCol\n",
    "    p.yaxis.axis_label_text_font_size = '18pt'\n",
    "    p.yaxis.major_label_text_font_size = '16pt'\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other subfunctions useful to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     13,
     17,
     42,
     84,
     116
    ]
   },
   "outputs": [],
   "source": [
    "def makeOrder(*args):\n",
    "    order = []\n",
    "    listeTuple = list(itertools.product(*args, repeat=1))\n",
    "    for tup in listeTuple:\n",
    "        tmpText = ''\n",
    "        for word in tup:\n",
    "            tmpText += word\n",
    "            tmpText += ' & '\n",
    "        tmpText = tmpText[:-3]\n",
    "        order.append(tmpText)\n",
    "    return(order)\n",
    "\n",
    "\n",
    "def makeBoxPairs(O):\n",
    "    return(list(itertools.combinations(O, 2)))\n",
    "\n",
    "\n",
    "def renameAxes(axes, rD):\n",
    "    try:\n",
    "        N = len(axes)\n",
    "    except:\n",
    "        axes = [axes]\n",
    "        N = 1\n",
    "    for i in range(N):\n",
    "        # set xticks\n",
    "        xticksTextObject = axes[i].get_xticklabels()\n",
    "        xticksList = [xticksTextObject[j].get_text() for j in range(len(xticksTextObject))]\n",
    "        test_hasXLabels = (len(''.join(xticksList)) > 0)\n",
    "        if test_hasXLabels:\n",
    "            newXticksList = [rD.get(k, k) for k in xticksList]\n",
    "            axes[i].set_xticklabels(newXticksList)\n",
    "        \n",
    "        # set xlabel\n",
    "        xlabel = axes[i].get_xlabel()\n",
    "        newXlabel = rD.get(xlabel, xlabel)\n",
    "        axes[i].set_xlabel(newXlabel)\n",
    "        # set ylabel\n",
    "        ylabel = axes[i].get_ylabel()\n",
    "        newYlabel = rD.get(ylabel, ylabel)\n",
    "        axes[i].set_ylabel(newYlabel)\n",
    "        \n",
    "\n",
    "def addStat(ax, data, box_pairs, param, cond, test = 'MannWhitney', percentHeight = 98):\n",
    "    refHeight = np.percentile(data[param].values, percentHeight)\n",
    "    currentHeight = refHeight\n",
    "    scale = ax.get_yscale()\n",
    "    xTicks = ax.get_xticklabels()\n",
    "    dictXTicks = {xTicks[i].get_text() : xTicks[i].get_position()[0] for i in range(len(xTicks))}\n",
    "    for bp in box_pairs:\n",
    "        c1 = data[data[cond] == bp[0]][param].values\n",
    "        c2 = data[data[cond] == bp[1]][param].values\n",
    "        if test=='Mann-Whitney':\n",
    "            statistic, pval = st.mannwhitneyu(c1,c2)\n",
    "        elif test=='t-test':\n",
    "            statistic, pval = st.ttest_ind(c1,c2)\n",
    "        text = 'ns'\n",
    "        if pval < 0.05 and pval > 0.01:\n",
    "            text = '*'\n",
    "        elif pval < 0.01 and pval > 0.001:\n",
    "            text = '**'\n",
    "        elif pval < 0.001 and pval < 0.001:\n",
    "            text = '***'\n",
    "        elif pval < 0.0001:\n",
    "            text = '****'\n",
    "        ax.plot([bp[0], bp[1]], [currentHeight, currentHeight], 'k-', lw = 1)\n",
    "        XposText = (dictXTicks[bp[0]]+dictXTicks[bp[1]])/2\n",
    "        if scale == 'log':\n",
    "            power = 0.006 * (text=='ns') + 0.000 * (text!='ns')\n",
    "            YposText = currentHeight*(refHeight**power)\n",
    "        else:\n",
    "            factor = 0.025 * (text=='ns') + 0.000 * (text!='ns')\n",
    "            YposText = currentHeight + factor*refHeight\n",
    "        ax.text(XposText, YposText, text, ha = 'center')\n",
    "#         if text=='ns':\n",
    "#             ax.text(posText, currentHeight + 0.025*refHeight, text, ha = 'center')\n",
    "#         else:\n",
    "#             ax.text(posText, currentHeight, text, ha = 'center')\n",
    "        if scale == 'log':\n",
    "            currentHeight = currentHeight*(refHeight**0.05)\n",
    "        else:\n",
    "            currentHeight =  currentHeight + 0.15*refHeight\n",
    "    ax.set_ylim([ax.get_ylim()[0], currentHeight])\n",
    "    \n",
    "\n",
    "def getStyleCycle(co_order, styleDict):\n",
    "    colors = []\n",
    "    markers = []\n",
    "    linestyles = []\n",
    "    linewidth = []\n",
    "\n",
    "    for co in co_order:\n",
    "        coStyle = styleDict[co]\n",
    "        if 'color' in coStyle.keys():\n",
    "            colors.append(coStyle['color'])\n",
    "        else:\n",
    "            colors.append('')\n",
    "        if 'marker' in coStyle.keys():\n",
    "            markers.append(coStyle['marker'])\n",
    "        else:\n",
    "            markers.append('')\n",
    "        if 'linestyle' in coStyle.keys():\n",
    "            linestyles.append(coStyle['marker'])\n",
    "        else:\n",
    "            linestyles.append('')\n",
    "        if 'linewidth' in coStyle.keys():\n",
    "            linewidth.append(coStyle['linewidth'])\n",
    "        else:\n",
    "            linewidth.append(1)\n",
    "            \n",
    "    cc = (cycler(color=colors) +\n",
    "          cycler(linestyle=linestyles) +\n",
    "          cycler(marker=markers) +\n",
    "          cycler(linewidth=linewidth))\n",
    "            \n",
    "    return(cc)\n",
    "\n",
    "def getStyleLists(co_order, styleDict):\n",
    "    colors = []\n",
    "    markers = []\n",
    "    try:\n",
    "        for co in co_order:\n",
    "            coStyle = styleDict[co]\n",
    "            if 'color' in coStyle.keys():\n",
    "                colors.append(coStyle['color'])\n",
    "            else:\n",
    "                colors.append('')\n",
    "            if 'marker' in coStyle.keys():\n",
    "                markers.append(coStyle['marker'])\n",
    "            else:\n",
    "                markers.append('')\n",
    "        palette = sns.color_palette(colors)\n",
    "    except:\n",
    "        palette = sns.color_palette()\n",
    "    return(palette)\n",
    "\n",
    "\n",
    "def buildStyleDictMCA():\n",
    "    # TBC\n",
    "    styleDict = {}\n",
    "    return(styleDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Test of the averaging per cell routine\n",
    "\n",
    "# data = GlobalTable_meca\n",
    "# CondCol='drug'\n",
    "# Parameters=['SurroundingThickness','EChadwick']\n",
    "# Filters = [(GlobalTable_meca['Validated'] == 1)]\n",
    "# AvgPerCell=True\n",
    "# cellID='CellName'\n",
    "\n",
    "# data_filtered = data\n",
    "# for fltr in Filters:\n",
    "#     data_filtered = data_filtered.loc[fltr]\n",
    "\n",
    "# group = data_filtered.groupby(cellID)\n",
    "# dictAggMean = getDictAggMean(data_filtered)\n",
    "# data_filtered = group.agg(dictAggMean.pop(cellID)) #.reset_index(level=0, inplace=True)\n",
    "# data_filtered.reset_index(level=0, inplace=True)\n",
    "# data_filtered=data_filtered[[cellID]+[CondCol]+Parameters]\n",
    "# print(data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Test of a routine to remove points of a list of XY positions where at least 1 of the coordinates is 'nan'\n",
    "\n",
    "# XYraw = np.array([[np.nan, 2, 3, np.nan, 5], [10,20,30,40,50]])\n",
    "# XYraw = XYraw.T\n",
    "# XY = XYraw[~np.isnan(XYraw).any(axis=1), :]\n",
    "# X, Y = XY[:,0], XY[:,1]\n",
    "# X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Test of a routine to double each element in a list ; example [1, 2, 3] -> [1, 1, 2, 2, 3, 3]\n",
    "\n",
    "# newnew_color_list = np.array([new_color_list, new_color_list])\n",
    "# custom_color_list = list(np.array([new_color_list, new_color_list]).flatten(order='F'))\n",
    "# custom_color_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Test of makeOrder function\n",
    "\n",
    "# print(makeOrder(['none','doxycyclin'],['BSA coated glass','20um fibronectin discs']))\n",
    "# print(makeOrder(['A','B']))\n",
    "# print(makeOrder(['A','B'], ['C','D']))\n",
    "# print(makeOrder(['A','B'], ['C','D'], ['E','F']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Test of makeBoxPairs function\n",
    "\n",
    "# O = makeOrder(['none','doxycyclin'],['BSA coated glass','20um fibronectin discs'])\n",
    "# makeBoxPairs(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Test of custom cycles\n",
    "\n",
    "cc = (cycler(color=list('rgb')) +\n",
    "      cycler(linestyle=['', '', '']) +\n",
    "      cycler(marker=['o','*','<']) +\n",
    "     cycler(linewidth=[1,1,1]))\n",
    "cc\n",
    "\n",
    "# plt.rcParams['axes.prop_cycle'] = cc\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# for i in range(10):\n",
    "#     ax.plot([0,1], [0,i])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.color_palette(\"tab20\").as_hex()\n",
    "p[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawMecaTable = getGlobalTable_meca()\n",
    "# rawMecaTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawMecaTable.loc[]\n",
    "# Agréger tous les M450 WT sous un même nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(rawMecaTable['Validated'] == 1), ((rawMecaTable['ExpType'] == 'DictyDB_M270') | (rawMecaTable['ExpType'] == 'DictyDB_M450')), (rawMecaTable['TpsComp'] == '1s')]\n",
    "# Filters = [(rawMecaTable['Validated'] == 1), ((rawMecaTable['ExpType'] == 'DictyDB_M450')), (rawMecaTable['TpsComp'] == '1s')]\n",
    "fig, ax = D1Plot(rawMecaTable, CondCol=['ExpType'],Parameters=['SurroundingThickness','EChadwick'],\\\n",
    "                 Filters=Filters,AvgPerCell=True,cellID='CellName')\n",
    "fig.suptitle('M450 vs M270 pour compressions de 1s')\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.show()\n",
    "# rawMecaTable[Filters[0] & Filters[1] & Filters[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(rawMecaTable['Validated'] == 1), ((rawMecaTable['ExpType'] == 'DictyDB_M450'))] #  | (rawMecaTable['ExpType'] == 'DictyDB_M450-Multi')\n",
    "co_order = makeOrder(['02s', '05s', '1s', '2s', '4s', '7s', '12s']) # co_order = co_order,\n",
    "fig, ax00 = D1Plot(rawMecaTable, CondCol=['TpsComp'],Parameters=['SurroundingThickness','EChadwick'], co_order = co_order,\\\n",
    "                   Filters=Filters,AvgPerCell=False,cellID='CellName',stats=False,figSizeFactor = 1.8,markerSizeFactor=0.5)\n",
    "fig.suptitle('M450, various rates')\n",
    "renameAxes(ax00,renameDict1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(rawMecaTable['Validated'] == 1), ((rawMecaTable['ExpType'] == 'DictyDB_M270'))]\n",
    "fig, ax01 = D1Plot(rawMecaTable, CondCol=['TpsComp'],Parameters=['SurroundingThickness','EChadwick'],Filters=Filters,\\\n",
    "                   AvgPerCell=False,cellID='CellName',stats=False,figSizeFactor = 1.8,markerSizeFactor=0.5)\n",
    "fig.suptitle('M270, various rates')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_ctField['validated'] == True), (GlobalTable_ctField['medianThickness'] <= 1000)]\n",
    "fig, ax = D1Plot(GlobalTable_ctField, CondCol=['drug','substrate'],Parameters=['medianThickness','fluctuAmpli'],Filters=Filters)\n",
    "fig.suptitle('3T3aSFL on patterns: Ct Field')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == 1), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "co_order = makeOrder([['none','doxycyclin'],['BSA coated glass','20um fibronectin discs']])\n",
    "fig, ax = D1Plot(GlobalTable_meca, CondCol=['drug','substrate'],Parameters=['SurroundingThickness','EChadwick'],Filters=Filters,AvgPerCell=True,cellID='CellName', co_order=co_order)\n",
    "fig.suptitle('3T3aSFL on diverse substrates: Compressions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == 1), (GlobalTable_meca['cell subtype'] == 'aSFL-6FP')]\n",
    "fig, ax = D1Plot(GlobalTable_meca, CondCol=['drug','substrate'],Parameters=['SurroundingThickness','EChadwick'],Filters=Filters,AvgPerCell=True,cellID='CellName')\n",
    "fig.suptitle('3T3aSFL on patterns: Compressions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == 1), (GlobalTable_meca['substrate'] == '20um fibronectin discs')]\n",
    "co_order = makeOrder([['aSFL','aSFL-6FP'],['none','doxycyclin']])\n",
    "fig, ax = D1Plot(GlobalTable_meca, CondCol=['cell subtype','drug'],Parameters=['SurroundingThickness','EChadwick'],Filters=Filters,AvgPerCell=True,cellID='CellName',co_order=co_order)\n",
    "fig.suptitle('3T3aSFL on diverse substrates: Compressions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == 1), (GlobalTable_meca['substrate'] == '20um fibronectin discs')]\n",
    "co_order = makeOrder([['aSFL','aSFL-6FP'],['none','doxycyclin']])\n",
    "fig, ax = D1Plot(GlobalTable_meca, CondCol=['cell subtype','drug'],Parameters=['SurroundingThickness','EChadwick'],Filters=Filters,AvgPerCell=True,cellID='CellName',co_order=co_order)\n",
    "fig.suptitle('3T3aSFL SHORT vs LONG linker: Compressions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_ctField['validated'] == True), (GlobalTable_ctField['cell subtype'] == 'aSFL')]\n",
    "fig, ax = D2Plot(GlobalTable_ctField, XCol='medianThickness',YCol='fluctuAmpli',CondCol = ['drug'], Filters=Filters, modelFit=True)\n",
    "fig.suptitle('3T3aSFL - Dh = f(H)')\n",
    "archiveFig(fig, ax, name='aSFL_Dh(h)_drug', figDir = todayFigDir, figSubDir='ThicknessPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above without the 2 thickest cells\n",
    "Filters = [(GlobalTable_ctField['validated'] == True), (GlobalTable_ctField['cell subtype'] == 'aSFL'), (GlobalTable_ctField['medianThickness'] <= 700)]\n",
    "fig, ax = D2Plot(GlobalTable_ctField, XCol='medianThickness',YCol='fluctuAmpli',CondCol = ['drug'], Filters=Filters, modelFit=True)\n",
    "fig.suptitle('3T3aSFL - Dh = f(H)')\n",
    "archiveFig(fig, ax, name='aSFL_Dh(h)_drug_wo2LastPoints', figDir = todayFigDir, figSubDir='ThicknessPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='SurroundingThickness',YCol='EChadwick',CondCol = ['substrate','drug'],\\\n",
    "           Filters=Filters, cellID = 'CellName', AvgPerCell=True, modelFit=False, modelType='y=A*exp(kx)', yscale = 'log')\n",
    "fig.suptitle('3T3aSFL: E(h)')\n",
    "renameAxes(ax,renameDict1)\n",
    "ax.legend(loc='upper right')\n",
    "archiveFig(fig, ax, name='aSFL_E(h)_drug&substrate_01', figDir = todayFigDir, figSubDir='')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL'), (GlobalTable_meca['substrate'] == '20um fibronectin discs')]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='SurroundingThickness',YCol='EChadwick',CondCol = ['substrate','drug'],\\\n",
    "           Filters=Filters, cellID = 'CellName', AvgPerCell=False, modelFit=False, modelType='y=A*exp(kx)', xscale = 'log', \\\n",
    "                 yscale = 'log')\n",
    "fig.suptitle('3T3aSFL: E(h)')\n",
    "renameAxes(ax,renameDict1)\n",
    "ax.set_xlim([90, 1500])\n",
    "ax.legend(loc='upper right')\n",
    "archiveFig(fig, ax, name='aSFL_E(h)_drug&substrate_00_allComp', figDir = todayFigDir, figSubDir='')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['substrate'] == '20um fibronectin discs')]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='SurroundingThickness',YCol='EChadwick',CondCol = ['cell subtype','drug'],\\\n",
    "           Filters=Filters, cellID = 'CellName', AvgPerCell=True, modelFit=False, modelType='y=A*exp(kx)', yscale = 'log')\n",
    "fig.suptitle('3T3aSFL: E(h)')\n",
    "renameAxes(ax,renameDict1)\n",
    "ax.legend(loc='upper right')\n",
    "archiveFig(fig, ax, name='aSFL_E(h)_drug&substrate_02', figDir = todayFigDir, figSubDir='')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['substrate'] == '20um fibronectin discs')]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='SurroundingThickness',YCol='EChadwick',CondCol = ['cell subtype','drug'],\\\n",
    "           Filters=Filters, cellID = 'CellName', AvgPerCell=False, modelFit=False, modelType='y=A*exp(kx)', yscale = 'log')\n",
    "fig.suptitle('3T3aSFL: E(h)')\n",
    "renameAxes(ax,renameDict1)\n",
    "ax.legend(loc='upper right')\n",
    "archiveFig(fig, ax, name='aSFL_E(h)_drug&substrate_02_allComp', figDir = todayFigDir, figSubDir='')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_o = ['BSA coated glass & none', 'BSA coated glass & doxycyclin', '20um fibronectin discs & doxycyclin', '20um fibronectin discs & none']\n",
    "# getStyleLists(co_o, styleDict1)\n",
    "sns.color_palette(['#ff9896', '#d62728', '#1f77b4', '#aec7e8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='SurroundingThickness',YCol='EChadwick',CondCol = ['substrate','drug'],\\\n",
    "           Filters=Filters, cellID = 'CellName', AvgPerCell=True, modelFit=False, modelType='y=A*exp(kx)', yscale = 'log')\n",
    "fig.suptitle('3T3aSFL: E(h)')\n",
    "ax.legend(loc='upper right')\n",
    "archiveFig(fig, ax, name='aSFL_E(h)_drug&substrate', figDir = todayFigDir, figSubDir='')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xticksTextObject = ax.get_xticklabels()\n",
    "# xticksList = [xticksTextObject[j].get_text() for j in range(len(xticksTextObject))]\n",
    "# newXticksList = [renameDict1.get(k, k) for k in xticksList]\n",
    "# newXticksList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca_Py['validatedFit'] == True), (GlobalTable_meca_Py['validatedThickness'] == True), (GlobalTable_meca_Py['substrate'] == '20um fibronectin discs')]\n",
    "co_order = makeOrder(['aSFL','aSFL-A8','aSFL-6FP'], ['none','doxycyclin'])\n",
    "box_pairs=[('aSFL & none', 'aSFL & doxycyclin'),\n",
    " ('aSFL-A8 & none', 'aSFL-A8 & doxycyclin'),\n",
    " ('aSFL-6FP & none', 'aSFL-6FP & doxycyclin'),\n",
    " ('aSFL & none', 'aSFL-A8 & none'),\n",
    " ('aSFL & none', 'aSFL-6FP & none')]\n",
    "fig, ax = D1Plot(GlobalTable_meca_Py, CondCol=['cell subtype','drug'],Parameters=['surroundingThickness','EChadwick'],\\\n",
    "                 Filters=Filters,AvgPerCell=False,cellID='cellID',co_order=co_order,box_pairs=box_pairs,stats=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL - All linker types: All Compressions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots that exlore the impact of the delay before starting experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figSubDir = 'ExploratoryPlots'\n",
    "GlobalTable_meca_Py['compStartTimeThisDay_min'] = GlobalTable_meca_Py['compStartTimeThisDay']/60\n",
    "GlobalTable_meca_Py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figSubDir = 'ExploratoryPlots'\n",
    "Filters = [(GlobalTable_meca_Py['validatedFit'] == True), (GlobalTable_meca_Py['validatedThickness'] == True),\\\n",
    "           (GlobalTable_meca_Py['cell subtype'] == 'aSFL'), (GlobalTable_meca_Py['substrate'] == '20um fibronectin discs')]\n",
    "fig, ax = D1Plot(GlobalTable_meca_Py, CondCol=['manipID','drug'],Parameters=['surroundingThickness','EChadwick'],\\\n",
    "                 Filters=Filters,AvgPerCell=True,cellID='cellID',stats=False)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL - Compressions - Differences with manip')\n",
    "for i in range(len(ax)):\n",
    "    xTicks = ax[i].get_xticklabels()\n",
    "    for j in range(len(xTicks)):\n",
    "        xTicks[j].set_fontsize(9)\n",
    "archiveFig(fig, ax, name='3T3aSFL-Compressions-DifferencesWithManip_PYTHONTABLE', figSubDir = figSubDir)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca_Py['validatedFit'] == True), (GlobalTable_meca_Py['validatedThickness'] == True),\\\n",
    "           (GlobalTable_meca_Py['cell subtype'] == 'aSFL'), (GlobalTable_meca_Py['substrate'] == '20um fibronectin discs')]\n",
    "fig, ax = D2Plot(GlobalTable_meca_Py, XCol='compStartTimeThisDay_min',YCol='EChadwick', CondCol = ['date_x','drug'],\\\n",
    "           Filters=Filters, cellID = 'cellID', AvgPerCell=False, modelFit=False)\n",
    "renameAxes(ax,renameDict1)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlabel('Time since start of experiment (min)')\n",
    "fig.suptitle('3T3aSFL - Compressions - Evolution with time')\n",
    "archiveFig(fig, ax, name='3T3aSFL-Compressions-EvolWithTime_PYTHONTABLE', figSubDir = figSubDir)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca_Py['validatedFit'] == True), (GlobalTable_meca_Py['validatedThickness'] == True),\\\n",
    "           (GlobalTable_meca_Py['cell subtype'] == 'aSFL-A8'), (GlobalTable_meca_Py['substrate'] == '20um fibronectin discs')]\n",
    "fig, ax = D1Plot(GlobalTable_meca_Py, CondCol=['manipID','drug'],Parameters=['surroundingThickness','EChadwick'],\\\n",
    "                 Filters=Filters,AvgPerCell=True,cellID='cellID',stats=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL-A8 - Compressions - Differences with manip')\n",
    "for i in range(len(ax)):\n",
    "    xTicks = ax[i].get_xticklabels()\n",
    "    for j in range(len(xTicks)):\n",
    "        xTicks[j].set_fontsize(9)\n",
    "archiveFig(fig, ax, name='3T3aSFL-A8-Compressions-DifferencesWithManip_PYTHONTABLE', figSubDir = figSubDir)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca_Py['validatedFit'] == True), (GlobalTable_meca_Py['validatedThickness'] == True),\\\n",
    "           (GlobalTable_meca_Py['cell subtype'] == 'aSFL-A8'), (GlobalTable_meca_Py['substrate'] == '20um fibronectin discs')]\n",
    "fig, ax = D2Plot(GlobalTable_meca_Py, XCol='compStartTimeThisDay_min',YCol='EChadwick', CondCol = ['date_x','drug'],\\\n",
    "           Filters=Filters, cellID = 'cellID', AvgPerCell=False, modelFit=False)\n",
    "renameAxes(ax,renameDict1)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlabel('Time since start of experiment (min)')\n",
    "fig.suptitle('3T3aSFL-A8 - Compressions - Evolution with time')\n",
    "archiveFig(fig, ax, name='3T3aSFL-A8-Compressions-EvolWithTime_PYTHONTABLE', figSubDir = figSubDir)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca_Py['validatedFit'] == True), (GlobalTable_meca_Py['validatedThickness'] == True),\\\n",
    "           (GlobalTable_meca_Py['cell subtype'] == 'aSFL-6FP'), (GlobalTable_meca_Py['substrate'] == '20um fibronectin discs')]\n",
    "fig, ax = D1Plot(GlobalTable_meca_Py, CondCol=['manipID','drug'],Parameters=['surroundingThickness','EChadwick'],\\\n",
    "                 Filters=Filters,AvgPerCell=True,cellID='cellID',stats=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL-6FP - Compressions - Differences with manip')\n",
    "for i in range(len(ax)):\n",
    "    xTicks = ax[i].get_xticklabels()\n",
    "    for j in range(len(xTicks)):\n",
    "        xTicks[j].set_fontsize(9)\n",
    "archiveFig(fig, ax, name='3T3aSFL-6FP-Compressions-DifferencesWithManip_PYTHONTABLE', figSubDir = figSubDir)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca_Py['validatedFit'] == True), (GlobalTable_meca_Py['validatedThickness'] == True),\\\n",
    "           (GlobalTable_meca_Py['cell subtype'] == 'aSFL-6FP'), (GlobalTable_meca_Py['substrate'] == '20um fibronectin discs')]\n",
    "fig, ax = D2Plot(GlobalTable_meca_Py, XCol='compStartTimeThisDay_min',YCol='EChadwick', CondCol = ['date_x','drug'],\\\n",
    "           Filters=Filters, cellID = 'cellID', AvgPerCell=False, modelFit=False)\n",
    "renameAxes(ax,renameDict1)\n",
    "ax.legend(loc='upper right')\n",
    "ax.set_xlabel('Time since start of experiment (min)')\n",
    "fig.suptitle('3T3aSFL-6FP - Compressions - Evolution with time')\n",
    "archiveFig(fig, ax, name='3T3aSFL-6FP-Compressions-EvolWithTime_PYTHONTABLE', figSubDir = figSubDir)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_ctField['validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "\n",
    "p = D1PlotInteractive(GlobalTable_ctField, CondCol='drug',Parameters=['medianThickness','fluctuAmpli'],Filters=Filters)\n",
    "p.children[0][0].title.text = '3T3aSFL on patterns: Ct Field'\n",
    "p.children[0][0].title.text_font_size = '16pt'\n",
    "p.children[1][0].title.text = ''\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == 1), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "p = D1PlotInteractive(GlobalTable_meca, CondCol='drug',Parameters=['SurroundingThickness','EChadwick'],Filters=Filters,AvgPerCell=True,cellID='CellName')\n",
    "p.children[0][0].title.text = '3T3aSFL on patterns: Compressions'\n",
    "p.children[0][0].title.text_font_size = '14pt'\n",
    "p.children[1][0].title.text = ''\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_ctField['validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "p = D2PlotInteractive(GlobalTable_ctField, XCol='medianThickness',YCol='fluctuAmpli',CondCol = 'drug', Filters=Filters)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "p = D2PlotInteractive(GlobalTable_meca, XCol='SurroundingThickness',YCol='EChadwick',CondCol = 'drug', Filters=Filters, cellID = 'CellName')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_ctField['validated'] == True)]\n",
    "p = D2PlotInteractive(GlobalTable_ctField, XCol='meanFluoPeakAmplitude',YCol='medianThickness',CondCol = 'drug', Filters=Filters, cellID = 'cellID',AvgPerCell=True)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True)]\n",
    "p = D2PlotInteractive(GlobalTable_meca, XCol='meanFluoPeakAmplitude',YCol='SurroundingThickness',CondCol = 'drug', Filters=Filters, cellID = 'CellName',AvgPerCell=True)\n",
    "p.title.text = '3T3aSFL expressing linker: H(fluo)'\n",
    "p.title.text_font_size = '16pt'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "p = D2PlotInteractive(GlobalTable_meca, XCol='meanFluoPeakAmplitude', YCol='EChadwick', CondCol = 'drug', Filters=Filters, cellID = 'CellName',AvgPerCell=True)\n",
    "p.title.text = 'aSFL expressing linker: E(fluo)'\n",
    "p.title.text_font_size = '16pt'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "p = D2PlotInteractive(GlobalTable_meca, XCol='meanFluoPeakAmplitude',YCol='SurroundingThickness',CondCol = 'drug', Filters=Filters, cellID = 'CellName',AvgPerCell=True)\n",
    "p.title.text = 'aSFL expressing linker: H(fluo)'\n",
    "p.title.text_font_size = '16pt'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL-6FP')]\n",
    "p = D2PlotInteractive(GlobalTable_meca, XCol='meanFluoPeakAmplitude', YCol='EChadwick', CondCol = 'drug', Filters=Filters, cellID = 'CellName',AvgPerCell=True)\n",
    "p.title.text = 'aSFL-6FP expressing long linker: E(fluo)'\n",
    "p.title.text_font_size = '16pt'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL-6FP')]\n",
    "p = D2PlotInteractive(GlobalTable_meca, XCol='meanFluoPeakAmplitude', YCol='SurroundingThickness', CondCol = 'drug', Filters=Filters, cellID = 'CellName',AvgPerCell=True)\n",
    "p.title.text = 'aSFL-6FP expressing long linker: H(fluo)'\n",
    "p.title.text_font_size = '16pt'\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     22
    ]
   },
   "outputs": [],
   "source": [
    "renameDict1 = {'SurroundingThickness':'Thickness (nm) [b&a]',\\\n",
    "               'surroundingThickness':'Thickness (nm) [b&a]',\\\n",
    "               'ctFieldThickness':'Thickness at low force (nm)',\\\n",
    "               'EChadwick': 'E Chadwick (Pa)',\\\n",
    "               'medianThickness': 'Median Thickness (nm)',\\\n",
    "               'fluctuAmpli': 'Fluctuations Amplitude (nm)',\\\n",
    "               'meanFluoPeakAmplitude' : 'Fluo Intensity (a.u.)',\\\n",
    "               'none & BSA coated glass':'control & non adherent',\\\n",
    "               'doxycyclin & BSA coated glass':'iMC & non adherent',\\\n",
    "               'none & 20um fibronectin discs':'control & adherent on fibro',\\\n",
    "               'doxycyclin & 20um fibronectin discs':'iMC & adherent on fibro',\\\n",
    "               'BSA coated glass & none':'control & non adherent',\\\n",
    "               'BSA coated glass & doxycyclin':'iMC & non adherent',\\\n",
    "               '20um fibronectin discs & none':'control & adherent on fibro',\\\n",
    "               '20um fibronectin discs & doxycyclin':'iMC & adherent on fibro',\\\n",
    "               'aSFL & none':'aSFL control',\\\n",
    "               'aSFL & doxycyclin':'aSFL iMC',\\\n",
    "               'aSFL-6FP & none':'aSFL-6FP control',\\\n",
    "               'aSFL-6FP & doxycyclin':'aSFL-6FP long-iMC',\\\n",
    "               'aSFL-A8 & none':'aSFL-A8 control',\\\n",
    "               'aSFL-A8 & doxycyclin':'aSFL-A8 iMC'}\n",
    "\n",
    "styleDict1 =  {'none & BSA coated glass':{'color':'#ff9896','marker':'^'},\\\n",
    "               'doxycyclin & BSA coated glass':{'color':'#d62728','marker':'^'},\\\n",
    "               'none & 20um fibronectin discs':{'color':'#aec7e8','marker':'o'},\\\n",
    "               'doxycyclin & 20um fibronectin discs':{'color':'#1f77b4','marker':'o'},\\\n",
    "               'BSA coated glass & none':{'color':'#ff9896','marker':'^'},\\\n",
    "               'BSA coated glass & doxycyclin':{'color':'#d62728','marker':'^'},\\\n",
    "               '20um fibronectin discs & none':{'color':'#aec7e8','marker':'o'},\\\n",
    "               '20um fibronectin discs & doxycyclin':{'color':'#1f77b4','marker':'o'},\\\n",
    "               'aSFL':{'color':'#1f77b4','marker':'o'},\\\n",
    "               'aSFL-6FP':{'color':'#2ca02c','marker':'o'},\\\n",
    "               'aSFL-A8':{'color':'#ff7f0e','marker':'o'}, \\\n",
    "               'aSFL & none':{'color':'#aec7e8','marker':'o'},\\\n",
    "               'aSFL & doxycyclin':{'color':'#1f77b4','marker':'o'},\\\n",
    "               'aSFL-6FP & none':{'color':'#98df8a','marker':'o'},\\\n",
    "               'aSFL-6FP & doxycyclin':{'color':'#2ca02c','marker':'o'},\\\n",
    "               'aSFL-A8 & none':{'color':'#ffbb78','marker':'o'},\\\n",
    "               'aSFL-A8 & doxycyclin':{'color':'#ff7f0e','marker':'o'}}\n",
    "\n",
    "\n",
    "figSubDir = 'CleanPlots'\n",
    "\n",
    "print(pairedPalette)\n",
    "pairedPalette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thickness and module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == 1), (GlobalTable_meca['cell subtype'] == 'aSFL'), (GlobalTable_meca['substrate'] == 'BSA coated glass'), (GlobalTable_meca['SurroundingThickness'] > 0)]\n",
    "co_order = makeOrder(['BSA coated glass'],['none','doxycyclin'])\n",
    "fig, ax = D1Plot(GlobalTable_meca, CondCol=['substrate','drug'],\\\n",
    "                 Parameters=['SurroundingThickness','EChadwick'], Filters=Filters,\\\n",
    "                 AvgPerCell=False, cellID='CellName', co_order=co_order, figSizeFactor = 0.5)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL non-adherent: Compressions')\n",
    "archiveFig(fig, ax, name='3T3aSFLonBSA_drug_SurroundingThickness&EChadwick_allComp', figSubDir = figSubDir)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == 1), (GlobalTable_meca['cell subtype'] == 'aSFL'), (GlobalTable_meca['SurroundingThickness'] > 0)]\n",
    "co_order = makeOrder(['BSA coated glass','20um fibronectin discs'],['none','doxycyclin'])\n",
    "fig, ax = D1Plot(GlobalTable_meca, CondCol=['substrate','drug'],\\\n",
    "                 Parameters=['SurroundingThickness','EChadwick'],Filters=Filters,\\\n",
    "                 AvgPerCell=True, cellID='CellName', co_order=co_order, figSizeFactor = 0.8)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL on diverse substrates: Compressions')\n",
    "archiveFig(fig, ax, name='3T3aSFL_substrate&drug_SurroundingThickness&EChadwick', figSubDir = figSubDir)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca_Py['validatedFit'] == True), (GlobalTable_meca_Py['validatedThickness'] == True), (GlobalTable_meca_Py['cell subtype'] == 'aSFL')]\n",
    "co_order = makeOrder(['BSA coated glass','20um fibronectin discs'],['none','doxycyclin'])\n",
    "fig, ax = D1Plot(GlobalTable_meca_Py, CondCol=['substrate','drug'],\\\n",
    "                 Parameters=['surroundingThickness','EChadwick'],Filters=Filters,\\\n",
    "                 AvgPerCell=True, cellID='cellID', co_order=co_order, figSizeFactor = 0.8)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL on diverse substrates: Compressions')\n",
    "archiveFig(fig, ax, name='3T3aSFL_substrate&drug_SurroundingThickness&EChadwick_NEWTABLE', figSubDir = figSubDir)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters = [(GlobalTable_meca['Validated'] == 1), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "# co_order = makeOrder(['BSA coated glass','20um fibronectin discs'],['none','doxycyclin'])\n",
    "# fig, ax = D1Plot(GlobalTable_meca, CondCol=['substrate','drug'],\\\n",
    "#                  Parameters=['EChadwick'],Filters=Filters,\\\n",
    "#                  AvgPerCell=True, cellID='CellName', co_order=co_order,statMethod = 'Mann-Whitney', statVerbose = 2)\n",
    "# renameAxes(ax,renameDict1)\n",
    "# fig.suptitle('3T3aSFL on diverse substrates: Compressions')\n",
    "# fig.show()\n",
    "\n",
    "# # test value should be one of the following: t-test_ind, t-test_welch, t-test_paired, Mann-Whitney, Mann-Whitney-gt, Mann-Whitney-ls, Levene, Wilcoxon, Kruskal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters = [(GlobalTable_meca['Validated'] == 1), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "# co_order = makeOrder(['BSA coated glass','20um fibronectin discs'],['none','doxycyclin'])\n",
    "# fig, ax = D1Plot(GlobalTable_meca, CondCol=['substrate','drug'],\\\n",
    "#                  Parameters=['SurroundingThickness','EChadwick'],Filters=Filters,\\\n",
    "#                  AvgPerCell=True, cellID='CellName', co_order=co_order, stats=False)\n",
    "# renameAxes(ax,renameDict1)\n",
    "# fig.suptitle('3T3aSFL on diverse substrates: Compressions')\n",
    "# fig.show()\n",
    "# # fig.savefig(todayFigDir + '//' + 'compressionsBSAvsFibro_woStats.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_ctField['validated'] == True), (GlobalTable_ctField['medianThickness'] <= 1000)]\n",
    "co_order = makeOrder(['20um fibronectin discs'],['none','doxycyclin'])\n",
    "fig, ax = D1Plot(GlobalTable_ctField, CondCol=['substrate','drug'],Parameters=['medianThickness','fluctuAmpli'],\\\n",
    "                 Filters=Filters,stats=True,co_order=co_order,figSizeFactor=0.5)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL on patterns: Constant Field')\n",
    "archiveFig(fig, ax, name='3T3aSFL_drug_medianThickness', figSubDir = figSubDir)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca_Py['validatedThickness'] == True), (GlobalTable_meca_Py['ctFieldThickness'] <= 1000)]\n",
    "co_order = makeOrder(['aSFL','aSFL-A8','aSFL-6FP'],['none','doxycyclin'])\n",
    "box_pairs=[('aSFL & none', 'aSFL & doxycyclin'),\n",
    " ('aSFL-A8 & none', 'aSFL-A8 & doxycyclin'),\n",
    " ('aSFL-6FP & none', 'aSFL-6FP & doxycyclin'),\n",
    " ('aSFL & none', 'aSFL-A8 & none'),\n",
    " ('aSFL & none', 'aSFL-6FP & none')]\n",
    "fig, ax = D1Plot(GlobalTable_meca_Py, CondCol=['cell subtype','drug'],Parameters=['ctFieldThickness','ctFieldFluctuAmpli'],\\\n",
    "                 Filters=Filters,AvgPerCell=True,stats=True,co_order=co_order,box_pairs=box_pairs,figSizeFactor=1)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL on patterns: H and DH from meca expe')\n",
    "archiveFig(fig, ax, name='3T3aSFL_drug_medianThickness_fromMeca_PYTHONTABLE', figSubDir = figSubDir)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == 1), (GlobalTable_meca['substrate'] == '20um fibronectin discs')]\n",
    "co_order = makeOrder(['aSFL','aSFL-6FP'],['none','doxycyclin'])\n",
    "fig, ax = D1Plot(GlobalTable_meca, CondCol=['cell subtype','drug'],Parameters=['SurroundingThickness','EChadwick'],\\\n",
    "                 Filters=Filters,AvgPerCell=True,cellID='CellName',co_order=co_order,stats=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL short vs long linker: Compressions')\n",
    "archiveFig(fig, ax, name='3T3aSFL_likerType&drug_SurroundingThickness&EChadwick', figSubDir = figSubDir)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['substrate'] == '20um fibronectin discs')]\n",
    "co_order = makeOrder(['aSFL','aSFL-A8','aSFL-6FP'],['none','doxycyclin'])\n",
    "box_pairs=[('aSFL & none', 'aSFL & doxycyclin'),\n",
    " ('aSFL-A8 & none', 'aSFL-A8 & doxycyclin'),\n",
    " ('aSFL-6FP & none', 'aSFL-6FP & doxycyclin'),\n",
    " ('aSFL & none', 'aSFL-A8 & none'),\n",
    " ('aSFL & none', 'aSFL-6FP & none')]\n",
    "fig, ax = D1Plot(GlobalTable_meca, CondCol=['cell subtype','drug'],Parameters=['SurroundingThickness','EChadwick'],\\\n",
    "                 Filters=Filters,AvgPerCell=True,cellID='CellName',co_order=co_order,box_pairs=box_pairs,stats=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL - All linker types: Compressions')\n",
    "archiveFig(fig, ax, name='3T3aSFL_likerType&drug_SurroundingThickness&EChadwick', figSubDir = figSubDir)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca_Py['validatedFit'] == True), (GlobalTable_meca_Py['validatedThickness'] == True), (GlobalTable_meca_Py['substrate'] == '20um fibronectin discs')]\n",
    "co_order = makeOrder(['aSFL','aSFL-A8','aSFL-6FP'],['none','doxycyclin'])\n",
    "box_pairs=[('aSFL & none', 'aSFL & doxycyclin'),\n",
    " ('aSFL-A8 & none', 'aSFL-A8 & doxycyclin'),\n",
    " ('aSFL-6FP & none', 'aSFL-6FP & doxycyclin'),\n",
    " ('aSFL & none', 'aSFL-A8 & none'),\n",
    " ('aSFL & none', 'aSFL-6FP & none')]\n",
    "fig, ax = D1Plot(GlobalTable_meca_Py, CondCol=['cell subtype','drug'],Parameters=['ctFieldThickness','EChadwick'],\\\n",
    "                 Filters=Filters,AvgPerCell=True,cellID='cellID',co_order=co_order,box_pairs=box_pairs,stats=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL - All linker types: Compressions')\n",
    "archiveFig(fig, ax, name='3T3aSFL_likerType&drug_ctFThickness&EChadwick_PYTHONTABLE', figSubDir = figSubDir)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca_Py['validatedFit'] == True), (GlobalTable_meca_Py['validatedThickness'] == True),\\\n",
    "           (GlobalTable_meca_Py['substrate'] == '20um fibronectin discs'), (GlobalTable_meca_Py['drug'] == 'doxycyclin'),\\\n",
    "           (pd.isna(GlobalTable_meca_Py['meanFluoPeakAmplitude']) != True)]\n",
    "co_order = makeOrder(['aSFL','aSFL-A8','aSFL-6FP'])\n",
    "fig, ax = D1Plot(GlobalTable_meca_Py, CondCol=['cell subtype'],Parameters=['meanFluoPeakAmplitude'],\\\n",
    "                 Filters=Filters,AvgPerCell=True,cellID='cellID',co_order=co_order,stats=True,figSizeFactor=1.25)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('3T3aSFL different cell lines\\nLinker expression quantif by fluo')\n",
    "archiveFig(fig, ax, name='3T3aSFL_likerType&_fluoExp_PYTHONTABLE', figSubDir = figSubDir)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_ctField['validated'] == True), (GlobalTable_ctField['cell subtype'] == 'aSFL')]\n",
    "fig, ax = D2Plot(GlobalTable_ctField, XCol='medianThickness',YCol='fluctuAmpli',CondCol = ['cell subtype', 'drug'],\\\n",
    "                 Filters=Filters, modelFit=True, figSizeFactor = 0.8)\n",
    "fig.suptitle('3T3aSFL - Dh = f(H)')\n",
    "archiveFig(fig, ax, name='aSFL_Dh(h)_drug', figDir = todayFigDir, figSubDir='ThicknessPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above without the 2 thickest cells\n",
    "Filters = [(GlobalTable_ctField['validated'] == True), (GlobalTable_ctField['cell subtype'] == 'aSFL'),\\\n",
    "           (GlobalTable_ctField['medianThickness'] <= 700)]\n",
    "fig, ax = D2Plot(GlobalTable_ctField, XCol='medianThickness',YCol='fluctuAmpli',CondCol = ['cell subtype', 'drug'],\\\n",
    "                 Filters=Filters, modelFit=True, figSizeFactor = 0.8)\n",
    "fig.suptitle('3T3aSFL - Dh = f(H)')\n",
    "archiveFig(fig, ax, name='aSFL_Dh(h)_drug_wo2LastPoints', figDir = todayFigDir, figSubDir='ThicknessPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='SurroundingThickness',YCol='EChadwick',CondCol = ['substrate','drug'],\\\n",
    "           Filters=Filters, cellID = 'CellName', AvgPerCell=True, modelFit=False, modelType='y=A*exp(kx)')\n",
    "fig.suptitle('3T3aSFL: E(h)')\n",
    "archiveFig(fig, ax, name='aSFL_E(h)_drug&substrate', figDir = todayFigDir, figSubDir='')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation with fluorescence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='meanFluoPeakAmplitude', YCol='EChadwick', CondCol = ['cell subtype', 'drug'], \\\n",
    "                 Filters=Filters, cellID = 'CellName', AvgPerCell=True, modelFit=True)\n",
    "\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('aSFL expressing linker: E(fluo)')\n",
    "yt = ax.get_yticks()\n",
    "ax.set_yticklabels((yt/1000).astype(int))\n",
    "ax.set_ylabel('E Chadwick (kPa)')\n",
    "\n",
    "archiveFig(fig, ax, name='aSFL_iMC_E(fluo)', figDir = todayFigDir, figSubDir='FluoPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='meanFluoPeakAmplitude', YCol='EChadwick', CondCol = ['cell subtype', 'drug'], \\\n",
    "                 Filters=Filters, cellID = 'CellName', AvgPerCell=True, modelFit=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('aSFL expressing linker: E(fluo)')\n",
    "archiveFig(fig, ax, name='aSFL_iMC_E(fluo)', figDir = todayFigDir, figSubDir='FluoPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as above without the lonely point\n",
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL'), (GlobalTable_meca['EChadwick'] <= 80000)]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='meanFluoPeakAmplitude', YCol='EChadwick', CondCol = ['cell subtype', 'drug'], \\\n",
    "                 Filters=Filters, cellID = 'CellName', AvgPerCell=True, modelFit=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('aSFL expressing linker: E(fluo)')\n",
    "archiveFig(fig, ax, name='aSFL_iMC_E(fluo)_woLastPoint', figDir = todayFigDir, figSubDir='FluoPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca_Py['validatedFit'] == True), ((GlobalTable_meca_Py['cell subtype'] == 'aSFL') | (GlobalTable_meca_Py['cell subtype'] == 'aSFL-A8')), (GlobalTable_meca_Py['drug'] == 'doxycyclin')]\n",
    "fig, ax = D2Plot(GlobalTable_meca_Py, XCol='meanFluoPeakAmplitude', YCol='EChadwick', CondCol = ['cell subtype'], \\\n",
    "                 Filters=Filters, cellID = 'cellID', AvgPerCell=True, modelFit=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('aSFL & aSFL-A8 expressing linker: E(fluo)')\n",
    "archiveFig(fig, ax, name='aSFL&A8_iMC_E(fluo)', figDir = todayFigDir, figSubDir='FluoPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as above without the lonely point\n",
    "Filters = [(GlobalTable_meca_Py['validatedFit'] == True), (GlobalTable_meca_Py['drug'] == 'doxycyclin'), \\\n",
    "           ((GlobalTable_meca_Py['cell subtype'] == 'aSFL') | (GlobalTable_meca_Py['cell subtype'] == 'aSFL-A8')), \\\n",
    "           (GlobalTable_meca_Py['meanFluoPeakAmplitude'] <= 1200), (GlobalTable_meca_Py['EChadwick'] >= 2000)]\n",
    "fig, ax = D2Plot(GlobalTable_meca_Py, XCol='meanFluoPeakAmplitude', YCol='EChadwick', CondCol = ['cell subtype'], \\\n",
    "                 Filters=Filters, cellID = 'cellID', AvgPerCell=True, modelFit=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('aSFL & aSFL-A8 expressing linker: E(fluo)')\n",
    "archiveFig(fig, ax, name='aSFL&A8_iMC_E(fluo)_fluo-1200_&_E+2000', figDir = todayFigDir, figSubDir='FluoPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='meanFluoPeakAmplitude',YCol='SurroundingThickness',CondCol = ['cell subtype', 'drug'], Filters=Filters, cellID = 'CellName',AvgPerCell=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('aSFL expressing linker: H(fluo)')\n",
    "archiveFig(fig, ax, name='aSFL_iMC_H(fluo)', figDir = todayFigDir, figSubDir='FluoPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_ctField['validated'] == True)]\n",
    "fig, ax = D2Plot(GlobalTable_ctField, XCol='meanFluoPeakAmplitude',YCol='medianThickness',CondCol = ['cell subtype', 'drug'],\\\n",
    "                 Filters=Filters, cellID = 'cellID', AvgPerCell=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('aSFL expressing linker: medianH(fluo)')\n",
    "archiveFig(fig, ax, name='aSFL_iMC_medianH(fluo)', figDir = todayFigDir, figSubDir='FluoPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL-6FP')]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='meanFluoPeakAmplitude', YCol='EChadwick', CondCol = ['cell subtype', 'drug'], \\\n",
    "                 Filters=Filters, cellID = 'CellName', AvgPerCell=True, modelFit=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('aSFL-6FP expressing long linker: E(fluo)')\n",
    "archiveFig(fig, ax, name='aSFL-6FP_iMC_E(fluo)', figDir = todayFigDir, figSubDir='FluoPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as above without the lonely point\n",
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL-6FP'), (GlobalTable_meca['meanFluoPeakAmplitude'] <= 1000)]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='meanFluoPeakAmplitude', YCol='EChadwick', CondCol = ['cell subtype', 'drug'], \\\n",
    "                 Filters=Filters, cellID = 'CellName', AvgPerCell=True, modelFit=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('aSFL-6FP expressing long linker: E(fluo)')\n",
    "archiveFig(fig, ax, name='aSFL-6FP_iMC_E(fluo)_woLastPoint', figDir = todayFigDir, figSubDir='FluoPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Filters = [(GlobalTable_meca['Validated'] == True), (GlobalTable_meca['cell subtype'] == 'aSFL-6FP')]\n",
    "fig, ax = D2Plot(GlobalTable_meca, XCol='meanFluoPeakAmplitude', YCol='SurroundingThickness', CondCol = ['cell subtype', 'drug'],\\\n",
    "                 Filters=Filters, cellID = 'CellName',AvgPerCell=True)\n",
    "renameAxes(ax,renameDict1)\n",
    "fig.suptitle('aSFL-6FP expressing long linker: H(fluo)')\n",
    "archiveFig(fig, ax, name='aSFL-6FP_iMC_H(fluo)', figDir = todayFigDir, figSubDir='FluoPlots')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Create a test table to test different fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Script !\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "testDir = os.path.join(dataDir, 'TestDataSet')\n",
    "testFileName = 'testFitCompression.txt'\n",
    "testFilePath = os.path.join(testDir, testFileName)\n",
    "\n",
    "list_mecaFiles = [f for f in os.listdir(timeSeriesDataDir) \\\n",
    "                  if (os.path.isfile(os.path.join(timeSeriesDataDir, f)) and f.endswith(\".csv\") \\\n",
    "                  and ('R40' in f))] # Change to allow different formats in the future\n",
    "expDf = getExperimentalConditions()\n",
    "tableDictTest = {}\n",
    "\n",
    "for f in list_mecaFiles:\n",
    "    print(f)\n",
    "    tS_DataFilePath = os.path.join(timeSeriesDataDir, f)\n",
    "    tsDF = pd.read_csv(tS_DataFilePath, ';')\n",
    "    \n",
    "    split_f = f.split('_')\n",
    "    tsDF.dx, tsDF.dy, tsDF.dz, tsDF.D2, tsDF.D3 = tsDF.dx*1000, tsDF.dy*1000, tsDF.dz*1000, tsDF.D2*1000, tsDF.D3*1000\n",
    "    thisManipID = split_f[0] + '_' + split_f[1]\n",
    "    expDf['manipID'] = expDf['date'] + '_' + expDf['manip']\n",
    "    thisExpDf = expDf.loc[expDf['manipID'] == thisManipID]\n",
    "    DIAMETER = thisExpDf.at[thisExpDf.index.values[0], 'bead diameter']\n",
    "    thisCellID = split_f[0] + '_' + split_f[1] + '_' + split_f[2] + '_' + split_f[3]\n",
    "    Ncomp = max(tsDF['idxCompression'])\n",
    "    \n",
    "    for i in range(1, Ncomp+1): #Ncomp+1):\n",
    "        thisCompHiD = thisCellID + '__' + str(i) + '__h'\n",
    "        thisCompFiD = thisCellID + '__' + str(i) + '__f'\n",
    "        print(thisCompHiD)\n",
    "        \n",
    "        thisCompDf = tsDF.loc[tsDF['idxCompression'] == i, :]\n",
    "        iStart = (findFirst(tsDF['idxCompression'], i))\n",
    "        iStop = iStart + thisCompDf.shape[0]\n",
    "        \n",
    "        # Delimit the start of the increase of B (typically the moment when the field decrease from 5 to 3)\n",
    "        # and the end of its decrease (typically when it goes back from 3 to 5)\n",
    "        \n",
    "        listB = thisCompDf.B.values\n",
    "        offsetStart, offsetStop = 0, 0\n",
    "        minB, maxB = min(listB), max(listB)\n",
    "        thresholdB = (maxB-minB)/50\n",
    "        k = 0\n",
    "        \n",
    "        while (listB[k] > minB+thresholdB) or (listB[-1-k] > minB+thresholdB):\n",
    "            offsetStart += int(listB[k] > minB+thresholdB)\n",
    "            k += 1\n",
    "        \n",
    "        jStart = offsetStart\n",
    "        jMax = np.argmax(thisCompDf.B)\n",
    "        \n",
    "        hCompr = (thisCompDf.D3.values[jStart:jMax+1] - DIAMETER)\n",
    "        fCompr = (thisCompDf.F.values[jStart:jMax+1])\n",
    "        \n",
    "        tableDictTest[thisCompHiD] = hCompr\n",
    "        tableDictTest[thisCompFiD] = fCompr\n",
    "        \n",
    "saveFile = open(testFilePath, 'w')\n",
    "for k in tableDictTest.keys():\n",
    "    saveFile.write(k)\n",
    "    for i in range(len(tableDictTest[k])):\n",
    "        saveFile.write(';')\n",
    "        saveFile.write(str(tableDictTest[k][i]))\n",
    "    saveFile.write('\\n')\n",
    "saveFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Create a test table to try statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Script !\n",
    "\n",
    "# Create a test table to try statistical tests\n",
    "\n",
    "testDir = os.path.join(dataDir, 'TestDataSet')\n",
    "GlobalTable_meca = getGlobalTable_meca()\n",
    "table_ExpConditions = getExperimentalConditions()\n",
    "table_fluo = getFluoData()\n",
    "GlobalTable_meca = pd.merge(GlobalTable_meca, table_ExpConditions, how=\"inner\", on='manipID',\n",
    "#     left_on=None,right_on=None,left_index=False,right_index=False,sort=True,\n",
    "#     suffixes=(\"_x\", \"_y\"),copy=True,indicator=False,validate=None,\n",
    ")\n",
    "GlobalTable_meca = pd.merge(GlobalTable_meca, table_fluo, how=\"left\", left_on='CellName', right_on='cellID'\n",
    "#     left_on=None,right_on=None,left_index=False,right_index=False,sort=True,\n",
    "#     suffixes=(\"_x\", \"_y\"),copy=True,indicator=False,validate=None,\n",
    ")\n",
    "print('Merged table has ' + str(GlobalTable_meca.shape[0]) + ' lines and ' + str(GlobalTable_meca.shape[1]) + ' columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Table 1\n",
    "\n",
    "testFileName = 'testStats01_allComp.csv'\n",
    "testFilePath = os.path.join(testDir, testFileName)\n",
    "\n",
    "Filters = [(GlobalTable_meca['Validated'] == 1), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "co_order = makeOrder([['BSA coated glass','20um fibronectin discs'],['none','doxycyclin']])\n",
    "data = GlobalTable_meca\n",
    "CondCol=['substrate','drug']\n",
    "Parameters=['SurroundingThickness','EChadwick']\n",
    "AvgPerCell=False\n",
    "cellID='CellName'\n",
    "\n",
    "data_filtered = data\n",
    "for fltr in Filters:\n",
    "    data_filtered = data_filtered.loc[fltr]\n",
    "\n",
    "NCond = len(CondCol)    \n",
    "if NCond == 1:\n",
    "    CondCol = CondCol[0]\n",
    "elif NCond > 1:\n",
    "    newColName = ''\n",
    "    for i in range(NCond):\n",
    "        newColName += CondCol[i]\n",
    "        newColName += ' & '\n",
    "    newColName = newColName[:-3]\n",
    "    data_filtered[newColName] = ''\n",
    "    for i in range(NCond):\n",
    "        data_filtered[newColName] += data_filtered[CondCol[i]].astype(str)\n",
    "        data_filtered[newColName] = data_filtered[newColName].apply(lambda x : x + ' & ')\n",
    "    data_filtered[newColName] = data_filtered[newColName].apply(lambda x : x[:-3])\n",
    "    CondCol = newColName\n",
    "    \n",
    "if AvgPerCell:\n",
    "    group = data_filtered.groupby(cellID)\n",
    "    dictAggMean = getDictAggMean(data_filtered)\n",
    "    data_filtered = group.agg(dictAggMean)\n",
    "\n",
    "data_filtered.sort_values(CondCol, axis=0, ascending=True, inplace=True)\n",
    "\n",
    "df_output = data_filtered[[cellID, 'CompNum', newColName] + Parameters]\n",
    "\n",
    "# df_output.to_csv(testFilePath)\n",
    "\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Table 2\n",
    "\n",
    "testFileName = 'testStats02_avgPerCell.csv'\n",
    "testFilePath = os.path.join(testDir, testFileName)\n",
    "\n",
    "Filters = [(GlobalTable_meca['Validated'] == 1), (GlobalTable_meca['cell subtype'] == 'aSFL')]\n",
    "co_order = makeOrder([['BSA coated glass','20um fibronectin discs'],['none','doxycyclin']])\n",
    "data = GlobalTable_meca\n",
    "CondCol=['substrate','drug']\n",
    "Parameters=['SurroundingThickness','EChadwick']\n",
    "AvgPerCell=True\n",
    "cellID='CellName'\n",
    "\n",
    "data_filtered = data\n",
    "for fltr in Filters:\n",
    "    data_filtered = data_filtered.loc[fltr]\n",
    "\n",
    "NCond = len(CondCol)    \n",
    "if NCond == 1:\n",
    "    CondCol = CondCol[0]\n",
    "elif NCond > 1:\n",
    "    newColName = ''\n",
    "    for i in range(NCond):\n",
    "        newColName += CondCol[i]\n",
    "        newColName += ' & '\n",
    "    newColName = newColName[:-3]\n",
    "    data_filtered[newColName] = ''\n",
    "    for i in range(NCond):\n",
    "        data_filtered[newColName] += data_filtered[CondCol[i]].astype(str)\n",
    "        data_filtered[newColName] = data_filtered[newColName].apply(lambda x : x + ' & ')\n",
    "    data_filtered[newColName] = data_filtered[newColName].apply(lambda x : x[:-3])\n",
    "    CondCol = newColName\n",
    "    \n",
    "if AvgPerCell:\n",
    "    group = data_filtered.groupby(cellID)\n",
    "    dictAggMean = getDictAggMean(data_filtered)\n",
    "    data_filtered = group.agg(dictAggMean)\n",
    "\n",
    "data_filtered.sort_values(CondCol, axis=0, ascending=True, inplace=True)\n",
    "\n",
    "df_output = data_filtered[[cellID, 'CompNum', newColName] + Parameters]\n",
    "\n",
    "# df_output.to_csv(testFilePath)\n",
    "\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Table 3\n",
    "# Fake data\n",
    "\n",
    "testDir = os.path.join(dataDir, 'TestDataSet')\n",
    "\n",
    "testFileName = 'testStats03_FakeData.csv'\n",
    "testFilePath = os.path.join(testDir, testFileName)\n",
    "\n",
    "Npop = 10\n",
    "Npoints = 30\n",
    "minAvg = 100\n",
    "maxAvg = 600\n",
    "step = (maxAvg - minAvg)/(Npop-1)\n",
    "std = 250\n",
    "dictFakeData = {}\n",
    "np.random.seed(11)\n",
    "\n",
    "for i in [1, 2, 3, 10]:\n",
    "    dictFakeData['Distribution_' + str(i)] = np.random.normal(loc=minAvg + step*(i-1), scale=std, size=Npoints)\n",
    "\n",
    "dfFakeData = pd.DataFrame(dictFakeData)\n",
    "\n",
    "# dfFakeData.to_csv(testFilePath)\n",
    "\n",
    "dfFakeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Table 4\n",
    "# Fake data 2\n",
    "\n",
    "testDir = os.path.join(dataDir, 'TestDataSet')\n",
    "\n",
    "testFileName = 'testStats04_FakeDataLarge.csv'\n",
    "testFilePath = os.path.join(testDir, testFileName)\n",
    "\n",
    "Npop = 10\n",
    "Npoints = 300\n",
    "minAvg = 100\n",
    "maxAvg = 600\n",
    "step = (maxAvg - minAvg)/(Npop-1)\n",
    "std = 250\n",
    "dictFakeData = {}\n",
    "np.random.seed(11)\n",
    "\n",
    "for i in [1, 2, 3, 10]:\n",
    "    dictFakeData['Distribution_' + str(i)] = np.random.normal(loc=minAvg + step*(i-1), scale=std, size=Npoints)\n",
    "\n",
    "dfFakeData = pd.DataFrame(dictFakeData)\n",
    "\n",
    "# dfFakeData.to_csv(testFilePath)\n",
    "\n",
    "dfFakeData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Comparison of stat tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### With the fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "testDir = os.path.join(dataDir, 'TestDataSet')\n",
    "\n",
    "# Table 3\n",
    "# Fake data\n",
    "testFileName = 'testStats03_FakeData.csv'\n",
    "testFilePath = os.path.join(testDir, testFileName)\n",
    "\n",
    "dfFakeData = pd.read_csv(testFilePath)\n",
    "dfFakeData = dfFakeData.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "Ncol = len(dfFakeData.columns)\n",
    "\n",
    "refCol = dfFakeData[dfFakeData.columns[0]]\n",
    "boxPlotMatrix = []\n",
    "\n",
    "for i in range(0,Ncol):\n",
    "    boxPlotMatrix.append(dfFakeData[dfFakeData.columns[i]].values)\n",
    "    if i > 0:\n",
    "        print('Comparison between distribution 1 and ' + str(i+1))\n",
    "        tTest = st.ttest_ind(refCol.values, dfFakeData[dfFakeData.columns[i]].values)\n",
    "        print('tTest : ' + str(tTest.pvalue))\n",
    "        wilcox = st.wilcoxon(refCol.values, dfFakeData[dfFakeData.columns[i]].values)\n",
    "        print('wilcox : ' + str(wilcox.pvalue))\n",
    "        mannwhitneyu = st.mannwhitneyu(refCol.values, dfFakeData[dfFakeData.columns[i]].values)\n",
    "        print('mannwhitneyu : ' + str(mannwhitneyu.pvalue))\n",
    "        print('')\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.boxplot(boxPlotMatrix,labels=dfFakeData.columns.values)\n",
    "ax.tick_params(axis='x', labelrotation = 15, labelsize = 7)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "testDir = os.path.join(dataDir, 'TestDataSet')\n",
    "\n",
    "# Table 4\n",
    "# Fake data Large\n",
    "testFileName = 'testStats04_FakeDataLarge.csv'\n",
    "testFilePath = os.path.join(testDir, testFileName)\n",
    "\n",
    "dfFakeData = pd.read_csv(testFilePath)\n",
    "dfFakeData = dfFakeData.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "Ncol = len(dfFakeData.columns)\n",
    "\n",
    "refCol = dfFakeData[dfFakeData.columns[0]]\n",
    "boxPlotMatrix = []\n",
    "\n",
    "for i in range(0,Ncol):\n",
    "    boxPlotMatrix.append(dfFakeData[dfFakeData.columns[i]].values)\n",
    "    if i > 0:\n",
    "        print('Comparison between distribution 1 and ' + str(i+1))\n",
    "        tTest = st.ttest_ind(refCol.values, dfFakeData[dfFakeData.columns[i]].values)\n",
    "        print('tTest : ' + str(tTest.pvalue))\n",
    "        wilcox = st.wilcoxon(refCol.values, dfFakeData[dfFakeData.columns[i]].values)\n",
    "        print('wilcox : ' + str(wilcox.pvalue))\n",
    "        mannwhitneyu = st.mannwhitneyu(refCol.values, dfFakeData[dfFakeData.columns[i]].values)\n",
    "        print('mannwhitneyu : ' + str(mannwhitneyu.pvalue))\n",
    "        print('')\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.boxplot(boxPlotMatrix,labels=dfFakeData.columns.values)\n",
    "ax.tick_params(axis='x', labelrotation = 15, labelsize = 7)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Summary of results: numpy.random.seed = 11\n",
    "    \n",
    "dictResultsFakeData = {}\n",
    "dictResultsFakeData['language'] = ['python'   , 'python', 'python'      , 'R'     , 'R'          , 'Matlab' , 'Matlab' ]\n",
    "dictResultsFakeData['test']     = ['ttest_ind', 'wilcox', 'mannwhitneyu', 't.test', 'wilcox.test', 'ttest2' , 'ranksum']\n",
    "dictResultsFakeData['1 vs 2']   = [0.2700     , 0.2711  , 0.1353        , 0.2701  , 0.2729       , 0.2700   , 0.2707   ]\n",
    "dictResultsFakeData['1 vs 3']   = [0.0714     , 0.0822  , 0.0452        , 0.0715  , 0.0906       , 0.0714   , 0.0905   ]\n",
    "dictResultsFakeData['1 vs 10']  = [1.33e-11   , 4.28e-06, 2.98e-09      , 1.44e-11, 5.799e-11    , 1.33e-11 , 5.96e-09 ]\n",
    "dfResultFakeData = pd.DataFrame(dictResultsFakeData)\n",
    "dfResultFakeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Summary of results: numpy.random.seed = 11\n",
    "\n",
    "dictResultsFakeDataLarge = {}\n",
    "dictResultsFakeDataLarge['language'] = ['python'   , 'python', 'python'      , 'R'     , 'R'          , 'Matlab' , 'Matlab' ]\n",
    "dictResultsFakeDataLarge['test']     = ['ttest_ind', 'wilcox', 'mannwhitneyu', 't.test', 'wilcox.test', 'ttest2' , 'ranksum']\n",
    "dictResultsFakeDataLarge['1 vs 2']   = [0.0082     , 0.0049  , 0.0038        , 0.0082  , 0.0077       , 0.0082   , 0.0077   ]\n",
    "dictResultsFakeDataLarge['1 vs 3']   = [1.26e-06   , 9.29e-06, 1.37e-06      , 1.27e-06, 2.75e-06     , 1.26e-06 , 2.74e-06 ]\n",
    "dictResultsFakeDataLarge['1 vs 10']  = [1.74e-98   , 5.64e-48, 6.39e-74      , 2.2e-16 , 2.2e-16      , 1.74e-98 , 1.27e-73 ]\n",
    "dictResultsFakeDataLarge = pd.DataFrame(dictResultsFakeDataLarge)\n",
    "dictResultsFakeDataLarge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### With real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# testDir = os.path.join(dataDir, 'TestDataSet')\n",
    "\n",
    "# Table 1\n",
    "# Avg Per Cell\n",
    "testFileName = 'testStats01_AvgPerCell.csv'\n",
    "testFilePath = os.path.join(testDir, testFileName)\n",
    "\n",
    "dfAvgPerCell = pd.read_csv(testFilePath)\n",
    "# dfAvgPerCell = dfAvgPerCell.drop(columns=['Unnamed: 0'])\n",
    "dfAvgPerCell\n",
    "categories = list(dfAvgPerCell['substrate & drug'].unique())\n",
    "Ncat = len(categories)\n",
    "for i in range(Ncat):\n",
    "    for j in range(i,Ncat):\n",
    "        if j != i:\n",
    "            x = dfAvgPerCell.loc[dfAvgPerCell['substrate & drug'] == categories[i], 'EChadwick'].values\n",
    "            y = dfAvgPerCell.loc[dfAvgPerCell['substrate & drug'] == categories[j], 'EChadwick'].values\n",
    "            print('Comparison between ' + categories[i] + ' and ' + categories[j])\n",
    "            tTest = st.ttest_ind(x, y)\n",
    "            print('tTest : ' + str(tTest.pvalue))\n",
    "            mannwhitneyu = st.mannwhitneyu(x, y)\n",
    "            print('mannwhitneyu : ' + str(mannwhitneyu.pvalue))\n",
    "            print('')\n",
    "\n",
    "# refCol = dfFakeData[dfFakeData.columns[0]]\n",
    "# boxPlotMatrix = []\n",
    "\n",
    "# for i in range(0,Ncol):\n",
    "#     boxPlotMatrix.append(dfFakeData[dfFakeData.columns[i]].values)\n",
    "#     if i > 0:\n",
    "#         print('Comparison between distribution 1 and ' + str(i+1))\n",
    "#         tTest = st.ttest_ind(refCol.values, dfFakeData[dfFakeData.columns[i]].values)\n",
    "#         print('tTest : ' + str(tTest.pvalue))\n",
    "#         wilcox = st.wilcoxon(refCol.values, dfFakeData[dfFakeData.columns[i]].values)\n",
    "#         print('wilcox : ' + str(wilcox.pvalue))\n",
    "#         mannwhitneyu = st.mannwhitneyu(refCol.values, dfFakeData[dfFakeData.columns[i]].values)\n",
    "#         print('mannwhitneyu : ' + str(mannwhitneyu.pvalue))\n",
    "#         print('')\n",
    "\n",
    "# fig, ax = plt.subplots(1,1)\n",
    "# ax.boxplot(boxPlotMatrix,labels=dfFakeData.columns.values)\n",
    "# ax.tick_params(axis='x', labelrotation = 15, labelsize = 7)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dictResultsAvgPerCell = {}\n",
    "order = ['language','test','c & NA vs iMC & A','c & NA vs c & A','iMC & NA vs iMC & A','c & NA vs iMC & NA','iMC & NA vs c & A','c & A vs iMC & A']\n",
    "dictResultsAvgPerCell['language']            = ['python_statAnot'   , 'python_statAnot' ,'python'   , 'python', 'R'      , 'R'          , 'Matlab' , 'Matlab' ]\n",
    "dictResultsAvgPerCell['test']                = ['ttest_ind', 'mannwhitneyu', 'ttest_ind', 'mannwhitneyu', 't.test' , 'wilcox.test', 'ttest2' , 'ranksum']\n",
    "dictResultsAvgPerCell['c & NA vs iMC & NA']  = [1.000e+00  , 5.669e-01     ,0.19226082553146542  , 0.047244130659518     , 0.1503   , 0.09502       , 0.1923       , 0.0945]\n",
    "dictResultsAvgPerCell['iMC & NA vs c & A']   = [9.673e-02  , 8.625e-03     ,0.016121864893694285  ,0.0007187494204219925     , 0.04082  , 0.0009726    , 0.0161     , 0.0014]\n",
    "dictResultsAvgPerCell['c & A vs iMC & A']    = [2.331e-02  , 1.376e-01     ,0.00388458593467288  , 0.01146586677766893     , 0.007326 , 0.02214      , 0.0039      , 0.0229]\n",
    "dictResultsAvgPerCell['c & NA vs c & A']     = [1.000e+00  , 1.000e+00     ,0.6977550928576132  , 0.2884535746840493     , 0.6948   , 0.5838       , 0.6978     , 0.5769]\n",
    "dictResultsAvgPerCell['iMC & NA vs iMC & A'] = [1.000e+00  , 1.000e+00     ,0.5573451346686198  , 0.41831870120029446,  0.5031  , 0.8387       , 0.5573      , 0.8366 ]\n",
    "dictResultsAvgPerCell['c & NA vs iMC & A']   = [9.726e-01  , 1.000e+00     ,0.16209530366557973  , 0.14893352365754048     , 0.04353  , 0.3043       , 0.1621       , 0.2979 ]\n",
    "dfResultsAvgPerCell = pd.DataFrame(dictResultsAvgPerCell)\n",
    "dfResultsAvgPerCell[order]\n",
    "\n",
    "# dfResultsAvgPerCell = dfResultsAvgPerCell.sort_values(by='test',ascending=False)\n",
    "# dfResultsAvgPerCell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot small stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALLER_SIZE = 6\n",
    "SMALL_SIZE = 6\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 10\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALLER_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "F0, F1 = 500, 250\n",
    "h0, h1 = 200, 50\n",
    "om = 2*np.pi\n",
    "delta = 1\n",
    "T = np.arange(0,3,0.01)\n",
    "F = F1 * np.sin(2*np.pi*T) + F0\n",
    "h = h1 * np.sin(2*np.pi*T - delta) + h0\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (4,2))\n",
    "color = 'firebrick'\n",
    "ax.plot(T, F, color = color, lw = 1)\n",
    "ax.plot([np.min(T), np.max(T)], [F0, F0], 'k--', lw = 1)\n",
    "ax.set_xlabel('t (s)')\n",
    "ax.set_ylabel('F (pN)', color=color)\n",
    "ax.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "axbis = ax.twinx()\n",
    "color = 'blue'\n",
    "axbis.set_ylabel('h (nm)', color=color)\n",
    "axbis.plot(T, h, color=color, lw = 1)\n",
    "axbis.tick_params(axis='y', labelcolor=color)\n",
    "# axbis.set_yticks([0,500,1000,1500])\n",
    "# minh = np.min(tsDF['D3'].values-DIAMETER)\n",
    "# ratio = min(1/abs(minh/axM), 5)\n",
    "# #             print(ratio)\n",
    "#             (axmbis, axMbis) = ax1bis.get_ylim()\n",
    "#             ax1bis.set_ylim([0, max(axMbis*ratio, 3*max(tsDF['F'].values))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Old Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tweaked version of analyseTimeSeries_meca to plot specific stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def analyseTimeSeries_meca_tweaked(f, tsDF, expDf, listColumnsMeca, PLOT, PLOT_SHOW):\n",
    "    \n",
    "    split_f = f.split('_')\n",
    "    tsDF.dx, tsDF.dy, tsDF.dz, tsDF.D2, tsDF.D3 = tsDF.dx*1000, tsDF.dy*1000, tsDF.dz*1000, tsDF.D2*1000, tsDF.D3*1000\n",
    "    thisManipID = split_f[0] + '_' + split_f[1]\n",
    "    expDf['manipID'] = expDf['date'] + '_' + expDf['manip']\n",
    "    thisExpDf = expDf.loc[expDf['manipID'] == thisManipID]\n",
    "    DIAMETER = thisExpDf.at[thisExpDf.index.values[0], 'bead diameter']\n",
    "    \n",
    "    results = {}\n",
    "    for c in listColumnsMeca:\n",
    "        results[c] = []\n",
    "        \n",
    "    Ncomp = max(tsDF['idxCompression'])\n",
    "    NimgComp = np.sum((tsDF['idxCompression'] != 0))/Ncomp\n",
    "    NimgCompTh = round(0.49999999999 + np.sum((tsDF['idxCompression'] != 0))/Ncomp)\n",
    "    NimgBtwComp = np.sum((tsDF['idxCompression'] == 0))/Ncomp\n",
    "    NimgBtwCompTh = round(0.4999999999 + np.sum((tsDF['idxCompression'] == 0))/Ncomp)\n",
    "#     print('Ncomp : ' + str(Ncomp) + ' ; ' + 'NimgComp : ' + str(NimgComp) + '/' + str(NimgCompTh) + ' ; ' + 'NimgBtwComp : ' + str(NimgBtwComp) + '/' + str(NimgBtwCompTh))\n",
    "#     if not NimgBtwComp%2 == 0:\n",
    "#         print('Bug with the compressions sequence delimitation')\n",
    "\n",
    "    # These values are computed once for the whole cell D3 time series, but since the table has 1 line per compression, \n",
    "    # that same value will be put in the table for each line corresponding to that cell\n",
    "    ctFieldH = (tsDF.loc[tsDF['idxCompression'] == 0, 'D3'].values - DIAMETER)\n",
    "    ctFieldThickness   = np.median(ctFieldH)\n",
    "    ctFieldFluctuAmpli = np.percentile(ctFieldH,90) - np.percentile(ctFieldH,10)\n",
    "    \n",
    "    # First part of the plot [mainly ax1 and ax1bis]\n",
    "    if PLOT:\n",
    "        nColsSubplot = 5\n",
    "        nRowsSubplot = ((Ncomp-1) // nColsSubplot) + 1\n",
    "        fig1, ax1 = plt.subplots(1,1,figsize=(tsDF.shape[0]*(1/100)*0.25,4))\n",
    "#         fig2, ax2 = plt.subplots(1,Ncomp,figsize=(3*Ncomp,3))\n",
    "        fig2, ax2 = plt.subplots(nRowsSubplot,nColsSubplot,figsize=(3*nColsSubplot,3*nRowsSubplot))\n",
    "        \n",
    "        color = 'blue'\n",
    "#         ax1.plot(tsDF['T'].values, tsDF['D3'].values-DIAMETER, color = color, ls = '-', linewidth = 1)\n",
    "        ax1.set_xlabel('t (s)')\n",
    "#         ax1.set_ylabel('h (nm)', color=color)\n",
    "#         ax1.tick_params(axis='y', labelcolor=color)\n",
    "#         (axm, axM) = ax1.get_ylim()\n",
    "#         ax1.set_ylim([min(0,axm), axM-50])\n",
    "        ax1.set_xlim([0, 45])\n",
    "#         if (max(tsDF['D3'].values-DIAMETER) > 200):\n",
    "#             ax1.set_yticks(np.arange(0, max(tsDF['D3'].values-DIAMETER), 100))\n",
    "        ax1.set_yticks([])\n",
    "        \n",
    "        twinAxis = True\n",
    "        if twinAxis:\n",
    "#             ax1.tick_params(axis='y', labelcolor='b')\n",
    "            ax1bis = ax1.twinx()\n",
    "            color = 'purple'\n",
    "            ax1bis.set_ylabel('B (mT)', color=color)\n",
    "            ax1bis.plot(tsDF['T'].values, tsDF['B'].values, color=color)\n",
    "            ax1bis.tick_params(axis='y', labelcolor=color)\n",
    "            ax1bis.set_yticks([0,3,6,10,20,30,40])\n",
    "#             ax1bis.set_yticks([0,500,1000,1500])\n",
    "#             minh = np.min(tsDF['D3'].values-DIAMETER)\n",
    "#             ratio = min(1/abs(minh/axM), 5)\n",
    "#             print(ratio)\n",
    "#             (axmbis, axMbis) = ax1bis.get_ylim()\n",
    "#             ax1bis.set_ylim([0, max(axMbis*ratio, 3*max(tsDF['F'].values))])\n",
    "            yt = ax1bis.get_yticklabels()\n",
    "            for item in yt:\n",
    "                item.set_fontsize(11)\n",
    "            \n",
    "    \n",
    "    for i in range(1, Ncomp+1):#Ncomp+1):\n",
    "\n",
    "        # (1) Identifiers\n",
    "        results['date'].append(split_f[0])\n",
    "        results['cellName'].append(split_f[1] + '_' + split_f[2] + '_' + split_f[3])\n",
    "        results['cellID'].append(split_f[0] + '_' + split_f[1] + '_' + split_f[2] + '_' + split_f[3])\n",
    "        results['manipID'].append(split_f[0] + '_' + split_f[1])\n",
    "        \n",
    "        # (2) Segment the compression n°i\n",
    "        thisCompDf = tsDF.loc[tsDF['idxCompression'] == i,:]\n",
    "        iStart = (findFirst(tsDF['idxCompression'], i))\n",
    "        iStop = iStart+thisCompDf.shape[0]\n",
    "        \n",
    "        # Easy-to-get parameters\n",
    "        results['compNum'].append(i)\n",
    "        results['compDuration'].append(thisExpDf.at[thisExpDf.index.values[0], 'compression duration'])\n",
    "        results['compStartTime'].append(thisCompDf['T'].values[0])\n",
    "        results['compAbsStartTime'].append(thisCompDf['Tabs'].values[0])\n",
    "        results['compStartTimeThisDay'].append(thisCompDf['Tabs'].values[0]) # Will be modifyed later !\n",
    "        \n",
    "        # (3) Inside the compression n°i, delimit the compression and relaxation phases\n",
    "        \n",
    "        # Delimit the start of the increase of B (typically the moment when the field decrease from 5 to 3)\n",
    "        # and the end of its decrease (typically when it goes back from 3 to 5)\n",
    "        listB = thisCompDf.B.values\n",
    "        offsetStart, offsetStop = 0, 0\n",
    "        minB, maxB = min(listB), max(listB)\n",
    "        thresholdB = (maxB-minB)/50\n",
    "        \n",
    "        k = 0\n",
    "        while (listB[k] > minB+thresholdB) or (listB[-1-k] > minB+thresholdB):\n",
    "            offsetStart += int(listB[k] > minB+thresholdB)\n",
    "            offsetStop += int(listB[-1-k] > minB+thresholdB)\n",
    "            k += 1\n",
    "        jStart = offsetStart # Beginning of compression\n",
    "        jMax = np.argmax(thisCompDf.B) # End of compression, beginning of relaxation\n",
    "        jStop = thisCompDf.shape[0] - offsetStop # End of relaxation\n",
    "        \n",
    "        # Four arrays\n",
    "        hCompr = (thisCompDf.D3.values[jStart:jMax+1] - DIAMETER)\n",
    "        hRelax = (thisCompDf.D3.values[jMax+1:jStop] - DIAMETER)\n",
    "        fCompr = (thisCompDf.F.values[jStart:jMax+1])\n",
    "        fRelax = (thisCompDf.F.values[jMax+1:jStop])\n",
    "        \n",
    "        # Refinement of the compression delimitation.\n",
    "        # Remove the 1-2 points at the begining where there is just the viscous relaxation of the cortex\n",
    "        # because of the initial decrease of B and the cortex thickness increases.\n",
    "        offsetStart2 = 0\n",
    "        k = 0\n",
    "        while (hCompr[k] < np.max(hCompr[k+1:min(k+10, len(hCompr))])) and k<len(hCompr)-10:\n",
    "            offsetStart2 += 1\n",
    "            k += 1\n",
    "        # Better compressions arrays\n",
    "        hCompr = hCompr[offsetStart2:]\n",
    "        fCompr = fCompr[offsetStart2:]\n",
    "        \n",
    "        # Get the points of constant field preceding and surrounding the current compression\n",
    "        # Ex : if the labview code was set so that there is 6 points of ct field before and after each compression,\n",
    "        # previousPoints will contains D3[iStart-12:iStart]\n",
    "        # surroundingPoints will contains D3[iStart-6:iStart] and D3[iStop:iStop+6]\n",
    "        previousPoints = (tsDF.D3.values[max(0,iStart-(NimgBtwCompTh)):iStart]) - DIAMETER\n",
    "        surroundingPoints = np.concatenate([tsDF.D3.values[max(0,iStart-(NimgBtwCompTh//2)):iStart],tsDF.D3.values[iStop:iStop+(NimgBtwCompTh//2)]]) - DIAMETER\n",
    "        \n",
    "        # Parameters relative to the thickness ( = D3-DIAMETER)\n",
    "        results['initialThickness'].append(np.mean(hCompr[0:3]))\n",
    "        results['minThickness'].append(np.min(hCompr))\n",
    "        results['maxIndent'].append(results['initialThickness'][-1] - results['minThickness'][-1])\n",
    "        results['previousThickness'].append(np.median(previousPoints))\n",
    "        results['surroundingThickness'].append(np.median(surroundingPoints))\n",
    "        results['ctFieldThickness'].append(ctFieldThickness)\n",
    "        results['ctFieldFluctuAmpli'].append(ctFieldFluctuAmpli)\n",
    "        \n",
    "        validatedThickness = np.min([results['initialThickness'],results['minThickness'],results['previousThickness'],\\\n",
    "                                    results['surroundingThickness'],results['ctFieldThickness']]) > 0\n",
    "        results['validatedThickness'].append(validatedThickness)\n",
    "\n",
    "        # (4) Fit with Chadwick model of the force-thickness curve\n",
    "        \n",
    "        E, H0, hPredict, R2, confIntE, confIntH0, fitError = compressionFitChadwick(hCompr, fCompr, DIAMETER) # IMPORTANT SUBFUNCTION\n",
    "        \n",
    "        R2CRITERION = 0.9\n",
    "        critFit = 'R2 > ' + str(R2CRITERION)\n",
    "        results['critFit'].append(critFit)\n",
    "        validatedFit = (R2 > R2CRITERION)\n",
    "        \n",
    "        if PLOT:\n",
    "\n",
    "            # fig1\n",
    "#             if not fitError:\n",
    "#                 if validatedFit:\n",
    "#                     ax1.plot(thisCompDf['T'].values, thisCompDf['D3'].values-DIAMETER, color = 'chartreuse', linestyle = '-', linewidth = 1.25)\n",
    "#                 else:\n",
    "#                     ax1.plot(thisCompDf['T'].values, thisCompDf['D3'].values-DIAMETER, color = 'gold', linestyle = '-', linewidth = 1.25)\n",
    "#             else:\n",
    "#                 ax1.plot(thisCompDf['T'].values, thisCompDf['D3'].values-DIAMETER, color = 'crimson', linestyle = '-', linewidth = 1.25)\n",
    "\n",
    "            \n",
    "            fig1.suptitle(results['cellID'][-1])\n",
    "            \n",
    "            # fig2\n",
    "            colSp = (i-1) % nColsSubplot\n",
    "            rowSp = (i-1) // nColsSubplot\n",
    "            # ax2[i-1] with the 1 line plot\n",
    "            if nRowsSubplot == 1:\n",
    "                thisAx2 = ax2[colSp]\n",
    "            elif nRowsSubplot >= 1:\n",
    "                thisAx2 = ax2[rowSp,colSp]\n",
    "            \n",
    "            thisAx2.plot(hCompr,fCompr,'b-', linewidth = 0.8)\n",
    "            thisAx2.plot(hRelax,fRelax,'r-', linewidth = 0.8)\n",
    "            titleText = results['cellID'][-1] + '__c' + str(i)\n",
    "            legendText = ''\n",
    "            thisAx2.set_xlabel('h (nm)')\n",
    "            thisAx2.set_ylabel('f (pN)')\n",
    "            \n",
    "            if not fitError:\n",
    "                legendText += 'H0 = {:.1f}nm\\nE = {:.2e}Pa\\nR2 = {:.3f}'.format(H0, E, R2)\n",
    "                thisAx2.plot(hPredict,fCompr,'k--', linewidth = 0.8, label = legendText)\n",
    "                thisAx2.legend(loc = 'upper right', prop={'size': 6})\n",
    "                if not validatedFit:\n",
    "                    titleText += '\\nNON VALIDATED'\n",
    "            else:\n",
    "                titleText += '\\nFIT ERROR'\n",
    "            \n",
    "            thisAx2.title.set_text(titleText)\n",
    "\n",
    "            for item in ([thisAx2.title, thisAx2.xaxis.label, \\\n",
    "                          thisAx2.yaxis.label] + thisAx2.get_xticklabels() + thisAx2.get_yticklabels()):\n",
    "                item.set_fontsize(9)\n",
    "                \n",
    "\n",
    "        if not fitError:\n",
    "            confIntEWidth = abs(confIntE[0] - confIntE[1])\n",
    "\n",
    "            results['H0Chadwick'].append(H0)\n",
    "            results['EChadwick'].append(E)\n",
    "            results['R2Chadwick'].append(R2)\n",
    "            results['EChadwick_CIWidth'].append(confIntEWidth)\n",
    "            \n",
    "\n",
    "            results['validatedFit'].append(validatedFit)\n",
    "            if validatedFit:\n",
    "                results['comments'].append('ok')\n",
    "            else:\n",
    "                results['comments'].append('R2 < ' + str(R2CRITERION))\n",
    "                \n",
    "        if fitError:\n",
    "            validatedFit = False\n",
    "            results['H0Chadwick'].append(np.nan)\n",
    "            results['EChadwick'].append(np.nan)\n",
    "            results['R2Chadwick'].append(np.nan)\n",
    "            results['EChadwick_CIWidth'].append(np.nan)\n",
    "            results['validatedFit'].append(validatedFit)\n",
    "            results['comments'].append('fitFailure')\n",
    "            \n",
    "        \n",
    "        # (5) hysteresis (its definition may change)\n",
    "        results['hysteresis'].append(hCompr[0] - hRelax[-1])\n",
    "    \n",
    "    if PLOT:\n",
    "        archiveFig(fig1, ax1, name=results['cellID'][-1] + '_h(t)', figSubDir = 'MecaAnalysis_allCells')\n",
    "        archiveFig(fig2, ax2, name=results['cellID'][-1] + '_F(h)', figSubDir = 'MecaAnalysis_allCells')\n",
    "        if PLOT_SHOW:\n",
    "            fig1.show()\n",
    "            fig2.tight_layout()\n",
    "            fig2.show()\n",
    "        else:\n",
    "            plt.close('all')\n",
    "    \n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data formatting and filtering\n",
    "\n",
    "TBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mecaDataFile = 'Global_MecaData.csv'\n",
    "mecaDataFilePath = os.path.join(dataDir, mecaDataFile)\n",
    "mecaDF = pd.read_csv(mecaDataFilePath, sep=';')\n",
    "print('Extracted a table with ' + str(mecaDF.shape[0]) + ' lines and ' + str(mecaDF.shape[1]) + ' columns.')\n",
    "\n",
    "mecaDF = mecaDF.rename(columns={\"CellID\": \"CellName\", \"CellName\": \"CellID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mecaDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "experimentalDataFile = 'ExperimentalConditions.csv'\n",
    "experimentalDataFilePath = os.path.join(experimentalDataDir, experimentalDataFile)\n",
    "expConditionsDF = pd.read_csv(experimentalDataFilePath, sep=';',header=0)\n",
    "print('Extracted a table with ' + str(expConditionsDF.shape[0]) + ' lines and ' + str(expConditionsDF.shape[1]) + ' columns.')\n",
    "\n",
    "# Cleaning the table\n",
    "try:\n",
    "    expConditionsDF = expConditionsDF.convert_dtypes()\n",
    "\n",
    "    listTextColumns = []\n",
    "    for col in expConditionsDF.columns:\n",
    "        if expConditionsDF[col].dtype == 'string':\n",
    "            listTextColumns.append(col)\n",
    "\n",
    "    expConditionsDF[listTextColumns] = expConditionsDF[listTextColumns].apply(lambda x: x.str.replace(',','.'))\n",
    "\n",
    "    expConditionsDF['scale pixel per um'] = expConditionsDF['scale pixel per um'].astype(float)\n",
    "    expConditionsDF['optical index correction'] = \\\n",
    "              expConditionsDF['optical index correction'].apply(lambda x: x.split('/')[0]).astype(float) \\\n",
    "            / expConditionsDF['optical index correction'].apply(lambda x: x.split('/')[1]).astype(float)\n",
    "    expConditionsDF['magnetic field correction'] = expConditionsDF['magnetic field correction'].astype(float)\n",
    "    expConditionsDF['with fluo images'] = expConditionsDF['with fluo images'].astype(bool)\n",
    "\n",
    "    expConditionsDF['ramp field'] = \\\n",
    "    expConditionsDF['ramp field'].apply(lambda x: [x.split(';')[0], x.split(';')[1]] if not pd.isnull(x) else [])\n",
    "\n",
    "except:\n",
    "    print('Unexpected bug with the cleaning step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expConditionsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Unused for now\n",
    "cellDescriptionDataFile = 'CellDescription.csv'\n",
    "cellDescriptionDataFilePath = os.path.join(experimentalDataDir, cellDescriptionDataFile)\n",
    "cellDescriptionDF = pd.read_csv(cellDescriptionDataFilePath, ',')\n",
    "print('Extracted a table with ' + str(cellDescriptionDF.shape[0]) + ' lines and ' + str(cellDescriptionDF.shape[1]) + ' columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mecaDF['ManipID'] = mecaDF['ExpDay'] + '_' + mecaDF['CellName'].apply(lambda x: x.split('_')[0])\n",
    "expConditionsDF['ManipID'] = expConditionsDF['date'] + '_' + expConditionsDF['manip']\n",
    "\n",
    "mainMecaDF = pd.merge(\n",
    "    expConditionsDF,\n",
    "    mecaDF,\n",
    "    how=\"inner\",\n",
    "    on='ManipID',\n",
    "#     left_on=None,\n",
    "#     right_on=None,\n",
    "#     left_index=False,\n",
    "#     right_index=False,\n",
    "#     sort=True,\n",
    "#     suffixes=(\"_x\", \"_y\"),\n",
    "#     copy=True,\n",
    "#     indicator=False,\n",
    "#     validate=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# mainMecaDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.reset_option('max_columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### * Data filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# mainMecaDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pd.reset_option('max_columns')\n",
    "# mainMecaDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mainMecaDF_f = mainMecaDF.loc[(mainMecaDF[\"Validated\"] == 1)]\n",
    "# mainMecaDF_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "listCells = mainMecaDF_f['CellID'].drop_duplicates().astype('string').values\n",
    "timeSeriesDict = {}\n",
    "for cell in listCells:\n",
    "    currentCell_TimeSeriesData = getCellTimeSeriesData(cell)\n",
    "    timeSeriesDict[cell] = currentCell_TimeSeriesData\n",
    "start, stop = 80, 100\n",
    "fig, axes = plt.subplots((stop-start),1, figsize = (7,4*(stop-start)))\n",
    "fig.tight_layout()\n",
    "for k in range(start, stop):\n",
    "    if k < len(listCells):\n",
    "        currentCell_TimeSeriesData = timeSeriesDict[listCells[k]]\n",
    "        T = currentCell_TimeSeriesData['T'].values\n",
    "        idxCompression = currentCell_TimeSeriesData['idxCompression'].values\n",
    "        D3 = currentCell_TimeSeriesData['D3'].values\n",
    "        maskConstant = (idxCompression == 0)\n",
    "        maskCompression = (idxCompression > 0)\n",
    "        axes[k - start].plot(T, D3*1000-4503, 'k-', linewidth = 0.5)\n",
    "        axes[k - start].plot(T[maskCompression], D3[maskCompression]*1000-4503, 'ro', markersize=2)\n",
    "        axes[k - start].plot(T[maskConstant], D3[maskConstant]*1000-4503, 'co', markersize=2)\n",
    "        axes[k - start].set_title(listCells[k])\n",
    "        axes[k - start].set_xlabel('T (s)')\n",
    "        axes[k - start].set_ylabel('D3 (µm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "addExcludedCell('21-01-18_M1_P1_C2', 'passive')\n",
    "addExcludedCell('21-01-18_M1_P1_C3', 'passive')\n",
    "addExcludedCell('21-01-18_M1_P1_C4', 'passive')\n",
    "addExcludedCell('21-01-21_M3_P1_C4', 'passive')\n",
    "addExcludedCell('21-01-21_M3_P1_C5', 'passive')\n",
    "addExcludedCell('20-08-07_M1_P1_C6', 'too thick')\n",
    "addExcludedCell('20-08-07_M1_P1_C62', 'too thick')\n",
    "\n",
    "excludedCellsDict = getExcludedCells()\n",
    "# # excludedMask = (mainMecaDF_f[\"CellID\"].values not in excludedCellsDict.keys())\n",
    "# # mainMecaDF_f = mainMecaDF_f.loc[(mainMecaDF_f[\"CellID\"].values not in excludedCellsDict.keys())]\n",
    "# for i in range(len(excludedCellsDict)):\n",
    "#     print('a')\n",
    "# mainMecaDF_f[\"CellID\"].drop_duplicates().astype('string').values\n",
    "excludedCellsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# currentCell_TimeSeriesData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mainMecaDF_GroupedPerCell = mainMecaDF_f.groupby('CellID')\n",
    "mainMecaDF_DataPerCell = mainMecaDF_GroupedPerCell.agg({\"EChadwick\": np.median, \"SurroundingThickness\": np.median, \"H0Chadwick\" : np.median})\n",
    "# mainMecaDF_GroupedPerCell.agg({\"EChadwick\": np.median, \"D\": lambda x: np.std(x, ddof=1)})\n",
    "cols = ['date', 'manip', 'experimentType', 'drug', 'substrate',\n",
    "       'objective magnification', 'scale pixel per um', 'objective immersion',\n",
    "       'optical index correction', 'magnetic field correction', 'cell type',\n",
    "       'cell subtype', 'bead type', 'bead diameter', 'normal field',\n",
    "       'ramp field', 'compression duration', 'with fluo images', 'comments',\n",
    "       'ManipID', 'ExpType', 'CellName', 'CellID']\n",
    "mainMecaDF_DataPerCell.dropna(inplace = True)\n",
    "mainMecaDF_DataPerCell = pd.merge(mainMecaDF_DataPerCell,\n",
    "                                  mainMecaDF_f[cols].drop_duplicates(subset=['CellID']),\n",
    "                                  how=\"inner\",\n",
    "                                  on='CellID',\n",
    "                                  #     left_on='CellID',\n",
    "                                  #     right_on='CellID',\n",
    "                                  #     left_index=False,\n",
    "                                  #     right_index=False,\n",
    "                                  #     sort=True,\n",
    "                                  #     suffixes=(\"_x\", \"_y\"),\n",
    "                                  #     copy=True,\n",
    "                                  #     indicator=False,\n",
    "                                  #     validate=None,\n",
    "                                  )\n",
    "# mainMecaDF_DataPerCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "GlobalTable_meca_Count = GlobalTable_meca.groupby(['cell type', 'cell subtype', 'bead type', 'drug', 'substrate']).count()\n",
    "GlobalTable_meca_Count.loc[:, ['CellID']].rename(columns={'CellID' : 'Count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Other old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1,2, figsize = (8, 5))\n",
    "# axes[0].plot(np.ones(len(resDict['nodrug']['median'])), resDict['nodrug']['median'], 'co')\n",
    "# axes[0].plot(2*np.ones(len(resDict['doxy']['median'])), resDict['doxy']['median'], 'ro')\n",
    "# axes[0].set_xlim(0.5, 2.5)\n",
    "# axes[0].set_ylabel('Median Thickness (nm)')\n",
    "# axes[0].set_xticks([1,2])\n",
    "# axes[0].set_xticklabels(['Control','Doxycylin'])\n",
    "# axes[1].plot(np.ones(len(resDict['nodrug']['fluctu'])), resDict['nodrug']['fluctu'], 'co')\n",
    "# axes[1].plot(2*np.ones(len(resDict['doxy']['fluctu'])), resDict['doxy']['fluctu'], 'ro')\n",
    "# axes[1].set_xlim(0.5, 2.5)\n",
    "# axes[1].set_ylabel('Thickness Fluctuations (nm)')\n",
    "# axes[1].set_xticks([1,2])\n",
    "# axes[1].set_xticklabels(['Control','Doxycylin'])\n",
    "# fig.savefig(\"C://Users//JosephVermeil//Desktop//ActinCortexAnalysis//DataAnalysis//constantField.png\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Old code\n",
    "conditions = ['nodrug', 'doxy']\n",
    "correspondance = {conditions[0] : 'M1', conditions[1] : 'M2'}\n",
    "allTimeSeriesDataFiles = [f for f in os.listdir(timeSeriesDataDir) if (os.path.isfile(os.path.join(timeSeriesDataDir, f)) and f.endswith(\".txt\"))]\n",
    "dates = ['21-02-10']\n",
    "resDict = {conditions[0] : {}, conditions[1] : {}}\n",
    "for C in conditions:\n",
    "    resDict[C]['accepted'] = []\n",
    "    resDict[C]['rejected'] = []\n",
    "    resDict[C]['median'] = []\n",
    "    resDict[C]['fluctu'] = []\n",
    "    for D in dates:\n",
    "        for f in allTimeSeriesDataFiles:\n",
    "            if correspondance[C] in f and D in f:\n",
    "                split_f = f.split('_')\n",
    "                cellID = split_f[0] + '_' + split_f[1] + '_' + split_f[2] + '_' + split_f[3]\n",
    "                currentCellTS = getCellTimeSeriesData(cellID)\n",
    "                D3 = currentCellTS.D3.values\n",
    "                decile_1 = np.percentile(D3, 10)\n",
    "                median = np.median(D3)\n",
    "                decile_9 = np.percentile(D3, 90)\n",
    "                if decile_1 < 0:\n",
    "                    resDict[C]['rejected'].append(cellID)\n",
    "                else:\n",
    "                    resDict[C]['accepted'].append(cellID)\n",
    "                    resDict[C]['median'].append(median)\n",
    "                    resDict[C]['fluctu'].append(decile_9-decile_1)\n",
    "#resDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "GlobalTable_ctField = getGlobalTable_ctField()\n",
    "table_ExpConditions = getExperimentalConditions()\n",
    "GlobalTable_ctField = pd.merge(table_ExpConditions, GlobalTable_ctField, how=\"inner\", on='manipID',\n",
    "#     left_on=None,right_on=None,left_index=False,right_index=False,sort=True,\n",
    "#     suffixes=(\"_x\", \"_y\"),copy=True,indicator=False,validate=None,\n",
    ")\n",
    "\n",
    "# data=pd.DataFrame(dict(\n",
    "#             x=[1, 2, 3, 4, 5],\n",
    "#             y=[2, 5, 8, 2, 7],\n",
    "#             desc=['A', 'A', 'C', 'd', 'E'],\n",
    "#         ))\n",
    "\n",
    "data = GlobalTable_ctField[['medianThickness','fluctuAmpli','cellID']]\n",
    "\n",
    "source = ColumnDataSource(\n",
    "        data=data\n",
    "    )\n",
    "\n",
    "# hover = HoverTool(\n",
    "#         tooltips=[\n",
    "#             (\"index\", \"$index\"),\n",
    "#             (\"(x,y)\", \"($x, $y)\"),\n",
    "#             (\"desc\", \"@desc\"),\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"medianThickness\", \"@medianThickness\"),\n",
    "            (\"fluctuAmpli\", \"@fluctuAmpli\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "p = figure(plot_width=300, plot_height=300, tools=[hover], title=\"Mouse over the dots\")\n",
    "\n",
    "p.circle('medianThickness', 'fluctuAmpli', size=20, source=data)\n",
    "\n",
    "show(p)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame(dict(\n",
    "            x=[1, 2, 3, 4, 5],\n",
    "            y=[2, 5, 8, 2, 7],\n",
    "            desc=['A', 'A', 'C', 'd', 'E'],\n",
    "        ))\n",
    "\n",
    "Conditions = list(data['desc'].unique())\n",
    "NCond = len(Conditions)\n",
    "data['X'] = 0\n",
    "for i in range(NCond):\n",
    "    mask = data['desc'] == Conditions[i]\n",
    "    data.loc[mask, ['X']] = i+1\n",
    "data.index = data.x\n",
    "data = data.drop(['x'], axis = 1)\n",
    "\n",
    "data.reset_index(level=0, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "169px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 765,
   "position": {
    "height": "787px",
    "left": "1610px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
